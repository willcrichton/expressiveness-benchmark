(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[5],{"/4Ii":function(n,e,t){"use strict";t.d(e,"f",(function(){return u})),t.d(e,"e",(function(){return p})),t.d(e,"c",(function(){return m})),t.d(e,"b",(function(){return g})),t.d(e,"a",(function(){return _}));var a=t("LvDl"),r=t.n(a),s=t("PA40"),i=t("j0Zo"),o=t("4Y7M"),l=t("rAU/"),d=t("Srz1");t.d(e,"d",(function(){return d}));var u=["Aggregation","Joins","Strings","First-order logic","Time Series","Graphs"],c=["customer_orders","unique_product","average_adjacent"],p=r.a.sortBy(i,[function(n){return r.a.findIndex(u,(function(e){return e==n.category}))},"name"]).filter((function(n){return!r.a.includes(c,n.id)})),m=l.map((function(n){return new s.Program(n)})),g=["python-imperative","python-functional","python-pandas","r","sql","datalog","q"],_=r.a.sortBy(o,(function(n){return r.a.findIndex(g,(function(e){return e==n.id}))}))},"4Y7M":function(n){n.exports=JSON.parse('[{"id":"python-imperative","name":"Python - Imperative"},{"id":"r","name":"R - Tidyverse"},{"id":"python-pandas","name":"Python - Pandas"},{"id":"python-functional","name":"Python - Functional"},{"id":"sql","name":"SQL - SQLite"},{"id":"q","name":"Q - kdb+"},{"id":"datalog","name":"Datalog - Souffle"}]')},BsWD:function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));var a=t("a3WO");function r(n,e){if(n){if("string"===typeof n)return Object(a.a)(n,e);var t=Object.prototype.toString.call(n).slice(8,-1);return"Object"===t&&n.constructor&&(t=n.constructor.name),"Map"===t||"Set"===t?Array.from(n):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?Object(a.a)(n,e):void 0}}},I7Fo:function(n,e,t){"use strict";t.d(e,"a",(function(){return y})),t.d(e,"c",(function(){return q})),t.d(e,"d",(function(){return O})),t.d(e,"e",(function(){return S})),t.d(e,"b",(function(){return T}));var a=t("a3WO");var r=t("BsWD");function s(n){return function(n){if(Array.isArray(n))return Object(a.a)(n)}(n)||function(n){if("undefined"!==typeof Symbol&&Symbol.iterator in Object(n))return Array.from(n)}(n)||Object(r.a)(n)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var i=t("ODXe"),o=t("rePB");function l(n,e){if(null==n)return{};var t,a,r=function(n,e){if(null==n)return{};var t,a,r={},s=Object.keys(n);for(a=0;a<s.length;a++)t=s[a],e.indexOf(t)>=0||(r[t]=n[t]);return r}(n,e);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(n);for(a=0;a<s.length;a++)t=s[a],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(r[t]=n[t])}return r}var d=t("nKUr"),u=t("q1tI"),c=t("LvDl"),p=t.n(c),m=t("PA40"),g=t("/4Ii"),_=t("YFqc"),k=t.n(_);function f(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(n);e&&(a=a.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,a)}return t}function h(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?f(Object(t),!0).forEach((function(e){Object(o.a)(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):f(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}var v=function(n,e){return"rgba(".concat(m.PALETTE[n].join(", "),", ").concat(e||1,")")},y=function(n){var e=n.program,t=l(n,["program"]);return Object(d.jsx)(m.CodeViewer,h(h({task:p.a.find(g.e,{id:e.task}),program:e},t),{},{editor_props:h({highlightActiveLine:!1,readOnly:!0,showGutter:!1,tabSize:2},t.editor_props)}))},w=function n(e){var t=e.val;return Array.isArray(t)?"object"===typeof t[0]?Object(d.jsx)(b,{table:t}):Object(d.jsxs)(d.Fragment,{children:["[",t.map((function(e,t){return[t>0&&", ",Object(d.jsx)(n,{val:e},t)]})),"]"]}):Object(d.jsx)(d.Fragment,{children:t})},b=function(n){var e=n.table,t=p.a.keys(e[0]);return Object(d.jsxs)("table",{children:[Object(d.jsx)("thead",{children:Object(d.jsx)("tr",{children:t.map((function(n){return Object(d.jsx)("th",{children:n},n)}))})}),Object(d.jsx)("tbody",{children:e.map((function(n,e){return Object(d.jsx)("tr",{children:t.map((function(e){return Object(d.jsx)("td",{children:Object(d.jsx)("code",{children:n[e]})},e)}))},e)}))})]})},x=function(n){var e=n.task;return Object(d.jsxs)("div",{className:"io",children:[Object(d.jsx)("strong",{className:"header",children:"Example input/output:"}),Object(d.jsxs)("div",{className:"data-container",children:[p.a.map(e.sample_input,(function(n,e){return Object(d.jsxs)("div",{className:"input",children:[Object(d.jsx)("strong",{children:"Input:"})," ",Object(d.jsx)("code",{children:e}),Object(d.jsx)(b,{table:n})]},e)})),Object(d.jsxs)("div",{className:"output",children:[Object(d.jsx)("strong",{children:"Output:"})," ",Object(d.jsx)("code",{children:Object(d.jsx)(w,{val:e.sample_output})})]})]})]})},E=function(n){var e=n.program,t=n.headers,a=l(n,["program","headers"]),r=p.a.find(g.e,{id:e.task});return Object(d.jsxs)("div",{className:"program-container",children:[Object(d.jsx)("h3",{children:t.map((function(n){var t=p.a.find("task"==n?g.e:g.a,{id:e[n]});return Object(d.jsx)(k.a,{href:"/".concat(n,"/").concat(t.id),children:t.name})})).reduce((function(n,e){return[n," / ",e]}))}),Object(d.jsx)(y,h({program:e,width:"100%",task:r},a))]})},q=function(n){var e=n.programs,t=n.query,a=l(n,["programs","query"]);return p.a.chunk(e||function(n){g.c.filter((function(e){var t=p.a.find(g.e,{id:e.task});return!!t&&p.a.toPairs(n).map((function(n){var a=Object(i.a)(n,2),r=a[0],s=a[1];return(e.hasOwnProperty(r)?e[r]:t[r])==s})).reduce((function(n,e){return n&&e}))}))}(t),2).map((function(n,e){return Object(d.jsx)("div",{className:"program-row",children:n.map((function(n,e){return Object(d.jsx)(E,h({program:n},a),e)}))},e)}))},O=function(n){var e=n.task,t=n.on_selected,a=Object(u.useState)(null),r=a[0],s=a[1],i=Object(u.useState)(null),o=i[0],l=i[1];Object(u.useEffect)((function(){return t(r)}),[r]);for(var c=e.description,m=p.a.chain(e.plan).map((function(n,e){return[c.indexOf(n.description),h({index:e},n)]})).fromPairs().value(),g=0,_=[];g<c.length;)g in m?function(){var n=m[g],e=r||o,a=e?e==n.id?1:.25:.5,i=(v(n.index,a),v(n.index,Math.min(1,2*a)));_.push(Object(d.jsx)("span",{className:"goal",onClick:function(e){s(r&&r==n.id?null:n.id),e.stopPropagation()},onMouseEnter:function(){r||t(n.id),l(n.id)},onMouseLeave:function(){r||t(null),l(null)},style:{background:v(n.index,a),border:"2px solid ".concat(i)},children:n.description})),g+=n.description.length}():(_.push(c[g]),g+=1);return Object(d.jsxs)("div",{className:"task-spec",onClick:function(){return s(null)},children:[Object(d.jsx)("strong",{children:"Specification: "}),_]})},N=function(n){var e=n.group_key,t=n.group_value,a=n.pivot_key,r=(n.show_plan,g.c.filter((function(n){return n[e]==t.id}))),i=("language"==a?g.a:g.e).filter((function(n){return p.a.find(r,Object(o.a)({},a,n.id))})),l=i.map((function(n){return n.id})),c=Object(u.useState)(l),m=c[0],_=c[1],k=Object(u.useState)(null),f=k[0],h=k[1],v=function(n){var e=n.pivot;return Object(d.jsxs)("div",{onClick:function(){var n=p.a.findIndex(m,(function(n){return n==e.id}));if(n>-1){var t=s(m);t.splice(n,1),_(t)}else _([].concat(s(m),[e.id]))},children:[Object(d.jsx)("input",{type:"checkbox",checked:p.a.includes(m,e.id)}),e.name]})},y=function(){return Object(d.jsxs)("div",{className:"minimap",children:[Object(d.jsx)("button",{className:"toggle",onClick:function(){_(0==m.length?l:[])},children:"Toggle All"}),i.map((function(n){return Object(d.jsx)(v,{pivot:n},n.id)}))]})},w=p.a.chain(m).sortBy((function(n){return p.a.findIndex(i,{id:n})})).map((function(n){return p.a.find(r,Object(o.a)({},a,n))})).value();return Object(d.jsxs)("div",{className:"pivot-view",children:[Object(d.jsxs)("h2",{children:[p.a.capitalize(e),": ",t.name]}),Object(d.jsxs)("div",{className:"column-container",children:[Object(d.jsxs)("div",{className:"main-content",children:["task"==e?Object(d.jsx)("div",{className:"main-sticky",children:Object(d.jsx)(O,{task:t,on_selected:h})}):null,Object(d.jsxs)("div",{className:"main-scroll",children:["task"==e?Object(d.jsx)(x,{task:t}):null,Object(d.jsx)(q,{programs:w,headers:[a],plan_focus:f})]})]}),Object(d.jsx)("div",{className:"sidebar",children:Object(d.jsx)("div",{className:"sidebar-sticky",children:Object(d.jsx)(y,{})})})]})]})},S=function(n){var e=n.task;return Object(d.jsx)(N,{group_key:"task",group_value:e,pivot_key:"language",show_plan:!0})},T=function(n){var e=n.lang;return Object(d.jsx)(N,{group_key:"language",group_value:e,pivot_key:"task",show_plan:!1})}},J4zp:function(n,e,t){var a=t("wTVA"),r=t("m0LI"),s=t("ZhPi"),i=t("wkBT");n.exports=function(n,e){return a(n)||r(n,e)||s(n,e)||i()}},ODXe:function(n,e,t){"use strict";t.d(e,"a",(function(){return r}));var a=t("BsWD");function r(n,e){return function(n){if(Array.isArray(n))return n}(n)||function(n,e){if("undefined"!==typeof Symbol&&Symbol.iterator in Object(n)){var t=[],a=!0,r=!1,s=void 0;try{for(var i,o=n[Symbol.iterator]();!(a=(i=o.next()).done)&&(t.push(i.value),!e||t.length!==e);a=!0);}catch(l){r=!0,s=l}finally{try{a||null==o.return||o.return()}finally{if(r)throw s}}return t}}(n,e)||Object(a.a)(n,e)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}},Srz1:function(n){n.exports=JSON.parse('[{"task":"average_window","language":"sql","plan":{"key":[{"line":2,"start":9,"end":30,"ntokens":12}],"group by":[{"line":2,"start":0,"end":8,"ntokens":4},{"line":1,"start":0,"end":9,"ntokens":3}],"average":[{"line":0,"start":7,"end":18,"ntokens":8}],"output_order":[{"line":3,"start":0,"end":13,"ntokens":5},{"line":3,"start":0,"end":13,"ntokens":5},{"line":3,"start":0,"end":13,"ntokens":5}]},"source":"SELECT AVG(x) as x\\nFROM data\\nGROUP BY cast(time / 7 as int)\\nORDER BY time","author":"scott","implementation":"","ntokens":34,"category":"Time Series","language_name":"SQL - SQLite","task_name":"Windowed average","token_zscore":-0.9714595758,"plan_overlap":0},{"task":"average_window","language":"python-imperative","plan":{"key":[{"line":1,"start":2,"end":20,"ntokens":7},{"line":2,"start":4,"end":40,"ntokens":15}],"output_order":[{"line":5,"start":2,"end":36,"ntokens":15}],"group by":[{"line":9,"start":2,"end":24,"ntokens":12},{"line":10,"start":4,"end":31,"ntokens":8},{"line":11,"start":4,"end":37,"ntokens":8},{"line":7,"start":2,"end":34,"ntokens":10},{"line":3,"start":2,"end":19,"ntokens":11},{"line":4,"start":4,"end":13,"ntokens":4}],"average":[{"line":12,"start":6,"end":34,"ntokens":10},{"line":13,"start":6,"end":54,"ntokens":17},{"line":8,"start":2,"end":32,"ntokens":17},{"line":6,"start":2,"end":13,"ntokens":6},{"line":14,"start":4,"end":23,"ntokens":8},{"line":15,"start":4,"end":14,"ntokens":5},{"line":17,"start":2,"end":15,"ntokens":3},{"line":16,"start":2,"end":30,"ntokens":10}]},"source":"def average_window(data):\\n  def window(value):\\n    return math.floor(value[\\"time\\"] / 7)\\n  if len(data) < 1:\\n    return []\\n  data.sort(key=lambda v: v[\\"time\\"])\\n  result = []\\n  current_window = window(data[0])\\n  total, count = data[0][\\"x\\"], 1\\n  for value in data[1:]:\\n    time_window = window(value)\\n    if time_window != current_window:\\n      result.append(total / count)\\n      current_window, total, count = time_window, 0, 0\\n    total += value[\\"x\\"]\\n    count += 1\\n  result.append(total / count)\\n  return result","author":"scott","implementation":"","ntokens":190,"category":"Time Series","language_name":"Python - Imperative","task_name":"Windowed average","token_zscore":1.9349345523,"plan_overlap":2},{"task":"average_window","language":"python-functional","plan":{"output_order":[{"line":5,"start":4,"end":35,"ntokens":15}],"group by":[{"line":3,"start":2,"end":20,"ntokens":5},{"line":4,"start":4,"end":56,"ntokens":25},{"line":5,"start":4,"end":35,"ntokens":15},{"line":6,"start":2,"end":3,"ntokens":1},{"line":9,"start":4,"end":32,"ntokens":7},{"line":7,"start":2,"end":10,"ntokens":3},{"line":10,"start":2,"end":3,"ntokens":1}],"key":[{"line":1,"start":2,"end":20,"ntokens":7},{"line":2,"start":4,"end":40,"ntokens":15}],"average":[{"line":8,"start":4,"end":29,"ntokens":11}]},"source":"def average_window(data):\\n  def window(value):\\n    return math.floor(value[\\"time\\"] / 7)\\n  grouped_values = [\\n    [point[\\"x\\"] for point in data if window(point) == w]\\n    for w in set(map(window, data))\\n  ]\\n  return [\\n    sum(values) / len(values)\\n    for values in grouped_values\\n  ]","author":"scott","implementation":"","ntokens":107,"category":"Time Series","language_name":"Python - Functional","task_name":"Windowed average","token_zscore":0.3885838303,"plan_overlap":2},{"task":"average_window","language":"python-pandas","plan":{"key":[{"line":1,"start":2,"end":16,"ntokens":7},{"line":2,"start":4,"end":28,"ntokens":12}],"output_order":[{"line":3,"start":12,"end":36,"ntokens":6}],"group by":[{"line":4,"start":35,"end":50,"ntokens":5},{"line":4,"start":17,"end":35,"ntokens":6},{"line":5,"start":2,"end":29,"ntokens":10},{"line":3,"start":2,"end":11,"ntokens":5}],"average":[{"line":4,"start":51,"end":57,"ntokens":3}]},"source":"def average_window(data):\\n  def window(t):\\n    return math.floor(t / 7)\\n  result = (data.sort_values(\\"time\\")\\n                .set_index(\\"time\\").groupby(window).mean())\\n  return result[\'x\'].tolist()","author":"scott","implementation":"","ntokens":66,"category":"Time Series","language_name":"Python - Pandas","task_name":"Windowed average","token_zscore":-0.3752761649,"plan_overlap":2},{"task":"average_window","language":"datalog","plan":{"average":[{"line":5,"start":18,"end":27,"ntokens":1},{"line":6,"start":2,"end":37,"ntokens":9},{"line":7,"start":6,"end":44,"ntokens":9}],"group by":[{"line":0,"start":0,"end":23,"ntokens":8},{"line":2,"start":0,"end":35,"ntokens":14},{"line":3,"start":0,"end":31,"ntokens":20},{"line":4,"start":0,"end":41,"ntokens":14},{"line":1,"start":0,"end":26,"ntokens":17}],"key":[{"line":1,"start":7,"end":10,"ntokens":1},{"line":3,"start":9,"end":12,"ntokens":1},{"line":1,"start":7,"end":10,"ntokens":1}],"output_order":[]},"source":".decl window(w: number)\\nwindow(t/7) :- data(t, _).\\n.decl windowed(w: number, x: float)\\nwindowed(t/7, x) :- data(t, x).\\n.decl windowed_total(w: number, x: float)\\nwindowed_total(w, total / n) :- window(w),\\n  total = sum x : { windowed(w, x) },\\n      n = sum z : { windowed(w, x), z=1.0 }.\\naverage_window(v) :- windowed_total(_, v).","author":"scott","implementation":"","ntokens":125,"category":"Time Series","language_name":"Datalog - Souffle","task_name":"Windowed average","token_zscore":0.7239369989,"plan_overlap":1},{"task":"average_window","language":"r","plan":{"average":[{"line":3,"start":4,"end":33,"ntokens":13},{"line":4,"start":4,"end":13,"ntokens":4}],"key":[{"line":2,"start":19,"end":27,"ntokens":6}],"group by":[{"line":1,"start":2,"end":11,"ntokens":4},{"line":2,"start":4,"end":19,"ntokens":5},{"line":2,"start":28,"end":33,"ntokens":4}]},"source":"average_window <- function(data) {\\n  data %>% \\n    group_by(floor(time / 7)) %>% \\n    summarize(avg = mean(x)) %>% \\n    pull(avg)\\n}","author":"scott","implementation":"","ntokens":49,"category":"Time Series","language_name":"R - Tidyverse","task_name":"Windowed average","token_zscore":-0.6919986019,"plan_overlap":1},{"task":"average_window","language":"q","plan":{"output_order":[{"line":1,"start":15,"end":22,"ntokens":5}],"average":[{"line":1,"start":23,"end":28,"ntokens":4}],"key":[{"line":1,"start":32,"end":33,"ntokens":2}],"group by":[{"line":1,"start":29,"end":31,"ntokens":2},{"line":1,"start":34,"end":43,"ntokens":4}]},"source":"average_window:\\n  (value select[<time] avg x by 7 xbar time from data) `x","author":"scott","implementation":"","ntokens":32,"category":"Time Series","language_name":"Q - kdb+","task_name":"Windowed average","token_zscore":-1.008721039,"plan_overlap":1},{"task":"changing_mean","language":"python-imperative","plan":{"remove":[{"line":10,"start":4,"end":34,"ntokens":19}],"new":[{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":11,"start":4,"end":27,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8}],"diff":[{"line":12,"start":4,"end":36,"ntokens":15}],"orig":[{"line":8,"start":2,"end":29,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5},{"line":3,"start":2,"end":14,"ntokens":8},{"line":4,"start":4,"end":21,"ntokens":8},{"line":5,"start":2,"end":20,"ntokens":8},{"line":1,"start":0,"end":17,"ntokens":7},{"line":2,"start":2,"end":9,"ntokens":5}],"first":[{"line":13,"start":6,"end":14,"ntokens":3},{"line":14,"start":2,"end":13,"ntokens":3}]},"source":"\\ndef get_mean(ls):\\n  sum = 0\\n  for e in ls:\\n    sum += e[\'value\']\\n  return sum/len(ls)\\n\\ndef changing_mean(vals):\\n  start_mean = get_mean(vals)\\n  for i,elem in enumerate(vals):\\n    new_ls = vals[:i] + vals[i+1:]\\n    mean = get_mean(new_ls)\\n    if abs(mean - start_mean) < 0.1:\\n      return i\\n  return None\\n","author":"g","implementation":"","ntokens":123,"category":"Aggregation","language_name":"Python - Imperative","task_name":"First element that doesn\'t change mean","token_zscore":1.2036088069,"plan_overlap":2},{"task":"changing_mean","language":"python-pandas","plan":{"diff":[{"line":4,"start":14,"end":47,"ntokens":16}],"new":[{"line":3,"start":2,"end":85,"ntokens":37},{"line":4,"start":9,"end":60,"ntokens":23}],"orig":[{"line":2,"start":2,"end":26,"ntokens":11}],"remove":[{"line":4,"start":9,"end":60,"ntokens":23},{"line":3,"start":45,"end":63,"ntokens":11}],"first":[{"line":4,"start":9,"end":60,"ntokens":23}]},"source":"\\ndef changing_mean(vals):\\n  mean = vals.value.mean()\\n  mean_without = vals.apply(lambda row: vals[vals.id != row.id].value.mean(), axis=1)\\n  return vals[(mean_without - mean).abs() < 0.1].id.tolist()\\n","author":"g","implementation":"","ntokens":83,"category":"Aggregation","language_name":"Python - Pandas","task_name":"First element that doesn\'t change mean","token_zscore":-0.3566248317,"plan_overlap":6},{"task":"changing_mean","language":"r","plan":{"remove":[{"line":4,"start":43,"end":65,"ntokens":10}],"orig":[{"line":4,"start":38,"end":43,"ntokens":3},{"line":4,"start":65,"end":66,"ntokens":1},{"line":4,"start":24,"end":35,"ntokens":2},{"line":2,"start":3,"end":34,"ntokens":10}],"new":[{"line":4,"start":36,"end":37,"ntokens":2},{"line":4,"start":5,"end":24,"ntokens":7},{"line":4,"start":66,"end":68,"ntokens":2}],"first":[{"line":7,"start":5,"end":29,"ntokens":8},{"line":8,"start":5,"end":13,"ntokens":4},{"line":3,"start":3,"end":16,"ntokens":5},{"line":5,"start":5,"end":17,"ntokens":8}],"diff":[{"line":6,"start":5,"end":34,"ntokens":10}]},"source":"library(data.table)\\nchanging_mean <- function(vals) {\\n   global_mean <- mean(vals$value)\\n   setDT(vals)[, \\n     mean_change := abs(global_mean - mean(vals[id != .BY, value])), \\n     by = id] %>%\\n     filter(mean_change < 0.1) %>%\\n     slice(which.min(id)) %>%\\n     pull(id)\\n}","author":"g","implementation":"","ntokens":90,"category":"Aggregation","language_name":"R - Tidyverse","task_name":"First element that doesn\'t change mean","token_zscore":-0.0835839449,"plan_overlap":7},{"task":"changing_mean","language":"q","plan":{"remove":[{"line":1,"start":44,"end":64,"ntokens":11}],"orig":[{"line":1,"start":7,"end":23,"ntokens":7},{"line":1,"start":26,"end":43,"ntokens":8}],"new":[{"line":1,"start":3,"end":6,"ntokens":2},{"line":1,"start":23,"end":26,"ntokens":4}],"diff":[{"line":4,"start":31,"end":48,"ntokens":7}],"first":[{"line":4,"start":15,"end":20,"ntokens":2},{"line":4,"start":20,"end":30,"ntokens":6}]},"source":"diffs: \\n  {abs avg vals[`value] - avg (vals[`value] where vals[`id] <> x)} \\n  each vals[`id];\\n  \\nchanging_mean: first vals[`id] where diffs < 0.1","author":"g","implementation":"","ntokens":64,"category":"Aggregation","language_name":"Q - kdb+","task_name":"First element that doesn\'t change mean","token_zscore":-1.09773581,"plan_overlap":1},{"task":"changing_mean","language":"sql","plan":{"diff":[{"line":6,"start":35,"end":40,"ntokens":3},{"line":2,"start":6,"end":11,"ntokens":2}],"new":[{"line":3,"start":2,"end":19,"ntokens":6},{"line":4,"start":2,"end":14,"ntokens":5},{"line":5,"start":2,"end":22,"ntokens":11},{"line":2,"start":6,"end":11,"ntokens":2},{"line":3,"start":2,"end":19,"ntokens":6},{"line":4,"start":2,"end":14,"ntokens":5},{"line":5,"start":2,"end":22,"ntokens":11},{"line":6,"start":0,"end":34,"ntokens":17}],"orig":[{"line":6,"start":5,"end":32,"ntokens":11}],"remove":[{"line":5,"start":2,"end":22,"ntokens":11},{"line":5,"start":2,"end":22,"ntokens":11}],"first":[{"line":0,"start":0,"end":9,"ntokens":3}]},"source":"SELECT id\\nFROM vals v1\\nWHERE ABS((\\n  SELECT AVG(value)\\n  FROM vals v2\\n  WHERE v1.id != v2.id\\n) - (SELECT AVG(value) FROM vals)) < 0.1","author":"g","implementation":"","ntokens":57,"category":"Aggregation","language_name":"SQL - SQLite","task_name":"First element that doesn\'t change mean","token_zscore":-1.3707766968,"plan_overlap":5},{"task":"changing_mean","language":"datalog","plan":{"orig":[{"line":9,"start":2,"end":27,"ntokens":9},{"line":10,"start":2,"end":29,"ntokens":9},{"line":11,"start":2,"end":18,"ntokens":1}],"new":[{"line":12,"start":2,"end":27,"ntokens":8},{"line":1,"start":0,"end":22,"ntokens":10},{"line":2,"start":2,"end":13,"ntokens":8},{"line":3,"start":2,"end":39,"ntokens":9},{"line":4,"start":2,"end":41,"ntokens":9},{"line":5,"start":2,"end":18,"ntokens":1}],"diff":[{"line":13,"start":2,"end":44,"ntokens":1},{"line":14,"start":3,"end":45,"ntokens":1}],"first":[{"line":8,"start":7,"end":8,"ntokens":1}],"remove":[{"line":3,"start":2,"end":39,"ntokens":9},{"line":4,"start":2,"end":41,"ntokens":9}]},"source":".decl avg_except(I:number, Avg:float)    \\navg_except(I, Avg) :- \\n  vals(I, _),\\n  N = sum 1.0 : { vals(J, _), I != J },\\n  Total = sum V : { vals(J, V), I != J },\\n  Avg = Total / N.\\n  \\nchanging_mean(I) :-\\n  vals(I, _),\\n  N = sum 1.0 : vals(_, _),\\n  Total = sum V : vals(_, V),\\n  Avg = Total / N,\\n  avg_except(I, AvgExcept),\\n  ((Avg > AvgExcept, Avg - AvgExcept < 0.1);\\n   (Avg < AvgExcept, AvgExcept - Avg < 0.1)).","author":"g","implementation":"","ntokens":97,"category":"Aggregation","language_name":"Datalog - Souffle","task_name":"First element that doesn\'t change mean","token_zscore":0.1894569418,"plan_overlap":3},{"task":"changing_mean","language":"python-functional","plan":{"remove":[{"line":6,"start":4,"end":52,"ntokens":26}],"diff":[{"line":8,"start":4,"end":35,"ntokens":13},{"line":3,"start":2,"end":34,"ntokens":20}],"new":[{"line":6,"start":4,"end":52,"ntokens":26},{"line":7,"start":4,"end":34,"ntokens":13},{"line":1,"start":0,"end":24,"ntokens":7},{"line":2,"start":2,"end":56,"ntokens":24},{"line":3,"start":2,"end":34,"ntokens":20}],"orig":[{"line":2,"start":2,"end":56,"ntokens":24},{"line":1,"start":0,"end":24,"ntokens":7}],"first":[{"line":9,"start":6,"end":14,"ntokens":3},{"line":10,"start":2,"end":13,"ntokens":3}]},"source":"\\ndef changing_mean(vals):\\n  start_mean = sum([l[\'value\'] for l in vals])/len(vals)\\n  diff = lambda m, sm: abs(m - sm)\\n    \\n  for i,elem in enumerate(vals):\\n    new_ls = [x[\'value\'] for x in vals if x != elem]\\n    mean = sum(new_ls)/len(new_ls)\\n    if diff(mean,start_mean) < 0.1:\\n      return i\\n  return None\\n","author":"g","implementation":"","ntokens":131,"category":"Aggregation","language_name":"Python - Functional","task_name":"First element that doesn\'t change mean","token_zscore":1.5156555346,"plan_overlap":4},{"task":"continent_by_population","language":"python-pandas","plan":{"group":[{"line":1,"start":22,"end":43,"ntokens":6}],"average":[{"line":1,"start":43,"end":61,"ntokens":6}],"max":[{"line":2,"start":24,"end":41,"ntokens":5}],"name":[{"line":2,"start":9,"end":24,"ntokens":5},{"line":2,"start":41,"end":42,"ntokens":1}]},"source":"def continent_by_population(countries):\\n  mean_pop = countries.groupby(\'continent\').population.mean()\\n  return mean_pop.index[mean_pop.argmax()]","author":"will","implementation":"","ntokens":36,"category":"Aggregation","language_name":"Python - Pandas","task_name":"Continent with the highest average population","token_zscore":-0.8804210357,"plan_overlap":1},{"task":"continent_by_population","language":"sql","plan":{"max":[{"line":3,"start":25,"end":29,"ntokens":1},{"line":3,"start":0,"end":8,"ntokens":4},{"line":4,"start":0,"end":7,"ntokens":3}],"average":[{"line":3,"start":9,"end":24,"ntokens":5}],"group":[{"line":2,"start":0,"end":18,"ntokens":5},{"line":1,"start":0,"end":14,"ntokens":3}],"name":[{"line":0,"start":0,"end":16,"ntokens":4}]},"source":"SELECT continent \\nFROM countries\\nGROUP BY continent\\nORDER BY AVG(population) DESC\\nLIMIT 1","author":"will","implementation":"","ntokens":25,"category":"Aggregation","language_name":"SQL - SQLite","task_name":"Continent with the highest average population","token_zscore":-1.1174574684,"plan_overlap":1},{"task":"continent_by_population","language":"datalog","plan":{"max":[{"line":10,"start":2,"end":69,"ntokens":20},{"line":9,"start":2,"end":41,"ntokens":8}],"group":[{"line":3,"start":18,"end":45,"ntokens":11},{"line":4,"start":26,"end":53,"ntokens":11}],"name":[{"line":8,"start":2,"end":29,"ntokens":11},{"line":7,"start":24,"end":33,"ntokens":1}],"average":[{"line":5,"start":2,"end":30,"ntokens":3},{"line":4,"start":2,"end":26,"ntokens":1},{"line":3,"start":2,"end":18,"ntokens":1},{"line":2,"start":2,"end":29,"ntokens":11},{"line":0,"start":0,"end":54,"ntokens":12},{"line":1,"start":0,"end":37,"ntokens":9}]},"source":".decl average_population(Continent:symbol, Avg:number)\\naverage_population(Continent, Avg) :-\\n  countries(Continent, _, _),\\n  Total = sum P : countries(Continent, _, P),\\n  Num_countries = count : countries(Continent, _, _),\\n  Avg = Total / Num_countries.\\n  \\ncontinent_by_population(Continent) :- \\n  countries(Continent, _, _), \\n  average_population(Continent, Max_avg),\\n  Max_avg = max A : { countries(C, _, _), average_population(C, A) }.","author":"will","implementation":"","ntokens":109,"category":"Aggregation","language_name":"Datalog - Souffle","task_name":"Continent with the highest average population","token_zscore":0.6926389267,"plan_overlap":1},{"task":"continent_by_population","language":"q","plan":{"max":[{"line":3,"start":3,"end":8,"ntokens":2},{"line":3,"start":15,"end":28,"ntokens":5}],"average":[{"line":1,"start":9,"end":24,"ntokens":5},{"line":1,"start":2,"end":9,"ntokens":3}],"name":[{"line":3,"start":29,"end":38,"ntokens":2},{"line":3,"start":54,"end":64,"ntokens":1}],"group":[{"line":1,"start":25,"end":52,"ntokens":8}]},"source":"averages: \\n  select avg(population) by continent from countries;\\ncontinent_by_population: \\n  (first select[>population] continent from averages) `continent","author":"will","implementation":"","ntokens":44,"category":"Aggregation","language_name":"Q - kdb+","task_name":"Continent with the highest average population","token_zscore":-0.7080309028,"plan_overlap":0},{"task":"continent_by_population","language":"python-functional","plan":{"group":[{"line":3,"start":33,"end":52,"ntokens":8},{"line":4,"start":17,"end":48,"ntokens":11}],"name":[{"line":6,"start":2,"end":3,"ntokens":1},{"line":2,"start":29,"end":30,"ntokens":1},{"line":8,"start":5,"end":15,"ntokens":3},{"line":9,"start":8,"end":18,"ntokens":3},{"line":11,"start":42,"end":45,"ntokens":3},{"line":11,"start":2,"end":8,"ntokens":2},{"line":3,"start":5,"end":15,"ntokens":3},{"line":5,"start":4,"end":31,"ntokens":7},{"line":1,"start":2,"end":55,"ntokens":19},{"line":2,"start":2,"end":30,"ntokens":5},{"line":7,"start":2,"end":14,"ntokens":5},{"line":9,"start":4,"end":7,"ntokens":2},{"line":9,"start":24,"end":51,"ntokens":3},{"line":10,"start":2,"end":3,"ntokens":1}],"max":[{"line":11,"start":9,"end":42,"ntokens":17}],"average":[{"line":8,"start":16,"end":37,"ntokens":11},{"line":9,"start":19,"end":23,"ntokens":2},{"line":3,"start":17,"end":32,"ntokens":5},{"line":9,"start":24,"end":51,"ntokens":3},{"line":9,"start":4,"end":7,"ntokens":2},{"line":10,"start":2,"end":3,"ntokens":1},{"line":7,"start":2,"end":14,"ntokens":5},{"line":2,"start":2,"end":30,"ntokens":5},{"line":6,"start":2,"end":3,"ntokens":1},{"line":5,"start":4,"end":31,"ntokens":7}]},"source":"def continent_by_population(countries):\\n  continents = set([c[\'continent\'] for c in countries])\\n  populations_by_continent = [\\n    (continent, [c[\'population\'] for c in countries \\n                 if c[\'continent\'] == continent])\\n    for continent in continents\\n  ]\\n  averages = [\\n    (continent, sum(pops) / len(pops))\\n    for continent, pops in populations_by_continent\\n  ]\\n  return max(averages, key=lambda t: t[1])[0]","author":"will","implementation":"","ntokens":131,"category":"Aggregation","language_name":"Python - Functional","task_name":"Continent with the highest average population","token_zscore":1.1667117921,"plan_overlap":4},{"task":"continent_by_population","language":"python-imperative","plan":{"name":[{"line":15,"start":2,"end":22,"ntokens":3},{"line":7,"start":2,"end":22,"ntokens":5},{"line":13,"start":6,"end":31,"ntokens":5},{"line":9,"start":2,"end":16,"ntokens":5},{"line":9,"start":32,"end":59,"ntokens":8},{"line":3,"start":4,"end":36,"ntokens":8},{"line":1,"start":2,"end":32,"ntokens":7},{"line":1,"start":46,"end":47,"ntokens":1},{"line":4,"start":4,"end":30,"ntokens":5},{"line":5,"start":4,"end":30,"ntokens":5}],"max":[{"line":11,"start":4,"end":52,"ntokens":16},{"line":12,"start":6,"end":27,"ntokens":5},{"line":8,"start":2,"end":20,"ntokens":5},{"line":9,"start":2,"end":5,"ntokens":2},{"line":9,"start":32,"end":59,"ntokens":8}],"average":[{"line":9,"start":17,"end":31,"ntokens":7},{"line":10,"start":4,"end":27,"ntokens":9},{"line":4,"start":30,"end":58,"ntokens":10},{"line":5,"start":30,"end":38,"ntokens":7}],"group":[{"line":2,"start":2,"end":27,"ntokens":8},{"line":3,"start":16,"end":36,"ntokens":4}]},"source":"def continent_by_population(countries):\\n  continent_stats = defaultdict(lambda: [0, 0])\\n  for country in countries:\\n    continent = country[\'continent\']\\n    continent_stats[continent][0] += country[\'population\']\\n    continent_stats[continent][1] += 1\\n     \\n  max_continent = None\\n  max_average = None\\n  for continent, [total, count] in continent_stats.items():\\n    average = total / count\\n    if max_average is None or max_average < average:\\n      max_average = average\\n      max_continent = continent\\n      \\n  return max_continent","author":"will","implementation":"","ntokens":146,"category":"Aggregation","language_name":"Python - Imperative","task_name":"Continent with the highest average population","token_zscore":1.4899432912,"plan_overlap":4},{"task":"continent_by_population","language":"r","plan":{"name":[{"line":5,"start":4,"end":15,"ntokens":3},{"line":4,"start":31,"end":34,"ntokens":1}],"max":[{"line":4,"start":4,"end":30,"ntokens":7},{"line":3,"start":43,"end":46,"ntokens":1}],"average":[{"line":3,"start":4,"end":42,"ntokens":11},{"line":2,"start":24,"end":27,"ntokens":1}],"group":[{"line":1,"start":12,"end":15,"ntokens":1},{"line":2,"start":4,"end":23,"ntokens":5},{"line":1,"start":2,"end":12,"ntokens":2}]},"source":"continent_by_population <- function(countries) {\\n  countries %>%\\n    group_by(continent) %>%\\n    summarize(mean_pop = mean(population)) %>%\\n    slice(which.max(mean_pop)) %>%\\n    .$continent\\n}","author":"will","implementation":"","ntokens":47,"category":"Aggregation","language_name":"R - Tidyverse","task_name":"Continent with the highest average population","token_zscore":-0.643384603,"plan_overlap":0},{"task":"continent_median_population","language":"python-pandas","plan":{"name":[{"line":4,"start":6,"end":20,"ntokens":4},{"line":4,"start":21,"end":21,"ntokens":0}],"agg":[{"line":3,"start":6,"end":26,"ntokens":6}],"iter":[{"line":2,"start":6,"end":27,"ntokens":5}],"group":[{"line":1,"start":10,"end":19,"ntokens":1}]},"source":"def continent_median_population(countries):\\n  return (countries\\n      .groupby(\'continent\')\\n      .population.median()\\n      .reset_index())","author":"will","implementation":"","ntokens":30,"category":"Aggregation","language_name":"Python - Pandas","task_name":"Median population for each continent","token_zscore":-1.096022361,"plan_overlap":0},{"task":"continent_median_population","language":"sql","plan":{"name":[{"line":0,"start":7,"end":16,"ntokens":2}],"agg":[{"line":0,"start":18,"end":47,"ntokens":8},{"line":2,"start":2,"end":13,"ntokens":3},{"line":3,"start":4,"end":21,"ntokens":6},{"line":4,"start":30,"end":59,"ntokens":11},{"line":5,"start":4,"end":16,"ntokens":6},{"line":6,"start":31,"end":39,"ntokens":3},{"line":7,"start":2,"end":17,"ntokens":4},{"line":8,"start":0,"end":6,"ntokens":2},{"line":9,"start":2,"end":48,"ntokens":32},{"line":10,"start":2,"end":55,"ntokens":34}],"group":[{"line":4,"start":7,"end":29,"ntokens":6},{"line":6,"start":7,"end":29,"ntokens":6}],"iter":[{"line":11,"start":0,"end":18,"ntokens":5}]},"source":"SELECT continent, AVG(population) as population\\nFROM\\n  (SELECT *, \\n    row_number() OVER \\n      (PARTITION BY continent ORDER BY population) AS rank, \\n    count() OVER \\n      (PARTITION BY continent) as count\\n  FROM countries)\\nWHERE \\n  (count % 2 = 1 AND rank = (count + 1) / 2) OR \\n  (count % 2 = 0 AND ABS(rank - 0.5 - count / 2) = 0.5)\\nGROUP BY continent","author":"will","implementation":"","ntokens":142,"category":"Aggregation","language_name":"SQL - SQLite","task_name":"Median population for each continent","token_zscore":0.2899155923,"plan_overlap":1},{"task":"continent_median_population","language":"datalog","plan":{"iter":[{"line":20,"start":2,"end":29,"ntokens":11}],"name":[{"line":20,"start":12,"end":21,"ntokens":1},{"line":19,"start":28,"end":37,"ntokens":1}],"agg":[{"line":19,"start":39,"end":45,"ntokens":1},{"line":21,"start":2,"end":53,"ntokens":12},{"line":22,"start":2,"end":27,"ntokens":3},{"line":23,"start":4,"end":54,"ntokens":13},{"line":24,"start":3,"end":26,"ntokens":3},{"line":25,"start":4,"end":47,"ntokens":19},{"line":26,"start":4,"end":43,"ntokens":15},{"line":27,"start":4,"end":28,"ntokens":1},{"line":0,"start":0,"end":46,"ntokens":13},{"line":1,"start":0,"end":50,"ntokens":21},{"line":2,"start":0,"end":0,"ntokens":0},{"line":3,"start":0,"end":56,"ntokens":17},{"line":4,"start":0,"end":45,"ntokens":16},{"line":5,"start":2,"end":44,"ntokens":11},{"line":6,"start":2,"end":25,"ntokens":8},{"line":7,"start":2,"end":21,"ntokens":1},{"line":8,"start":4,"end":32,"ntokens":11},{"line":9,"start":4,"end":22,"ntokens":8},{"line":10,"start":4,"end":18,"ntokens":1},{"line":11,"start":2,"end":4,"ntokens":1},{"line":12,"start":2,"end":18,"ntokens":1},{"line":13,"start":4,"end":32,"ntokens":11},{"line":14,"start":4,"end":22,"ntokens":8},{"line":15,"start":4,"end":20,"ntokens":1},{"line":16,"start":4,"end":12,"ntokens":1},{"line":17,"start":2,"end":4,"ntokens":1}],"group":[{"line":21,"start":26,"end":52,"ntokens":11},{"line":8,"start":14,"end":23,"ntokens":1},{"line":5,"start":12,"end":21,"ntokens":1}]},"source":".decl unique_id(Country:symbol, Id:number)    \\nunique_id(Country, $) :- countries(_, Country, _).\\n\\n.decl rank(Continent:symbol, R:number, Population:float)\\nrank(Continent, R_less + R_eq, Population) :-\\n  countries(Continent, Country, Population),\\n  unique_id(Country, Id),\\n  R_less = count : { \\n    countries(Continent, C, P), \\n    unique_id(C, Id2),\\n    P < Population\\n  },\\n  R_eq = count : {\\n    countries(Continent, C, P), \\n    unique_id(C, Id2),\\n    P = Population, \\n    Id2 < Id\\n  }.\\n\\ncontinent_median_population(Continent, Median) :-\\n  countries(Continent, _, _),\\n  Num_countries = count : countries(Continent, _, _),\\n  ((Num_countries % 2 = 1, \\n    rank(Continent, (Num_countries - 1) / 2, Median));\\n   (Num_countries % 2 = 0,\\n    rank(Continent, Num_countries / 2 - 1, P1),\\n    rank(Continent, Num_countries / 2, P2),\\n    Median = (P1 + P2) / 2)).     ","author":"will","implementation":"","ntokens":227,"category":"Aggregation","language_name":"Datalog - Souffle","task_name":"Median population for each continent","token_zscore":1.3417435032,"plan_overlap":6},{"task":"continent_median_population","language":"q","plan":{"agg":[{"line":1,"start":17,"end":32,"ntokens":5}],"iter":[{"line":1,"start":33,"end":45,"ntokens":4}],"group":[{"line":1,"start":46,"end":60,"ntokens":3}],"name":[{"line":1,"start":33,"end":45,"ntokens":4}]},"source":"continent_median_population:\\n  () xkey select med[population] by continent from countries","author":"will","implementation":"","ntokens":26,"category":"Aggregation","language_name":"Q - kdb+","task_name":"Median population for each continent","token_zscore":-1.145520145,"plan_overlap":1},{"task":"continent_median_population","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":55,"ntokens":19},{"line":7,"start":4,"end":31,"ntokens":7},{"line":3,"start":4,"end":13,"ntokens":2},{"line":20,"start":4,"end":46,"ntokens":14},{"line":18,"start":2,"end":10,"ntokens":3},{"line":21,"start":2,"end":3,"ntokens":1}],"group":[{"line":4,"start":22,"end":41,"ntokens":8},{"line":5,"start":6,"end":36,"ntokens":10},{"line":6,"start":4,"end":5,"ntokens":1},{"line":3,"start":15,"end":16,"ntokens":1}],"agg":[{"line":4,"start":6,"end":21,"ntokens":5},{"line":2,"start":2,"end":17,"ntokens":5},{"line":8,"start":2,"end":3,"ntokens":1},{"line":10,"start":2,"end":27,"ntokens":7},{"line":11,"start":4,"end":23,"ntokens":8},{"line":12,"start":4,"end":17,"ntokens":8},{"line":13,"start":4,"end":18,"ntokens":12},{"line":14,"start":6,"end":31,"ntokens":15},{"line":15,"start":4,"end":9,"ntokens":2},{"line":16,"start":6,"end":50,"ntokens":31},{"line":19,"start":29,"end":63,"ntokens":7}],"name":[{"line":19,"start":5,"end":27,"ntokens":5}]},"source":"def continent_median_population(countries):\\n  continents = set([c[\'continent\'] for c in countries])\\n  populations = {\\n    continent: [\\n      c[\'population\'] for c in countries \\n      if c[\'continent\'] == continent\\n    ]\\n    for continent in continents\\n  }\\n  \\n  def compute_median(pops):\\n    pops = sorted(pops)\\n    N = len(pops)\\n    if N % 2 == 1:\\n      return pops[(N - 1) // 2]\\n    else:\\n      return (pops[N // 2 - 1] + pops[N // 2]) / 2  \\n   \\n  return [\\n    {\\"continent\\": continent, \\"population\\": compute_median(pops)}\\n    for continent, pops in populations.items()\\n  ]","author":"will","implementation":"","ntokens":203,"category":"Aggregation","language_name":"Python - Functional","task_name":"Median population for each continent","token_zscore":1.044756799,"plan_overlap":5},{"task":"continent_median_population","language":"python-imperative","plan":{"iter":[{"line":3,"start":16,"end":36,"ntokens":4},{"line":6,"start":6,"end":15,"ntokens":2},{"line":6,"start":22,"end":45,"ntokens":8},{"line":13,"start":4,"end":19,"ntokens":4},{"line":16,"start":4,"end":6,"ntokens":1},{"line":5,"start":2,"end":13,"ntokens":7},{"line":6,"start":2,"end":6,"ntokens":3},{"line":18,"start":2,"end":15,"ntokens":3}],"group":[{"line":2,"start":2,"end":27,"ntokens":8},{"line":3,"start":45,"end":52,"ntokens":2}],"agg":[{"line":1,"start":2,"end":33,"ntokens":8},{"line":3,"start":4,"end":16,"ntokens":3},{"line":3,"start":36,"end":45,"ntokens":5},{"line":3,"start":52,"end":67,"ntokens":3},{"line":6,"start":17,"end":45,"ntokens":10},{"line":7,"start":4,"end":15,"ntokens":5},{"line":8,"start":4,"end":17,"ntokens":8},{"line":9,"start":4,"end":18,"ntokens":12},{"line":10,"start":6,"end":33,"ntokens":17},{"line":11,"start":4,"end":9,"ntokens":2},{"line":12,"start":6,"end":52,"ntokens":32},{"line":15,"start":6,"end":26,"ntokens":4},{"line":6,"start":2,"end":6,"ntokens":3}],"name":[{"line":14,"start":6,"end":29,"ntokens":5}]},"source":"def continent_median_population(countries):\\n  populations = defaultdict(list)\\n  for country in countries:\\n    populations[country[\'continent\']].append(country[\'population\'])\\n  \\n  output = []  \\n  for continent, pops in populations.items():\\n    pops.sort()\\n    N = len(pops)\\n    if N % 2 == 1:\\n      median = pops[(N - 1) // 2]\\n    else:\\n      median = (pops[N // 2 - 1] + pops[N // 2]) / 2\\n    output.append({\\n      \\"continent\\": continent,\\n      \\"population\\": median\\n    })\\n    \\n  return output","author":"will","implementation":"","ntokens":169,"category":"Aggregation","language_name":"Python - Imperative","task_name":"Median population for each continent","token_zscore":0.6240256346,"plan_overlap":5},{"task":"continent_median_population","language":"r","plan":{"iter":[{"line":1,"start":2,"end":15,"ntokens":3}],"group":[{"line":2,"start":4,"end":27,"ntokens":6}],"agg":[{"line":3,"start":4,"end":46,"ntokens":10}],"name":[{"line":1,"start":2,"end":15,"ntokens":3}]},"source":"continent_median_population <- function(countries) {\\n  countries %>%\\n    group_by(continent) %>%\\n    summarize(population = median(population))\\n}","author":"will","implementation":"","ntokens":33,"category":"Aggregation","language_name":"R - Tidyverse","task_name":"Median population for each continent","token_zscore":-1.058899023,"plan_overlap":1},{"task":"documents_with_infrequent_words","language":"python-pandas","plan":{"word":[{"line":1,"start":2,"end":52,"ntokens":19}],"frequency":[{"line":2,"start":2,"end":37,"ntokens":13},{"line":3,"start":2,"end":49,"ntokens":16}],"documents":[{"line":4,"start":2,"end":30,"ntokens":6},{"line":5,"start":4,"end":44,"ntokens":11},{"line":6,"start":2,"end":45,"ntokens":13}]},"source":"def documents_with_infrequent_words(documents):\\n  words = documents.text.str.split(\\" \\", expand=True)\\n  freq = words.stack().value_counts()\\n  infrequent_words = freq[freq == 1].index.values\\n  infrequent_docs = documents[\\n    np.isin(words.values, infrequent_words)]\\n  return infrequent_docs.id.unique().tolist()","author":"will","implementation":"","ntokens":91,"category":"Strings","language_name":"Python - Pandas","task_name":"Documents with infrequent words","token_zscore":-0.9078825261,"plan_overlap":0},{"task":"documents_with_infrequent_words","language":"sql","plan":{"word":[{"line":3,"start":0,"end":42,"ntokens":12},{"line":4,"start":2,"end":52,"ntokens":13},{"line":5,"start":0,"end":51,"ntokens":14},{"line":6,"start":0,"end":51,"ntokens":15}],"documents":[{"line":8,"start":0,"end":18,"ntokens":5},{"line":9,"start":0,"end":5,"ntokens":2},{"line":10,"start":2,"end":11,"ntokens":1},{"line":11,"start":2,"end":12,"ntokens":3},{"line":14,"start":26,"end":38,"ntokens":1},{"line":12,"start":2,"end":23,"ntokens":6},{"line":13,"start":3,"end":13,"ntokens":3},{"line":16,"start":2,"end":44,"ntokens":16},{"line":17,"start":2,"end":36,"ntokens":14},{"line":18,"start":2,"end":36,"ntokens":14},{"line":19,"start":2,"end":25,"ntokens":10},{"line":15,"start":0,"end":5,"ntokens":1}],"frequency":[{"line":14,"start":3,"end":24,"ntokens":8}]},"source":"-- NOTE: SQLite tokenize is case-insensitive by default, \\n-- so this solution is NOT exactly like the others\\n\\nCREATE VIRTUAL TABLE doc_index USING fts4(\\n  text, id, content=documents, tokenize=simple);    \\nINSERT INTO doc_index(doc_index) VALUES(\'rebuild\');\\nCREATE VIRTUAL TABLE words USING fts4aux(doc_index);    \\n\\nSELECT DISTINCT id\\nFROM \\n  documents\\n  CROSS JOIN\\n  (SELECT DISTINCT term\\n   FROM words\\n   WHERE occurrences = 1) unique_words\\nWHERE\\n  (LOWER(text) LIKE \'% \' || term || \' %\') OR\\n  (LOWER(text) LIKE term || \' %\') OR\\n  (LOWER(text) LIKE \'% \' || term) OR\\n  (LOWER(text) LIKE term)","author":"will","implementation":"","ntokens":151,"category":"Strings","language_name":"SQL - SQLite","task_name":"Documents with infrequent words","token_zscore":0.0825347751,"plan_overlap":1},{"task":"documents_with_infrequent_words","language":"datalog","plan":{"word":[{"line":0,"start":0,"end":50,"ntokens":17},{"line":1,"start":0,"end":23,"ntokens":13},{"line":2,"start":2,"end":39,"ntokens":13},{"line":3,"start":0,"end":27,"ntokens":15},{"line":4,"start":2,"end":49,"ntokens":16},{"line":5,"start":0,"end":29,"ntokens":15},{"line":6,"start":2,"end":57,"ntokens":16},{"line":8,"start":0,"end":63,"ntokens":22},{"line":9,"start":0,"end":32,"ntokens":15},{"line":10,"start":2,"end":25,"ntokens":8},{"line":11,"start":2,"end":26,"ntokens":11},{"line":12,"start":2,"end":35,"ntokens":1},{"line":13,"start":2,"end":42,"ntokens":12},{"line":14,"start":2,"end":53,"ntokens":17},{"line":15,"start":2,"end":32,"ntokens":12},{"line":16,"start":2,"end":23,"ntokens":11}],"frequency":[{"line":21,"start":2,"end":35,"ntokens":15}],"documents":[{"line":19,"start":2,"end":19,"ntokens":8},{"line":20,"start":2,"end":24,"ntokens":14}]},"source":".decl substrs(Text:symbol, Idx:number, Len:number)\\nsubstrs(Text, 0, 1) :- \\n  documents(_, Text), strlen(Text) > 0.\\nsubstrs(Text, 0, Len+1) :- \\n  substrs(Text, 0, Len), Len + 1 <= strlen(Text).\\nsubstrs(Text, Idx+1, Len) :- \\n  substrs(Text, Idx, Len), Idx + Len + 1 <= strlen(Text).\\n\\n.decl token(Docid:number, Text:symbol, Idx:number, Word:symbol)\\ntoken(Docid, Text, Idx, Word) :-\\n  documents(Docid, Text),\\n  substrs(Text, Idx, Len),\\n  Prev = Idx - 1, Next = Idx + Len,\\n  (Prev < 0; \\" \\" = substr(Text, Prev, 1)),\\n  (Next = strlen(Text); \\" \\" = substr(Text, Next, 1)),\\n  Word = substr(Text, Idx, Len),\\n  !contains(\\" \\", Word).\\n\\ndocuments_with_infrequent_words(Id) :-\\n  documents(Id, _),\\n  token(Id, _, _, Word),\\n  1 = count : token(_, _, _, Word).","author":"will","implementation":"","ntokens":264,"category":"Strings","language_name":"Datalog - Souffle","task_name":"Documents with infrequent words","token_zscore":1.9478206924,"plan_overlap":0},{"task":"documents_with_infrequent_words","language":"q","plan":{"word":[{"line":0,"start":0,"end":38,"ntokens":16}],"frequency":[{"line":1,"start":0,"end":34,"ntokens":13},{"line":2,"start":0,"end":20,"ntokens":10}],"documents":[{"line":4,"start":2,"end":70,"ntokens":29}]},"source":"words: (\\" \\" vs) each documents[`text];\\nfreq: count each group raze words;\\nuniq: where[freq=1];\\ndocuments_with_infrequent_words:\\n  (select id from documents where \'[any; in\\\\: [;uniq]] each words) `id","author":"will","implementation":"","ntokens":77,"category":"Strings","language_name":"Q - kdb+","task_name":"Documents with infrequent words","token_zscore":-1.1389798964,"plan_overlap":0},{"task":"documents_with_infrequent_words","language":"python-functional","plan":{"word":[{"line":1,"start":2,"end":55,"ntokens":23}],"frequency":[{"line":2,"start":2,"end":46,"ntokens":23},{"line":3,"start":2,"end":10,"ntokens":5},{"line":4,"start":4,"end":33,"ntokens":10},{"line":5,"start":4,"end":31,"ntokens":10},{"line":6,"start":2,"end":3,"ntokens":1},{"line":7,"start":2,"end":26,"ntokens":6},{"line":8,"start":4,"end":41,"ntokens":17},{"line":9,"start":4,"end":17,"ntokens":7},{"line":10,"start":2,"end":4,"ntokens":1}],"documents":[{"line":11,"start":2,"end":21,"ntokens":5},{"line":12,"start":4,"end":53,"ntokens":22},{"line":13,"start":4,"end":42,"ntokens":17},{"line":14,"start":2,"end":3,"ntokens":1},{"line":15,"start":2,"end":24,"ntokens":3}]},"source":"def documents_with_infrequent_words(documents):\\n  words = [doc[\\"text\\"].split(\\" \\") for doc in documents]\\n  words_flat = [w for ws in words for w in ws]\\n  freq = {\\n    word: words_flat.count(word) \\n    for word in set(words_flat)\\n  }\\n  infrequent_words = set([\\n    word for word, count in freq.items() \\n    if count == 1\\n  ])\\n  infrequent_docs = [\\n    documents[i][\\"id\\"] for i, ws in enumerate(words) \\n    if len(set(ws) & infrequent_words) > 0\\n  ]\\n  return infrequent_docs","author":"will","implementation":"","ntokens":173,"category":"Strings","language_name":"Python - Functional","task_name":"Documents with infrequent words","token_zscore":0.4456877855,"plan_overlap":0},{"task":"documents_with_infrequent_words","language":"python-imperative","plan":{"word":[{"line":4,"start":23,"end":45,"ntokens":9}],"frequency":[{"line":1,"start":1,"end":12,"ntokens":7},{"line":2,"start":2,"end":25,"ntokens":8},{"line":3,"start":2,"end":23,"ntokens":8},{"line":4,"start":4,"end":22,"ntokens":9},{"line":5,"start":4,"end":33,"ntokens":13},{"line":6,"start":6,"end":21,"ntokens":8},{"line":8,"start":2,"end":26,"ntokens":7},{"line":9,"start":2,"end":34,"ntokens":15},{"line":10,"start":4,"end":18,"ntokens":8},{"line":11,"start":6,"end":32,"ntokens":6}],"documents":[{"line":13,"start":2,"end":22,"ntokens":6},{"line":14,"start":2,"end":23,"ntokens":8},{"line":15,"start":4,"end":33,"ntokens":13},{"line":16,"start":6,"end":34,"ntokens":8},{"line":17,"start":8,"end":41,"ntokens":8},{"line":18,"start":8,"end":13,"ntokens":1},{"line":20,"start":0,"end":24,"ntokens":4}]},"source":"def documents_with_infrequent_words(documents):\\n  words = {}\\n  freq = defaultdict(int)\\n  for doc in documents:\\n    words[doc[\\"id\\"]] = doc[\\"text\\"].split(\\" \\")\\n    for word in words[doc[\\"id\\"]]:\\n      freq[word] += 1\\n      \\n  infrequent_words = set()\\n  for word, count in freq.items():\\n    if count == 1:\\n      infrequent_words.add(word)\\n      \\n  infrequent_docs = []\\n  for doc in documents:\\n    for word in words[doc[\\"id\\"]]:\\n      if word in infrequent_words:\\n        infrequent_docs.append(doc[\\"id\\"])\\n        break\\n        \\n  return infrequent_docs","author":"will","implementation":"","ntokens":171,"category":"Strings","language_name":"Python - Imperative","task_name":"Documents with infrequent words","token_zscore":0.4126738755,"plan_overlap":1},{"task":"documents_with_infrequent_words","language":"r","plan":{"documents":[{"line":6,"start":2,"end":12,"ntokens":4},{"line":7,"start":4,"end":43,"ntokens":12},{"line":8,"start":4,"end":16,"ntokens":6},{"line":9,"start":4,"end":12,"ntokens":2}],"frequency":[{"line":4,"start":2,"end":31,"ntokens":12},{"line":5,"start":2,"end":41,"ntokens":16}],"word":[{"line":1,"start":2,"end":24,"ntokens":7},{"line":2,"start":4,"end":43,"ntokens":14},{"line":3,"start":4,"end":12,"ntokens":2}]},"source":"documents_with_infrequent_words <- function(documents) {\\n  split <- documents %>%\\n    mutate(word = str_split(text, \\" \\")) %>%\\n    unnest()\\n  freq <- split %>% count(word)\\n  unique_words <- freq %>% filter(n == 1)\\n  split %>% \\n    filter(word %in% unique_words$word) %>%\\n    pull(id) %>%\\n    unique()\\n}","author":"will","implementation":"","ntokens":95,"category":"Strings","language_name":"R - Tidyverse","task_name":"Documents with infrequent words","token_zscore":-0.841854706,"plan_overlap":0},{"task":"process_tweets","language":"sql","plan":{"lowercase":[{"line":0,"start":7,"end":18,"ntokens":5}],"select":[{"line":0,"start":19,"end":30,"ntokens":5},{"line":0,"start":0,"end":6,"ntokens":2}],"iter":[{"line":1,"start":0,"end":9,"ntokens":3}],"filter":[{"line":2,"start":0,"end":46,"ntokens":15}]},"source":"SELECT LOWER(body) as body, ts\\nFROM data\\nWHERE language = \\"en\\" and is_retweet = \\"false\\"","author":"scott","implementation":"","ntokens":30,"category":"Strings","language_name":"SQL - SQLite","task_name":"Filter and clean tweets","token_zscore":-1.5626311467,"plan_overlap":1},{"task":"process_tweets","language":"python-imperative","plan":{"iter":[{"line":2,"start":2,"end":20,"ntokens":8},{"line":1,"start":2,"end":13,"ntokens":6},{"line":9,"start":2,"end":15,"ntokens":3}],"filter":[{"line":3,"start":4,"end":37,"ntokens":13},{"line":4,"start":8,"end":40,"ntokens":10}],"lowercase":[{"line":6,"start":16,"end":38,"ntokens":9}],"select":[{"line":5,"start":6,"end":21,"ntokens":4},{"line":6,"start":8,"end":15,"ntokens":3},{"line":7,"start":8,"end":25,"ntokens":7},{"line":8,"start":6,"end":8,"ntokens":1}]},"source":"def process_tweets(data):\\n  result = []\\n  for value in data:\\n    if (value[\\"language\\"] == \\"en\\" and\\n        value[\\"is_retweet\\"] == \\"false\\"):\\n      result.append({\\n        \\"body\\": value[\\"body\\"].lower(),\\n        \\"ts\\": value[\\"ts\\"]\\n      })\\n  return result","author":"scott","implementation":"","ntokens":80,"category":"Strings","language_name":"Python - Imperative","task_name":"Filter and clean tweets","token_zscore":1.3673022534,"plan_overlap":4},{"task":"process_tweets","language":"python-functional","plan":{"lowercase":[{"line":2,"start":13,"end":34,"ntokens":9}],"filter":[{"line":5,"start":4,"end":36,"ntokens":12},{"line":6,"start":7,"end":37,"ntokens":9}],"select":[{"line":3,"start":5,"end":23,"ntokens":7},{"line":2,"start":4,"end":13,"ntokens":5}],"iter":[{"line":4,"start":4,"end":21,"ntokens":7},{"line":7,"start":2,"end":3,"ntokens":1},{"line":1,"start":2,"end":10,"ntokens":3}]},"source":"def process_tweets(data):\\n  return [\\n    {\\"body\\": value[\\"body\\"].lower(),\\n     \\"ts\\": value[\\"ts\\"]}\\n    for value in data\\n    if value[\\"language\\"] == \\"en\\" and\\n       value[\\"is_retweet\\"] == \\"false\\" \\n  ]","author":"scott","implementation":"","ntokens":66,"category":"Strings","language_name":"Python - Functional","task_name":"Filter and clean tweets","token_zscore":0.5469209014,"plan_overlap":4},{"task":"process_tweets","language":"python-pandas","plan":{"iter":[{"line":1,"start":11,"end":15,"ntokens":2}],"filter":[{"line":1,"start":15,"end":16,"ntokens":1},{"line":2,"start":4,"end":29,"ntokens":11},{"line":3,"start":4,"end":33,"ntokens":9}],"lowercase":[{"line":4,"start":2,"end":54,"ntokens":22}],"select":[{"line":5,"start":2,"end":31,"ntokens":9}]},"source":"def process_tweets(data):\\n  result = data[\\n    (data.language == \'en\') &\\n    (data.is_retweet == \'false\')]\\n  result.body = result.body.apply(lambda s: s.lower())\\n  return result[[\\"body\\", \\"ts\\"]]","author":"scott","implementation":"","ntokens":69,"category":"Strings","language_name":"Python - Pandas","task_name":"Filter and clean tweets","token_zscore":0.7227169054,"plan_overlap":0},{"task":"process_tweets","language":"r","plan":{"iter":[{"line":1,"start":2,"end":10,"ntokens":3}],"filter":[{"line":2,"start":4,"end":56,"ntokens":18}],"select":[{"line":4,"start":4,"end":20,"ntokens":6}],"lowercase":[{"line":3,"start":4,"end":36,"ntokens":12}]},"source":"process_tweets <- function(data) {\\n  data %>%\\n    filter(language == \\"en\\" & is_retweet == \\"false\\") %>%\\n    mutate(body = tolower(body)) %>%\\n    select(ts, body)\\n}","author":"scott","implementation":"","ntokens":54,"category":"Strings","language_name":"R - Tidyverse","task_name":"Filter and clean tweets","token_zscore":-0.1562631147,"plan_overlap":0},{"task":"process_tweets","language":"q","plan":{"lowercase":[{"line":1,"start":9,"end":15,"ntokens":3},{"line":1,"start":19,"end":20,"ntokens":2}],"select":[{"line":1,"start":15,"end":19,"ntokens":2},{"line":1,"start":20,"end":24,"ntokens":4},{"line":1,"start":2,"end":9,"ntokens":3}],"iter":[{"line":1,"start":25,"end":34,"ntokens":4}],"filter":[{"line":2,"start":2,"end":56,"ntokens":21}]},"source":"process_tweets:\\n  select lower[body], ts from data \\n  where (is_retweet ~\\\\: \\"false\\") and (language ~\\\\: \\"en\\")","author":"scott","implementation":"","ntokens":41,"category":"Strings","language_name":"Q - kdb+","task_name":"Filter and clean tweets","token_zscore":-0.9180457987,"plan_overlap":1},{"task":"purchased_all_food","language":"python-pandas","plan":{"iter":[{"line":2,"start":21,"end":27,"ntokens":1},{"line":3,"start":4,"end":21,"ntokens":5},{"line":6,"start":2,"end":25,"ntokens":5},{"line":6,"start":50,"end":64,"ntokens":5}],"all":[{"line":1,"start":2,"end":20,"ntokens":8},{"line":6,"start":25,"end":50,"ntokens":6}],"ordered":[{"line":2,"start":2,"end":21,"ntokens":6},{"line":4,"start":4,"end":19,"ntokens":7},{"line":5,"start":4,"end":14,"ntokens":5}]},"source":"def purchased_all_food(food, orders):\\n  n_food = len(food)\\n  n_unique_orders = (orders\\n    .groupby(\'buyer\')\\n    .food.unique() \\n    .map(len))\\n  return n_unique_orders[n_unique_orders == n_food].index.values","author":"will","implementation":"","ntokens":61,"category":"First-order logic","language_name":"Python - Pandas","task_name":"People that purchased all possible items","token_zscore":-0.5179631974,"plan_overlap":3},{"task":"purchased_all_food","language":"sql","plan":{"iter":[{"line":0,"start":0,"end":21,"ntokens":5},{"line":1,"start":0,"end":14,"ntokens":5}],"ordered":[{"line":3,"start":2,"end":46,"ntokens":16},{"line":4,"start":3,"end":29,"ntokens":13}],"all":[{"line":5,"start":2,"end":29,"ntokens":12},{"line":4,"start":30,"end":31,"ntokens":2}]},"source":"SELECT DISTINCT buyer\\nFROM orders o1\\nWHERE \\n  (SELECT COUNT(DISTINCT food) FROM orders o2 \\n   WHERE o1.buyer = o2.buyer) = \\n  (SELECT COUNT(*) FROM food)","author":"will","implementation":"","ntokens":58,"category":"First-order logic","language_name":"SQL - SQLite","task_name":"People that purchased all possible items","token_zscore":-0.6934023448,"plan_overlap":0},{"task":"purchased_all_food","language":"datalog","plan":{"ordered":[{"line":0,"start":0,"end":46,"ntokens":12},{"line":1,"start":0,"end":53,"ntokens":21},{"line":6,"start":2,"end":52,"ntokens":9}],"all":[{"line":5,"start":2,"end":30,"ntokens":9},{"line":7,"start":2,"end":27,"ntokens":3}],"iter":[{"line":4,"start":2,"end":22,"ntokens":11},{"line":3,"start":19,"end":24,"ntokens":1}]},"source":".decl has_purchased(Buyer:symbol, Food:number)\\nhas_purchased(Buyer, Food) :- orders(Buyer, Food, _).\\n\\npurchased_all_food(Buyer) :-\\n  orders(Buyer, _, _),\\n  N_food = count : food(_, _),\\n  N_unique_orders = count : has_purchased(Buyer, _),\\n  N_food = N_unique_orders.","author":"will","implementation":"","ntokens":72,"category":"First-order logic","language_name":"Datalog - Souffle","task_name":"People that purchased all possible items","token_zscore":0.1253136768,"plan_overlap":2},{"task":"purchased_all_food","language":"q","plan":{"iter":[{"line":3,"start":45,"end":56,"ntokens":4}],"ordered":[{"line":0,"start":0,"end":29,"ntokens":9}],"all":[{"line":3,"start":3,"end":44,"ntokens":17},{"line":1,"start":0,"end":18,"ntokens":7}]},"source":"buyers: `buyer xgroup orders;\\ntotal: count food;\\npurchased_all_food:\\n  (where {(count distinct x[`food]) = total} each buyers) `buyer","author":"will","implementation":"","ntokens":47,"category":"First-order logic","language_name":"Q - kdb+","task_name":"People that purchased all possible items","token_zscore":-1.336679219,"plan_overlap":0},{"task":"purchased_all_food","language":"python-functional","plan":{"iter":[{"line":2,"start":4,"end":54,"ntokens":19},{"line":4,"start":8,"end":13,"ntokens":1},{"line":5,"start":8,"end":27,"ntokens":7}],"all":[{"line":1,"start":4,"end":22,"ntokens":8},{"line":7,"start":43,"end":52,"ntokens":3},{"line":6,"start":8,"end":10,"ntokens":2}],"ordered":[{"line":6,"start":11,"end":54,"ntokens":17},{"line":7,"start":13,"end":42,"ntokens":12}]},"source":"def purchased_all_food(food, orders):\\n    n_food = len(food)\\n    buyers = set([order[\\"buyer\\"] for order in orders])\\n    return [\\n        buyer\\n        for buyer in buyers\\n        if len(set([order[\\"food\\"] for order in orders \\n             if order[\\"buyer\\"] == buyer])) == n_food\\n    ]","author":"will","implementation":"","ntokens":91,"category":"First-order logic","language_name":"Python - Functional","task_name":"People that purchased all possible items","token_zscore":1.2364282776,"plan_overlap":2},{"task":"purchased_all_food","language":"python-imperative","plan":{"all":[{"line":1,"start":2,"end":20,"ntokens":8},{"line":8,"start":4,"end":29,"ntokens":11}],"ordered":[{"line":2,"start":2,"end":34,"ntokens":8},{"line":3,"start":2,"end":22,"ntokens":8},{"line":4,"start":4,"end":18,"ntokens":3},{"line":4,"start":32,"end":52,"ntokens":8},{"line":7,"start":13,"end":45,"ntokens":10}],"iter":[{"line":4,"start":18,"end":32,"ntokens":4},{"line":6,"start":2,"end":13,"ntokens":6},{"line":7,"start":2,"end":12,"ntokens":5},{"line":7,"start":20,"end":45,"ntokens":8},{"line":9,"start":6,"end":26,"ntokens":6},{"line":10,"start":2,"end":15,"ntokens":3}]},"source":"def purchased_all_food(food, orders):\\n  n_food = len(food)\\n  unique_orders = defaultdict(set)\\n  for order in orders:\\n    unique_orders[order[\\"buyer\\"]].add(order[\\"food\\"])\\n      \\n  buyers = []\\n  for buyer, orders in unique_orders.items():\\n    if len(orders) == n_food:\\n      buyers.append(buyer)\\n  return buyers","author":"will","implementation":"","ntokens":98,"category":"First-order logic","language_name":"Python - Imperative","task_name":"People that purchased all possible items","token_zscore":1.6457862884,"plan_overlap":3},{"task":"purchased_all_food","language":"r","plan":{"iter":[{"line":2,"start":2,"end":12,"ntokens":3},{"line":3,"start":4,"end":23,"ntokens":6},{"line":7,"start":4,"end":14,"ntokens":4}],"ordered":[{"line":4,"start":4,"end":22,"ntokens":6}],"all":[{"line":5,"start":4,"end":15,"ntokens":4},{"line":6,"start":4,"end":27,"ntokens":10},{"line":1,"start":2,"end":23,"ntokens":9}]},"source":"purchased_all_food <- function(food, orders) {\\n  n_food <- count(food)    \\n  orders %>%\\n    group_by(buyer) %>%\\n    distinct(food) %>%\\n    count() %>%\\n    filter(n == n_food) %>%\\n    pull(buyer)\\n}","author":"will","implementation":"","ntokens":62,"category":"First-order logic","language_name":"R - Tidyverse","task_name":"People that purchased all possible items","token_zscore":-0.4594834815,"plan_overlap":3},{"task":"reachable","language":"sql","plan":{"step":[{"line":2,"start":0,"end":43,"ntokens":10},{"line":4,"start":0,"end":33,"ntokens":10},{"line":5,"start":2,"end":41,"ntokens":1},{"line":6,"start":2,"end":30,"ntokens":9}],"source":[{"line":9,"start":14,"end":37,"ntokens":0},{"line":11,"start":0,"end":37,"ntokens":15}],"edge_sequence":[{"line":4,"start":2,"end":34,"ntokens":9},{"line":7,"start":2,"end":41,"ntokens":15}],"edge_match":[{"line":8,"start":2,"end":30,"ntokens":11}],"vertices":[{"line":6,"start":2,"end":33,"ntokens":9},{"line":1,"start":0,"end":23,"ntokens":7},{"line":2,"start":2,"end":34,"ntokens":9},{"line":3,"start":2,"end":7,"ntokens":1},{"line":5,"start":2,"end":7,"ntokens":1},{"line":6,"start":2,"end":8,"ntokens":2},{"line":5,"start":2,"end":7,"ntokens":1},{"line":6,"start":2,"end":33,"ntokens":9},{"line":5,"start":2,"end":7,"ntokens":1},{"line":10,"start":0,"end":33,"ntokens":13}]},"source":"WITH RECURSIVE\\nclosure(source, target) AS (\\n  SELECT source, source FROM graph\\n  UNION\\n  SELECT source, target FROM graph\\n  UNION\\n  SELECT edge.source, path.target\\n  FROM closure as path JOIN graph as edge\\n  ON edge.target = path.source\\n)\\nSELECT S.target FROM closure as S\\nJOIN query ON S.source = query.source","author":"scott","implementation":"","ntokens":104,"category":"Graphs","language_name":"SQL - SQLite","task_name":"Reflexive-transitive closure","token_zscore":-0.902628546,"plan_overlap":5},{"task":"reachable","language":"python-imperative","plan":{"graph":[{"line":1,"start":2,"end":36,"ntokens":8},{"line":2,"start":2,"end":20,"ntokens":8},{"line":3,"start":4,"end":57,"ntokens":13}],"edge_match":[{"line":13,"start":4,"end":44,"ntokens":11},{"line":14,"start":6,"end":28,"ntokens":6}],"edge_sequence":[{"line":13,"start":20,"end":34,"ntokens":2}],"vertices":[{"line":7,"start":2,"end":26,"ntokens":8},{"line":6,"start":2,"end":17,"ntokens":7},{"line":9,"start":2,"end":26,"ntokens":11},{"line":15,"start":4,"end":24,"ntokens":6},{"line":10,"start":4,"end":28,"ntokens":9},{"line":11,"start":4,"end":26,"ntokens":8},{"line":12,"start":6,"end":14,"ntokens":1}],"source":[{"line":7,"start":18,"end":24,"ntokens":2},{"line":4,"start":2,"end":29,"ntokens":11}]},"source":"def reachable(graph, query):\\n  adjacency_list = defaultdict(list)\\n  for edge in graph:\\n    adjacency_list[edge[\\"source\\"]].append(edge[\\"target\\"])\\n  source = query[0][\\"source\\"]\\n\\n  visited = set()\\n  to_visit = set([source])\\n    \\n  while len(to_visit) > 0:\\n    current = to_visit.pop()\\n    if current in visited:\\n      continue\\n    for neighbor in adjacency_list[current]:\\n      to_visit.add(neighbor)\\n    visited.add(current)\\n            \\n  return list(visited)","author":"scott","implementation":"","ntokens":139,"category":"Graphs","language_name":"Python - Imperative","task_name":"Reflexive-transitive closure","token_zscore":0.8331955809,"plan_overlap":4},{"task":"reachable","language":"python-functional","plan":{"edge_match":[{"line":6,"start":6,"end":33,"ntokens":10}],"edge_sequence":[{"line":5,"start":6,"end":23,"ntokens":7}],"vertices":[{"line":10,"start":2,"end":16,"ntokens":10},{"line":11,"start":4,"end":15,"ntokens":8},{"line":12,"start":4,"end":43,"ntokens":21},{"line":15,"start":14,"end":22,"ntokens":4},{"line":8,"start":4,"end":34,"ntokens":8},{"line":3,"start":6,"end":20,"ntokens":4},{"line":4,"start":6,"end":27,"ntokens":7},{"line":2,"start":4,"end":20,"ntokens":6}],"source":[{"line":14,"start":2,"end":29,"ntokens":11},{"line":15,"start":24,"end":37,"ntokens":4}]},"source":"def reachable(graph, query):\\n  def step(visited):\\n    frontier = set([\\n      edge[\\"target\\"]\\n      for vertex in visited\\n      for edge in graph\\n      if vertex == edge[\\"source\\"]\\n    ])\\n    return frontier.union(visited)\\n\\n  def fix(f, x):\\n    next = f(x)\\n    return x if next == x else fix(f, next)\\n\\n  source = query[0][\\"source\\"]\\n  return list(fix(step, set([source])))","author":"scott","implementation":"","ntokens":136,"category":"Graphs","language_name":"Python - Functional","task_name":"Reflexive-transitive closure","token_zscore":0.6844106557,"plan_overlap":3},{"task":"reachable","language":"datalog","plan":{"graph":[],"source":[{"line":3,"start":0,"end":35,"ntokens":12},{"line":4,"start":0,"end":47,"ntokens":21}],"vertices":[{"line":4,"start":44,"end":45,"ntokens":1},{"line":0,"start":11,"end":31,"ntokens":1},{"line":4,"start":44,"end":45,"ntokens":1},{"line":1,"start":0,"end":26,"ntokens":18},{"line":2,"start":0,"end":38,"ntokens":27},{"line":4,"start":44,"end":45,"ntokens":1},{"line":4,"start":10,"end":11,"ntokens":1}],"edge_match":[{"line":2,"start":23,"end":24,"ntokens":1},{"line":2,"start":32,"end":33,"ntokens":1}],"edge_sequence":[{"line":1,"start":14,"end":25,"ntokens":8},{"line":2,"start":14,"end":37,"ntokens":16}]},"source":".decl path(x: symbol, y: symbol)\\npath(x, y) :- graph(x, y).\\npath(x, y) :- graph(x, z), path(z, y).\\nreachable(source) :- query(source).\\nreachable(x) :- query(source), path(source, x).","author":"scott","implementation":"","ntokens":92,"category":"Graphs","language_name":"Datalog - Souffle","task_name":"Reflexive-transitive closure","token_zscore":-1.4977682466,"plan_overlap":4},{"task":"reachable","language":"q","plan":{"graph":[{"line":0,"start":0,"end":27,"ntokens":12},{"line":1,"start":0,"end":51,"ntokens":18},{"line":2,"start":0,"end":31,"ntokens":11},{"line":3,"start":0,"end":12,"ntokens":5},{"line":4,"start":2,"end":66,"ntokens":30}],"source":[{"line":6,"start":0,"end":48,"ntokens":19},{"line":7,"start":0,"end":49,"ntokens":14}],"edge_sequence":[{"line":5,"start":0,"end":62,"ntokens":30}],"vertices":[{"line":5,"start":0,"end":62,"ntokens":30}],"edge_match":[{"line":5,"start":0,"end":62,"ntokens":30}]},"source":"graph: (first\') each graph;\\nnodes: asc distinct graph[`source], graph[`target];\\nadj_list: `source xgroup graph;\\nadj_matrix: \\n  {in[;x] each nodes} each nodes ,\' (adj_list each nodes) `target;\\niterated_matrix: last ({x | any each (x *\\\\: x)} \\\\) adj_matrix;\\nquery_idx: nodes ? (first first query[`source]);\\nreachable: nodes where iterated_matrix[query_idx]","author":"scott","implementation":"","ntokens":140,"category":"Graphs","language_name":"Q - kdb+","task_name":"Reflexive-transitive closure","token_zscore":0.882790556,"plan_overlap":3},{"task":"rolling_average","language":"sql","plan":{"windows":[{"line":2,"start":0,"end":16,"ntokens":7},{"line":0,"start":0,"end":6,"ntokens":1},{"line":1,"start":0,"end":21,"ntokens":8}],"group":[{"line":3,"start":0,"end":18,"ntokens":7},{"line":4,"start":0,"end":29,"ntokens":13},{"line":5,"start":3,"end":28,"ntokens":13},{"line":6,"start":0,"end":17,"ntokens":7}],"filter":[{"line":1,"start":23,"end":46,"ntokens":10}]},"source":"SELECT\\nend.time as end_time,  AVG(other.x) as average\\nFROM data as end\\nJOIN data as other\\nON other.time <= end.time and\\n   other.time > end.time - 7\\nGROUP BY end.time","author":"scott","implementation":"","ntokens":67,"category":"Time Series","language_name":"SQL - SQLite","task_name":"Rolling average","token_zscore":-1.1851343832,"plan_overlap":1},{"task":"rolling_average","language":"python-imperative","plan":{"windows":[{"line":3,"start":2,"end":34,"ntokens":14},{"line":2,"start":2,"end":13,"ntokens":6},{"line":10,"start":4,"end":18,"ntokens":4},{"line":11,"start":6,"end":23,"ntokens":6},{"line":14,"start":2,"end":15,"ntokens":3}],"group":[{"line":6,"start":4,"end":30,"ntokens":19},{"line":7,"start":6,"end":36,"ntokens":18},{"line":8,"start":8,"end":13,"ntokens":1},{"line":1,"start":2,"end":36,"ntokens":15},{"line":4,"start":4,"end":23,"ntokens":8}],"filter":[{"line":9,"start":6,"end":39,"ntokens":18},{"line":5,"start":4,"end":25,"ntokens":11},{"line":12,"start":7,"end":31,"ntokens":9}]},"source":"def rolling_average(data):\\n  data.sort(key=lambda v: v[\\"time\\"])\\n  result = []\\n  for i, value in enumerate(data):\\n    end = value[\\"time\\"]\\n    total, count = 0.0, 0\\n    for j in range(i, -1, -1):\\n      if data[j][\\"time\\"] <= end - 7:\\n        break\\n      total += data[j][\\"x\\"]; count += 1\\n    result.append(\\n      {\\"end_time\\": end,\\n       \\"average\\": total / count}\\n    )\\n  return result","author":"scott","implementation":"","ntokens":154,"category":"Time Series","language_name":"Python - Imperative","task_name":"Rolling average","token_zscore":1.6341892081,"plan_overlap":3},{"task":"rolling_average","language":"python-functional","plan":{"filter":[{"line":3,"start":5,"end":34,"ntokens":14}],"windows":[{"line":4,"start":4,"end":17,"ntokens":7},{"line":1,"start":2,"end":10,"ntokens":3},{"line":2,"start":4,"end":27,"ntokens":9}],"group":[{"line":6,"start":7,"end":27,"ntokens":12},{"line":7,"start":14,"end":43,"ntokens":15},{"line":8,"start":17,"end":42,"ntokens":16},{"line":5,"start":8,"end":10,"ntokens":2}]},"source":"def rolling_average(data):\\n  return [\\n    {\\"end_time\\": x[\\"time\\"],\\n     \\"average\\": sum(vs) / len(vs)}\\n    for x in data\\n    for vs in [\\n      [y[\\"x\\"] for y in data\\n              if y[\\"time\\"] <= x[\\"time\\"] and\\n                 y[\\"time\\"] > x[\\"time\\"] - 7]\\n    ]\\n  ]","author":"scott","implementation":"","ntokens":103,"category":"Time Series","language_name":"Python - Functional","task_name":"Rolling average","token_zscore":-0.0185177247,"plan_overlap":1},{"task":"rolling_average","language":"python-pandas","plan":{"filter":[{"line":5,"start":36,"end":42,"ntokens":3},{"line":9,"start":5,"end":37,"ntokens":11}],"group":[{"line":5,"start":15,"end":35,"ntokens":7},{"line":3,"start":2,"end":47,"ntokens":20}],"windows":[{"line":4,"start":2,"end":52,"ntokens":16},{"line":1,"start":2,"end":17,"ntokens":9},{"line":7,"start":2,"end":32,"ntokens":8},{"line":8,"start":4,"end":58,"ntokens":17}]},"source":"def rolling_average(data):\\n  d = data.copy()\\n\\n  data.time = pd.to_datetime(data.time * 10**9)\\n  data = (data.sort_values(\'time\').set_index(\'time\')\\n              .rolling(window=\'7s\').mean())\\n\\n  return pd.DataFrame.from_dict(\\n    {\'end_time\': d.sort_values(\'time\').reset_index().time,\\n     \'average\': data.reset_index().x}\\n  )","author":"scott","implementation":"","ntokens":108,"category":"Time Series","language_name":"Python - Pandas","task_name":"Rolling average","token_zscore":0.1435123667,"plan_overlap":2},{"task":"rolling_average","language":"datalog","plan":{"group":[{"line":0,"start":0,"end":44,"ntokens":14},{"line":1,"start":0,"end":22,"ntokens":9},{"line":2,"start":2,"end":32,"ntokens":16},{"line":3,"start":2,"end":34,"ntokens":1},{"line":6,"start":31,"end":50,"ntokens":8},{"line":7,"start":31,"end":50,"ntokens":8}],"filter":[{"line":6,"start":2,"end":15,"ntokens":1},{"line":7,"start":6,"end":15,"ntokens":1},{"line":8,"start":0,"end":31,"ntokens":9},{"line":9,"start":2,"end":44,"ntokens":13},{"line":7,"start":52,"end":59,"ntokens":1}],"windows":[{"line":5,"start":30,"end":47,"ntokens":8},{"line":9,"start":2,"end":17,"ntokens":4},{"line":4,"start":0,"end":54,"ntokens":20},{"line":5,"start":0,"end":26,"ntokens":11},{"line":6,"start":19,"end":29,"ntokens":8},{"line":7,"start":19,"end":29,"ntokens":8}]},"source":".decl window(end_time: number, time: number)\\nwindow(end_time, t) :-\\n  data(end_time, _), data(t, _),\\n  t <= end_time, t > end_time - 7.\\n.decl bucket(end_time: number, total: float, n: float)\\nbucket(end_time, total, n) :- data(end_time, _),\\n  total = sum v : {data(t, v), window(end_time, t)},\\n      n = sum z : {data(t, _), window(end_time, t), z = 1.0}.\\nrolling_average(end_time, v) :-\\n  bucket(end_time, total, n), v = total / n.","author":"scott","implementation":"","ntokens":139,"category":"Time Series","language_name":"Datalog - Souffle","task_name":"Rolling average","token_zscore":1.1480989337,"plan_overlap":3},{"task":"rolling_average","language":"r","plan":{"group":[{"line":3,"start":59,"end":72,"ntokens":7},{"line":3,"start":10,"end":47,"ntokens":12}],"filter":[{"line":3,"start":48,"end":59,"ntokens":7},{"line":3,"start":2,"end":10,"ntokens":5},{"line":4,"start":35,"end":49,"ntokens":6},{"line":4,"start":72,"end":79,"ntokens":2}]},"source":"library(slider)\\nrolling_average <- function(data) {\\n  data <- arrange(data, time)\\n  avgs <- unlist(slide_index(data$x, data$time, ~ mean(.x), .before = 6))\\n  data %>% mutate(end_time = time, average = avgs) %>% select(end_time, average)\\n}","author":"scott","implementation":"","ntokens":84,"category":"Time Series","language_name":"R - Tidyverse","task_name":"Rolling average","token_zscore":-0.6342320723,"plan_overlap":1},{"task":"rolling_average","language":"q","plan":{"filter":[{"line":1,"start":15,"end":21,"ntokens":5},{"line":3,"start":25,"end":48,"ntokens":10},{"line":1,"start":8,"end":15,"ntokens":3}],"group":[{"line":1,"start":22,"end":61,"ntokens":21}],"windows":[{"line":3,"start":49,"end":58,"ntokens":3},{"line":3,"start":2,"end":23,"ntokens":8}]},"source":"get_avg: \\n  {[t] (select avg(x) from data where time within (t - 6; t)) `x};\\nrolling_average: \\n  select end_time: time, average: get_avg\'[time] from data","author":"scott","implementation":"","ntokens":70,"category":"Time Series","language_name":"Q - kdb+","task_name":"Rolling average","token_zscore":-1.0879163283,"plan_overlap":2},{"task":"row_per_child","language":"python-pandas","plan":{"each-family":[{"line":2,"start":4,"end":12,"ntokens":2}],"child-ID":[{"line":7,"start":2,"end":48,"ntokens":23}],"family-ID":[{"line":5,"start":4,"end":14,"ntokens":4}],"each-child":[{"line":6,"start":4,"end":13,"ntokens":4},{"line":4,"start":4,"end":17,"ntokens":5},{"line":1,"start":7,"end":23,"ntokens":4}],"dob-height":[{"line":3,"start":4,"end":32,"ntokens":10}]},"source":"def row_per_child(families):\\n  df = pd.wide_to_long(\\n    families, \\n    stubnames=[\'dob\', \'height\'], \\n    sep=\\"_child\\", \\n    i=\'family\', \\n    j=\'child\').reset_index()\\n  df.child = df.child.map(lambda c: f\'child{c}\')\\n  return df","author":"will","implementation":"","ntokens":80,"category":"Joins","language_name":"Python - Pandas","task_name":"Row per family to row per child","token_zscore":-0.5085019875,"plan_overlap":3},{"task":"row_per_child","language":"sql","plan":{"child-ID":[{"line":2,"start":2,"end":30,"ntokens":10}],"dob-height":[{"line":3,"start":2,"end":14,"ntokens":5},{"line":4,"start":4,"end":27,"ntokens":8},{"line":5,"start":4,"end":27,"ntokens":8},{"line":6,"start":4,"end":27,"ntokens":8},{"line":7,"start":3,"end":15,"ntokens":7},{"line":8,"start":2,"end":14,"ntokens":5},{"line":9,"start":4,"end":30,"ntokens":8},{"line":10,"start":4,"end":30,"ntokens":8},{"line":11,"start":4,"end":30,"ntokens":8},{"line":12,"start":3,"end":17,"ntokens":6}],"each-family":[{"line":13,"start":0,"end":5,"ntokens":2},{"line":14,"start":2,"end":10,"ntokens":1}],"each-child":[{"line":15,"start":2,"end":12,"ntokens":3},{"line":16,"start":2,"end":43,"ntokens":20}],"family-ID":[{"line":1,"start":2,"end":8,"ntokens":2}]},"source":"SELECT \\n  family,\\n  (\'child\' || child) AS child,\\n  (CASE child \\n    WHEN 1 THEN dob_child1 \\n    WHEN 2 THEN dob_child2 \\n    WHEN 3 THEN dob_child3 \\n   END) AS dob,\\n  (CASE child \\n    WHEN 1 THEN height_child1 \\n    WHEN 2 THEN height_child2 \\n    WHEN 3 THEN height_child3 \\n   END) AS height\\nFROM \\n  families\\n  CROSS JOIN\\n  (SELECT 1 as child UNION VALUES (2), (3))","author":"will","implementation":"","ntokens":126,"category":"Joins","language_name":"SQL - SQLite","task_name":"Row per family to row per child","token_zscore":1.2333877996,"plan_overlap":0},{"task":"row_per_child","language":"datalog","plan":{"each-family":[{"line":1,"start":2,"end":11,"ntokens":3},{"line":1,"start":42,"end":43,"ntokens":1},{"line":3,"start":2,"end":11,"ntokens":3},{"line":3,"start":42,"end":43,"ntokens":1},{"line":5,"start":2,"end":11,"ntokens":3},{"line":5,"start":42,"end":43,"ntokens":1}],"each-child":[{"line":0,"start":0,"end":47,"ntokens":17},{"line":2,"start":0,"end":47,"ntokens":17},{"line":4,"start":0,"end":47,"ntokens":17}],"family-ID":[{"line":1,"start":22,"end":28,"ntokens":1},{"line":3,"start":22,"end":28,"ntokens":1},{"line":5,"start":22,"end":28,"ntokens":1}],"child-ID":[{"line":0,"start":14,"end":22,"ntokens":1},{"line":2,"start":14,"end":22,"ntokens":1},{"line":4,"start":14,"end":22,"ntokens":1}],"dob-height":[{"line":1,"start":11,"end":14,"ntokens":1},{"line":1,"start":30,"end":36,"ntokens":1},{"line":3,"start":14,"end":17,"ntokens":1},{"line":3,"start":33,"end":39,"ntokens":1},{"line":5,"start":17,"end":20,"ntokens":1},{"line":5,"start":36,"end":42,"ntokens":1}]},"source":"row_per_child(\\"child1\\", dob, family, height) :-\\n  families(dob, _, _, family, height, _, _).\\nrow_per_child(\\"child2\\", dob, family, height) :-\\n  families(_, dob, _, family, _, height, _).\\nrow_per_child(\\"child3\\", dob, family, height) :-\\n  families(_, _, dob, family, _, _, height).","author":"will","implementation":"","ntokens":123,"category":"Joins","language_name":"Datalog - Souffle","task_name":"Row per family to row per child","token_zscore":1.1197862917,"plan_overlap":10},{"task":"row_per_child","language":"q","plan":{"each-family":[{"line":1,"start":8,"end":28,"ntokens":13},{"line":2,"start":63,"end":64,"ntokens":2}],"each-child":[{"line":5,"start":15,"end":51,"ntokens":19},{"line":0,"start":0,"end":20,"ntokens":9},{"line":3,"start":66,"end":67,"ntokens":1}],"family-ID":[{"line":2,"start":5,"end":13,"ntokens":3}],"dob-height":[{"line":2,"start":14,"end":62,"ntokens":17}],"child-ID":[{"line":3,"start":2,"end":66,"ntokens":24}]},"source":"child_rows: {[child] \\n  rows: ?[families; (); 0b; `family`dob`height ! \\n    (`family; `$(\\"dob_child\\",child); `$(\\"height_child\\", child))];\\n  update child: (count families)#enlist (\\"child\\", child) from rows}\\n      \\nrow_per_child: (child_rows each (\\"1\\"; \\"2\\"; \\"3\\")) ,/;","author":"will","implementation":"","ntokens":104,"category":"Joins","language_name":"Q - kdb+","task_name":"Row per family to row per child","token_zscore":0.4003100753,"plan_overlap":6},{"task":"row_per_child","language":"python-functional","plan":{"each-family":[{"line":6,"start":4,"end":26,"ntokens":8}],"each-child":[{"line":7,"start":4,"end":22,"ntokens":15}],"family-ID":[{"line":2,"start":5,"end":32,"ntokens":8}],"child-ID":[{"line":3,"start":5,"end":26,"ntokens":9}],"dob-height":[{"line":4,"start":5,"end":36,"ntokens":12},{"line":5,"start":5,"end":41,"ntokens":11}]},"source":"def row_per_child(families):\\n  return [\\n    {\'family\': family[\'family\'],\\n     \'child\': f\'child{i}\',\\n     \'dob\': family[f\'dob_child{i}\'],\\n     \'height\': family[f\'height_child{i}\']}\\n    for family in families    \\n    for i in [1, 2, 3]\\n  ]","author":"will","implementation":"","ntokens":83,"category":"Joins","language_name":"Python - Functional","task_name":"Row per family to row per child","token_zscore":-0.3949004797,"plan_overlap":0},{"task":"row_per_child","language":"python-imperative","plan":{"each-family":[{"line":3,"start":2,"end":25,"ntokens":8}],"family-ID":[{"line":6,"start":8,"end":35,"ntokens":8}],"each-child":[{"line":4,"start":4,"end":23,"ntokens":16},{"line":5,"start":6,"end":23,"ntokens":4},{"line":10,"start":6,"end":8,"ntokens":1}],"child-ID":[{"line":7,"start":8,"end":29,"ntokens":9}],"dob-height":[{"line":8,"start":8,"end":39,"ntokens":12},{"line":9,"start":8,"end":44,"ntokens":11}]},"source":"\\ndef row_per_child(families):\\n  children = []\\n  for family in families:\\n    for i in [1, 2, 3]:\\n      children.append({\\n        \'family\': family[\'family\'],\\n        \'child\': f\'child{i}\',\\n        \'dob\': family[f\'dob_child{i}\'],\\n        \'height\': family[f\'height_child{i}\']\\n      })\\n  return children\\n","author":"will","implementation":"","ntokens":95,"category":"Joins","language_name":"Python - Imperative","task_name":"Row per family to row per child","token_zscore":0.0595055517,"plan_overlap":3},{"task":"row_per_child","language":"r","plan":{"each-family":[{"line":1,"start":2,"end":14,"ntokens":3}],"family-ID":[{"line":3,"start":6,"end":13,"ntokens":3}],"each-child":[{"line":4,"start":6,"end":38,"ntokens":11},{"line":5,"start":6,"end":22,"ntokens":6}],"child-ID":[{"line":2,"start":4,"end":17,"ntokens":2},{"line":6,"start":4,"end":5,"ntokens":1}],"dob-height":[{"line":2,"start":4,"end":17,"ntokens":2},{"line":6,"start":4,"end":5,"ntokens":1}]},"source":"row_per_child <- function(families) {\\n  families %>%\\n    pivot_longer(\\n      !family,\\n      names_to = c(\\".value\\", \\"child\\"),\\n      names_sep = \\"_\\",\\n    )\\n}","author":"will","implementation":"","ntokens":43,"category":"Joins","language_name":"R - Tidyverse","task_name":"Row per family to row per child","token_zscore":-1.9095872511,"plan_overlap":5},{"task":"scc","language":"sql","plan":{"vertices":[{"line":1,"start":0,"end":23,"ntokens":7}],"edge_match":[{"line":6,"start":2,"end":30,"ntokens":11}],"edge_sequence":[{"line":4,"start":2,"end":33,"ntokens":9},{"line":5,"start":2,"end":41,"ntokens":15}],"source<->target":[{"line":11,"start":2,"end":62,"ntokens":23},{"line":10,"start":2,"end":44,"ntokens":15},{"line":14,"start":0,"end":33,"ntokens":15},{"line":8,"start":0,"end":22,"ntokens":10},{"line":9,"start":2,"end":33,"ntokens":9},{"line":13,"start":0,"end":31,"ntokens":13}],"graph":[{"line":2,"start":2,"end":43,"ntokens":11}]},"source":"WITH RECURSIVE\\nclosure(source, target) AS (\\n  SELECT DISTINCT source, target FROM graph\\n  UNION\\n  SELECT edge.source, path.target\\n  FROM closure as path JOIN graph as edge\\n  ON edge.target = path.source\\n),\\ncomponent(v1, v2) AS (\\n  SELECT path.source, path.target\\n  FROM closure as path JOIN closure as path_\\n  ON path.source = path_.target AND path.target = path_.source\\n)\\nSELECT S.v2 FROM component as S\\nJOIN query ON S.v1 = query.source","author":"scott","implementation":"","ntokens":156,"category":"Graphs","language_name":"SQL - SQLite","task_name":"Strongly-connected components","token_zscore":-1.2652484068,"plan_overlap":0},{"task":"scc","language":"python-imperative","plan":{"graph":[{"line":2,"start":2,"end":18,"ntokens":7},{"line":5,"start":4,"end":32,"ntokens":8},{"line":6,"start":4,"end":32,"ntokens":8},{"line":3,"start":2,"end":20,"ntokens":8},{"line":4,"start":4,"end":51,"ntokens":14},{"line":18,"start":2,"end":25,"ntokens":8}],"source<->target":[{"line":19,"start":4,"end":41,"ntokens":14},{"line":20,"start":8,"end":39,"ntokens":12},{"line":16,"start":2,"end":29,"ntokens":11},{"line":17,"start":2,"end":13,"ntokens":6},{"line":22,"start":2,"end":15,"ntokens":3},{"line":21,"start":6,"end":27,"ntokens":6}],"vertices":[{"line":1,"start":2,"end":19,"ntokens":7},{"line":12,"start":8,"end":53,"ntokens":17},{"line":13,"start":12,"end":55,"ntokens":17},{"line":14,"start":10,"end":24,"ntokens":5},{"line":15,"start":10,"end":49,"ntokens":12},{"line":8,"start":2,"end":16,"ntokens":4},{"line":9,"start":4,"end":19,"ntokens":5},{"line":21,"start":9,"end":9,"ntokens":1},{"line":7,"start":0,"end":16,"ntokens":6}],"edge_sequence":[{"line":10,"start":4,"end":22,"ntokens":8},{"line":11,"start":6,"end":29,"ntokens":8}]},"source":"def scc(graph, query):\\n  reachable = set()\\n  vertices = set()\\n  for edge in graph:\\n    reachable.add((edge[\\"source\\"], edge[\\"target\\"]))\\n    vertices.add(edge[\\"source\\"])\\n    vertices.add(edge[\\"target\\"])\\n  changed = True\\n  while changed:\\n    changed = False\\n    for edge in graph:\\n      for vertex in vertices:\\n        if ((edge[\\"source\\"], vertex) not in reachable\\n            and (edge[\\"target\\"], vertex) in reachable):\\n          changed = True\\n          reachable.add((edge[\\"source\\"], vertex))\\n  source = query[0][\\"source\\"]\\n  result = []\\n  for vertex in vertices:\\n    if ((source, vertex) in reachable and\\n        (vertex, source) in reachable):\\n      result.append(vertex)\\n  return result","author":"scott","implementation":"","ntokens":225,"category":"Graphs","language_name":"Python - Imperative","task_name":"Strongly-connected components","token_zscore":1.2114080491,"plan_overlap":5},{"task":"scc","language":"python-functional","plan":{"source<->target":[{"line":13,"start":4,"end":31,"ntokens":11},{"line":16,"start":4,"end":46,"ntokens":20},{"line":17,"start":6,"end":65,"ntokens":26}],"edge_sequence":[{"line":4,"start":12,"end":44,"ntokens":12},{"line":5,"start":12,"end":29,"ntokens":7}],"edge_match":[{"line":6,"start":12,"end":39,"ntokens":10}],"vertices":[{"line":1,"start":4,"end":23,"ntokens":7},{"line":2,"start":8,"end":20,"ntokens":4},{"line":3,"start":12,"end":36,"ntokens":8},{"line":9,"start":4,"end":18,"ntokens":10},{"line":10,"start":8,"end":19,"ntokens":8},{"line":11,"start":8,"end":47,"ntokens":21},{"line":15,"start":4,"end":31,"ntokens":11},{"line":7,"start":8,"end":26,"ntokens":6}],"graph":[{"line":14,"start":4,"end":68,"ntokens":25}]},"source":"def scc(graph, query):\\n    def step(relation):\\n        return set([\\n            (source, edge[\\"target\\"])\\n            for (source, target) in relation\\n            for edge in graph\\n            if target == edge[\\"source\\"]\\n        ]).union(relation)\\n\\n    def fix(f, x):\\n        next = f(x)\\n        return x if next == x else fix(f, next)\\n\\n    source = query[0][\\"source\\"]\\n    init = set([(edge[\\"source\\"], edge[\\"target\\"]) for edge in graph])\\n    reachable = fix(step, init)\\n    return list(set([v for (_, v) in reachable\\n      if (v, source) in reachable and (source, v) in reachable]))","author":"scott","implementation":"","ntokens":211,"category":"Graphs","language_name":"Python - Functional","task_name":"Strongly-connected components","token_zscore":0.7088980435,"plan_overlap":5},{"task":"scc","language":"datalog","plan":{"edge_match":[{"line":8,"start":31,"end":32,"ntokens":0},{"line":5,"start":22,"end":22,"ntokens":1},{"line":5,"start":31,"end":31,"ntokens":1},{"line":5,"start":22,"end":23,"ntokens":1},{"line":5,"start":31,"end":32,"ntokens":1}],"edge_sequence":[{"line":4,"start":14,"end":25,"ntokens":8},{"line":5,"start":13,"end":36,"ntokens":16}],"graph":[{"line":10,"start":0,"end":26,"ntokens":0},{"line":7,"start":0,"end":26,"ntokens":15},{"line":8,"start":0,"end":26,"ntokens":15},{"line":6,"start":0,"end":23,"ntokens":8}],"source<->target":[{"line":0,"start":0,"end":32,"ntokens":14},{"line":1,"start":0,"end":24,"ntokens":15},{"line":2,"start":0,"end":37,"ntokens":27},{"line":9,"start":0,"end":35,"ntokens":21}],"vertices":[{"line":3,"start":0,"end":32,"ntokens":14},{"line":4,"start":0,"end":26,"ntokens":18},{"line":5,"start":0,"end":37,"ntokens":26}]},"source":".decl scc1(x: symbol, y: symbol)\\nscc1(x, x) :- vertex(x).\\nscc1(x, y) :- path(x, y), path(y, x).\\n.decl path(x: symbol, y: symbol)\\npath(x, y) :- graph(x, y).\\npath(x,y) :- graph(x, z), path(z, y).\\n.decl vertex(x: symbol)\\nvertex(x)  :- graph(x, _).\\nvertex(x)  :- graph(_, x).\\nscc(x) :- query(src), scc1(src, x).","author":"scott","implementation":"","ntokens":173,"category":"Graphs","language_name":"Datalog - Souffle","task_name":"Strongly-connected components","token_zscore":-0.6550576858,"plan_overlap":8},{"task":"strings_to_numbers","language":"python-pandas","plan":{"cond":[{"line":2,"start":4,"end":51,"ntokens":19}],"clean":[{"line":3,"start":15,"end":41,"ntokens":11}],"number":[{"line":3,"start":41,"end":42,"ntokens":1},{"line":3,"start":4,"end":15,"ntokens":5}],"iter":[{"line":4,"start":9,"end":48,"ntokens":15}]},"source":"def strings_to_numbers(numbers):\\n  def convert(row):\\n    sep = \\",\\" if row.format == \'comma_sep\' else \\"_\\"\\n    return int(row.value.replace(sep, \\"\\"))\\n  return numbers.apply(convert, axis=1).tolist()","author":"will","implementation":"","ntokens":69,"category":"Strings","language_name":"Python - Pandas","task_name":"Convert strings with different formats to numbers","token_zscore":-0.0782192712,"plan_overlap":1},{"task":"strings_to_numbers","language":"sql","plan":{"cond":[{"line":1,"start":8,"end":19,"ntokens":0},{"line":4,"start":6,"end":18,"ntokens":4},{"line":5,"start":8,"end":34,"ntokens":8},{"line":6,"start":8,"end":34,"ntokens":8},{"line":7,"start":6,"end":9,"ntokens":2}],"clean":[{"line":2,"start":26,"end":49,"ntokens":0},{"line":3,"start":26,"end":49,"ntokens":0},{"line":2,"start":4,"end":12,"ntokens":2},{"line":3,"start":6,"end":13,"ntokens":2},{"line":7,"start":9,"end":14,"ntokens":3}],"number":[{"line":1,"start":2,"end":7,"ntokens":2},{"line":8,"start":4,"end":15,"ntokens":4}],"iter":[{"line":9,"start":0,"end":12,"ntokens":3}]},"source":"SELECT \\n  CAST(\\n    REPLACE(\\n      value, \\n      CASE format \\n        WHEN \\"comma_sep\\" THEN \\",\\" \\n        WHEN \\"under_sep\\" THEN \\"_\\" \\n      END, \\"\\")\\n    AS integer)\\nFROM numbers","author":"will","implementation":"","ntokens":47,"category":"Strings","language_name":"SQL - SQLite","task_name":"Convert strings with different formats to numbers","token_zscore":-0.8310797564,"plan_overlap":3},{"task":"strings_to_numbers","language":"datalog","plan":{"number":[{"line":13,"start":2,"end":22,"ntokens":6}],"cond":[{"line":6,"start":2,"end":37,"ntokens":1},{"line":7,"start":3,"end":38,"ntokens":1},{"line":1,"start":0,"end":28,"ntokens":16}],"clean":[{"line":2,"start":0,"end":32,"ntokens":17},{"line":3,"start":2,"end":34,"ntokens":14},{"line":4,"start":2,"end":19,"ntokens":6},{"line":5,"start":2,"end":26,"ntokens":12},{"line":8,"start":2,"end":33,"ntokens":1},{"line":9,"start":3,"end":44,"ntokens":9},{"line":12,"start":2,"end":40,"ntokens":17},{"line":0,"start":0,"end":62,"ntokens":23}],"iter":[{"line":1,"start":29,"end":50,"ntokens":8}]},"source":".decl clean(Format:symbol, Inp:symbol, I:number, Outp:symbol) \\nclean(Format, Inp, 0, \\"\\") :- numbers(Format, Inp).\\nclean(Format, Inp, I+1, Outp) :-\\n  clean(Format, Inp, I, Outp_rec),\\n  I <= strlen(Inp),\\n  Chr = substr(Inp, I, 1),\\n  ((Format = \\"comma_sep\\", Sep = \\",\\");\\n   (Format = \\"under_sep\\", Sep = \\"_\\")),\\n  ((Chr  = Sep, Outp = Outp_rec);\\n   (Chr != Sep, Outp = cat(Outp_rec, Chr))).\\n\\nstrings_to_numbers(N) :-\\n  clean(Format, Inp, strlen(Inp), Outp),\\n  N = to_number(Outp).","author":"will","implementation":"","ntokens":139,"category":"Strings","language_name":"Datalog - Souffle","task_name":"Convert strings with different formats to numbers","token_zscore":2.317245909,"plan_overlap":3},{"task":"strings_to_numbers","language":"q","plan":{"cond":[{"line":1,"start":2,"end":56,"ntokens":21}],"clean":[{"line":2,"start":8,"end":25,"ntokens":10}],"number":[{"line":2,"start":2,"end":7,"ntokens":4}],"iter":[{"line":5,"start":2,"end":45,"ntokens":13}]},"source":"convert: {[val; format] \\n  sep: ((\\"comma_sep\\"; \\"under_sep\\") ! (\\",\\"; \\"_\\")) format;\\n  \\"J\\" $ ssr[val; sep; \\"\\"]}\\n  \\nstrings_to_numbers:\\n  convert\'[numbers[`value]; numbers[`format]]","author":"will","implementation":"","ntokens":68,"category":"Strings","language_name":"Q - kdb+","task_name":"Convert strings with different formats to numbers","token_zscore":-0.1124402023,"plan_overlap":0},{"task":"strings_to_numbers","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":10,"ntokens":3},{"line":4,"start":4,"end":30,"ntokens":7},{"line":5,"start":2,"end":3,"ntokens":1}],"number":[{"line":2,"start":4,"end":8,"ntokens":3},{"line":3,"start":55,"end":56,"ntokens":1}],"clean":[{"line":2,"start":8,"end":29,"ntokens":7},{"line":3,"start":50,"end":55,"ntokens":4}],"cond":[{"line":3,"start":6,"end":50,"ntokens":17}]},"source":"def strings_to_numbers(numbers):\\n  return [\\n    int(row[\\"value\\"].replace(\\n      \\",\\" if row[\\"format\\"] == \\"comma_sep\\" else \\"_\\", \\"\\"))\\n    for row in numbers\\n  ]","author":"will","implementation":"","ntokens":52,"category":"Strings","language_name":"Python - Functional","task_name":"Convert strings with different formats to numbers","token_zscore":-0.6599751007,"plan_overlap":6},{"task":"strings_to_numbers","language":"python-imperative","plan":{"iter":[{"line":1,"start":1,"end":13,"ntokens":7},{"line":7,"start":4,"end":18,"ntokens":5},{"line":7,"start":52,"end":53,"ntokens":1},{"line":2,"start":2,"end":21,"ntokens":8}],"cond":[{"line":3,"start":4,"end":36,"ntokens":11},{"line":4,"start":6,"end":15,"ntokens":5},{"line":5,"start":4,"end":9,"ntokens":2},{"line":6,"start":6,"end":15,"ntokens":5}],"number":[{"line":7,"start":18,"end":22,"ntokens":3},{"line":7,"start":51,"end":52,"ntokens":1}],"clean":[{"line":7,"start":22,"end":51,"ntokens":12}]},"source":"def strings_to_numbers(numbers):\\n  output = []\\n  for row in numbers:\\n    if row[\\"format\\"] == \'comma_sep\':\\n      sep = \\",\\"\\n    else:\\n      sep = \\"_\\"\\n    output.append(int(row[\\"value\\"].replace(sep, \\"\\")))\\n  return output","author":"will","implementation":"","ntokens":73,"category":"Strings","language_name":"Python - Imperative","task_name":"Convert strings with different formats to numbers","token_zscore":0.0586644534,"plan_overlap":4},{"task":"strings_to_numbers","language":"r","plan":{"cond":[{"line":3,"start":13,"end":52,"ntokens":13}],"clean":[{"line":2,"start":31,"end":47,"ntokens":2},{"line":3,"start":6,"end":13,"ntokens":3},{"line":3,"start":52,"end":57,"ntokens":3}],"number":[{"line":2,"start":20,"end":31,"ntokens":3},{"line":3,"start":57,"end":58,"ntokens":1}],"iter":[{"line":1,"start":2,"end":13,"ntokens":3},{"line":2,"start":4,"end":20,"ntokens":7},{"line":3,"start":58,"end":63,"ntokens":3},{"line":4,"start":4,"end":16,"ntokens":4}]},"source":"strings_to_numbers <- function(numbers) {\\n  numbers %>%\\n    mutate(output = as.numeric(str_replace_all(\\n      value, ifelse(format == \\"comma_sep\\", \\",\\", \\"_\\"), \\"\\"))) %>%\\n    pull(output)\\n}","author":"will","implementation":"","ntokens":51,"category":"Strings","language_name":"R - Tidyverse","task_name":"Convert strings with different formats to numbers","token_zscore":-0.6941960318,"plan_overlap":6},{"task":"tom_hanks","language":"python-imperative","plan":{"director":[{"line":7,"start":10,"end":40,"ntokens":8},{"line":8,"start":4,"end":22,"ntokens":3},{"line":2,"start":2,"end":21,"ntokens":7},{"line":5,"start":6,"end":25,"ntokens":8}],"actor":[{"line":4,"start":4,"end":33,"ntokens":11},{"line":3,"start":2,"end":18,"ntokens":8}],"movies":[{"line":6,"start":8,"end":36,"ntokens":14}]},"source":"\\ndef tom_hanks(actors,directors):\\n  r_directors = set()\\n  for a in actors:\\n    if \'Tom Hanks\' == a[\'actor\']:\\n      for d in directors:\\n        if a[\'movie\'] == d[\'movie\']:\\n          r_directors.add(d[\'director\'])\\n    return r_directors\\n","author":"g","implementation":"","ntokens":75,"category":"Joins","language_name":"Python - Imperative","task_name":"Directors of movies Tom Hanks starred in","token_zscore":1.4808883095,"plan_overlap":2},{"task":"tom_hanks","language":"python-pandas","plan":{"director":[{"line":4,"start":2,"end":38,"ntokens":9},{"line":5,"start":4,"end":29,"ntokens":7}],"actor":[{"line":3,"start":3,"end":34,"ntokens":10}],"movies":[{"line":3,"start":36,"end":43,"ntokens":2},{"line":4,"start":19,"end":37,"ntokens":5}]},"source":"\\ndef tom_hanks(actors,directors):\\n  movies = list(actors.loc[\\n    actors[\'actor\'] == \'Tom Hanks\', \'movie\'])\\n  return directors[directors[\'movie\'].\\n    isin(movies)][\'director\']\\n","author":"g","implementation":"","ntokens":51,"category":"Joins","language_name":"Python - Pandas","task_name":"Directors of movies Tom Hanks starred in","token_zscore":0.1287728965,"plan_overlap":1},{"task":"tom_hanks","language":"r","plan":{"actor":[{"line":2,"start":4,"end":36,"ntokens":10}],"movies":[{"line":1,"start":2,"end":12,"ntokens":3}],"director":[{"line":3,"start":4,"end":43,"ntokens":12},{"line":4,"start":4,"end":18,"ntokens":4}]},"source":"tom_hanks <- function(actors, directors) {\\n  actors %>%\\n    filter(actor == \\"Tom Hanks\\") %>%\\n    inner_join(directors, by = \\"movie\\") %>%\\n    pull(director)\\n}","author":"g","implementation":"","ntokens":46,"category":"Joins","language_name":"R - Tidyverse","task_name":"Directors of movies Tom Hanks starred in","token_zscore":-0.1529178146,"plan_overlap":0},{"task":"tom_hanks","language":"q","plan":{"actor":[{"line":2,"start":3,"end":30,"ntokens":8}],"director":[{"line":2,"start":32,"end":41,"ntokens":1},{"line":1,"start":3,"end":18,"ntokens":4},{"line":1,"start":31,"end":57,"ntokens":10}],"movies":[{"line":1,"start":19,"end":30,"ntokens":4},{"line":1,"start":35,"end":41,"ntokens":2}]},"source":"tom_hanks:\\n  (select director from actors ij (`movie xkey directors) \\n   where actor ~\\\\: \\"Tom Hanks\\") `director","author":"g","implementation":"","ntokens":35,"category":"Joins","language_name":"Q - kdb+","task_name":"Directors of movies Tom Hanks starred in","token_zscore":-0.7726373789,"plan_overlap":2},{"task":"tom_hanks","language":"sql","plan":{"director":[{"line":1,"start":0,"end":25,"ntokens":5},{"line":2,"start":0,"end":5,"ntokens":2},{"line":3,"start":2,"end":12,"ntokens":2}],"actor":[{"line":7,"start":0,"end":30,"ntokens":7},{"line":4,"start":2,"end":19,"ntokens":5}],"movies":[{"line":5,"start":2,"end":23,"ntokens":8},{"line":6,"start":2,"end":14,"ntokens":3}]},"source":"\\nSELECT directors.director\\nFROM \\n  directors \\n  INNER JOIN actors\\n  ON directors.movie = \\n  actors.movie\\nWHERE actors.actor=\\"Tom Hanks\\"\\n","author":"g","implementation":"","ntokens":36,"category":"Joins","language_name":"SQL - SQLite","task_name":"Directors of movies Tom Hanks starred in","token_zscore":-0.7162992367,"plan_overlap":1},{"task":"tom_hanks","language":"datalog","plan":{"director":[{"line":3,"start":2,"end":28,"ntokens":7},{"line":1,"start":10,"end":18,"ntokens":1}],"actor":[{"line":2,"start":2,"end":28,"ntokens":11}],"movies":[{"line":2,"start":21,"end":26,"ntokens":1},{"line":3,"start":21,"end":26,"ntokens":1}]},"source":"\\ntom_hanks(Director):-\\n  actors(\\"Tom Hanks\\",movie),\\n  directors(Director,movie).\\n","author":"g","implementation":"","ntokens":25,"category":"Joins","language_name":"Datalog - Souffle","task_name":"Directors of movies Tom Hanks starred in","token_zscore":-1.336018801,"plan_overlap":3},{"task":"tom_hanks","language":"python-functional","plan":{"director":[{"line":3,"start":15,"end":47,"ntokens":13},{"line":4,"start":2,"end":18,"ntokens":3},{"line":3,"start":2,"end":19,"ntokens":8}],"actor":[{"line":2,"start":46,"end":71,"ntokens":6},{"line":2,"start":23,"end":71,"ntokens":19}],"movies":[{"line":2,"start":12,"end":22,"ntokens":5},{"line":3,"start":52,"end":75,"ntokens":8},{"line":2,"start":2,"end":19,"ntokens":8}]},"source":"\\ndef tom_hanks(actors,directors):\\n  movies = [a[\'movie\'] for a in actors if a[\'actor\'] == \'Tom Hanks\']\\n  directors = [d[\'director\'] for d in directors if d[\'movie\'] in movies]\\n  return directors\\n","author":"g","implementation":"","ntokens":73,"category":"Joins","language_name":"Python - Functional","task_name":"Directors of movies Tom Hanks starred in","token_zscore":1.3682120251,"plan_overlap":3},{"task":"unique_beer_drinkers","language":"python-pandas","plan":{"iter":[{"line":1,"start":22,"end":27,"ntokens":1},{"line":2,"start":4,"end":20,"ntokens":5},{"line":1,"start":2,"end":22,"ntokens":6},{"line":11,"start":1,"end":37,"ntokens":7},{"line":12,"start":52,"end":53,"ntokens":1},{"line":13,"start":2,"end":38,"ntokens":9}],"collect":[{"line":3,"start":4,"end":27,"ntokens":11},{"line":4,"start":4,"end":18,"ntokens":4},{"line":1,"start":2,"end":22,"ntokens":6}],"compare":[{"line":6,"start":2,"end":28,"ntokens":7},{"line":7,"start":4,"end":36,"ntokens":6},{"line":8,"start":6,"end":43,"ntokens":10},{"line":9,"start":4,"end":55,"ntokens":19},{"line":12,"start":4,"end":52,"ntokens":11}]},"source":"def unique_beer_drinkers(likes):\\n  likes_per_person = (likes\\n    .groupby(\'name\')\\n    .beer.unique().map(set)\\n    .reset_index())\\n\\n  def check_not_exists(row):\\n    other_people = likes_per_person[\\n      likes_per_person.name != row[\'name\']]\\n    return not (other_people.beer == row[\'beer\']).any()\\n  \\n  unique_drinkers = likes_per_person[\\n    likes_per_person.apply(check_not_exists, axis=1)]\\n  return unique_drinkers.name.tolist()","author":"will","implementation":"","ntokens":113,"category":"First-order logic","language_name":"Python - Pandas","task_name":"People who like a unique set of beer","token_zscore":-0.1577771845,"plan_overlap":2},{"task":"unique_beer_drinkers","language":"datalog","plan":{"iter":[{"line":11,"start":21,"end":25,"ntokens":1},{"line":12,"start":2,"end":17,"ntokens":8}],"compare":[{"line":13,"start":2,"end":20,"ntokens":6},{"line":4,"start":0,"end":27,"ntokens":7},{"line":5,"start":0,"end":20,"ntokens":7},{"line":7,"start":2,"end":18,"ntokens":8},{"line":8,"start":2,"end":16,"ntokens":1},{"line":6,"start":2,"end":18,"ntokens":8},{"line":9,"start":2,"end":23,"ntokens":9},{"line":1,"start":0,"end":16,"ntokens":11},{"line":1,"start":30,"end":61,"ntokens":17},{"line":2,"start":0,"end":46,"ntokens":30},{"line":0,"start":0,"end":32,"ntokens":12}],"collect":[{"line":1,"start":16,"end":30,"ntokens":8},{"line":2,"start":46,"end":60,"ntokens":8}]},"source":".decl differ(a:symbol, b:symbol)\\ndiffer(A, B) :- likes(Beer, A), likes(_, B), !likes(Beer, B).\\ndiffer(A, B) :- likes(_, A), likes(Beer, B), !likes(Beer, A).\\n\\n.decl exists_same(a:symbol)\\nexists_same(Name) :- \\n  likes(_, Other), \\n  likes(_, Name), \\n  Name != Other, \\n  !differ(Name, Other).\\n\\nunique_beer_drinkers(Name) :- \\n  likes(_, Name), \\n  !exists_same(Name).","author":"will","implementation":"neg_exist","ntokens":150,"category":"First-order logic","language_name":"Datalog - Souffle","task_name":"People who like a unique set of beer","token_zscore":0.7925551592,"plan_overlap":2},{"task":"unique_beer_drinkers","language":"sql","plan":{"iter":[{"line":0,"start":0,"end":23,"ntokens":7},{"line":1,"start":0,"end":13,"ntokens":5}],"compare":[{"line":2,"start":0,"end":17,"ntokens":6},{"line":23,"start":34,"end":35,"ntokens":1},{"line":3,"start":4,"end":12,"ntokens":2},{"line":4,"start":4,"end":17,"ntokens":5},{"line":5,"start":4,"end":28,"ntokens":11},{"line":6,"start":4,"end":19,"ntokens":6},{"line":7,"start":8,"end":16,"ntokens":2},{"line":8,"start":8,"end":21,"ntokens":5},{"line":9,"start":8,"end":31,"ntokens":11},{"line":10,"start":8,"end":23,"ntokens":6},{"line":14,"start":12,"end":35,"ntokens":12},{"line":15,"start":4,"end":19,"ntokens":6},{"line":19,"start":8,"end":23,"ntokens":6},{"line":20,"start":12,"end":20,"ntokens":2},{"line":21,"start":12,"end":25,"ntokens":5},{"line":22,"start":12,"end":35,"ntokens":11},{"line":23,"start":12,"end":35,"ntokens":11}],"collect":[{"line":11,"start":12,"end":20,"ntokens":2},{"line":12,"start":12,"end":25,"ntokens":5},{"line":13,"start":12,"end":35,"ntokens":11},{"line":16,"start":8,"end":16,"ntokens":2},{"line":17,"start":8,"end":21,"ntokens":5},{"line":18,"start":8,"end":31,"ntokens":11}]},"source":"SELECT DISTINCT L1.name\\nFROM likes L1\\nWHERE NOT EXISTS(\\n    SELECT *\\n    FROM likes L2\\n    WHERE L1.name != L2.name\\n    AND NOT EXISTS(\\n        SELECT *\\n        FROM likes L3\\n        WHERE L3.name = L2.name\\n        AND NOT EXISTS(\\n            SELECT *\\n            FROM likes L4\\n            WHERE L4.name = L1.name\\n            AND L4.beer = L3.beer))\\n    AND NOT EXISTS(\\n        SELECT *\\n        FROM likes L5\\n        WHERE L5.name = L1.name\\n        AND NOT EXISTS(\\n            SELECT *\\n            FROM likes L6\\n            WHERE L6.name = L2.name\\n            AND L6.beer= L5.beer)))","author":"will","implementation":"","ntokens":176,"category":"First-order logic","language_name":"SQL - SQLite","task_name":"People who like a unique set of beer","token_zscore":1.4603562655,"plan_overlap":1},{"task":"unique_beer_drinkers","language":"q","plan":{"collect":[{"line":0,"start":0,"end":37,"ntokens":13}],"compare":[{"line":1,"start":0,"end":42,"ntokens":14},{"line":3,"start":43,"end":68,"ntokens":10}],"iter":[{"line":3,"start":3,"end":42,"ntokens":13},{"line":4,"start":2,"end":7,"ntokens":1}]},"source":"likes_per_person: `name xgroup likes;\\ncounts: count each group likes_per_person;\\nunique_beer_drinkers: \\n  (select name from likes_per_person where beer in\\\\: where[counts=1])\\n  `name","author":"will","implementation":"","ntokens":61,"category":"First-order logic","language_name":"Q - kdb+","task_name":"People who like a unique set of beer","token_zscore":-1.4933793971,"plan_overlap":1},{"task":"unique_beer_drinkers","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":46,"ntokens":19},{"line":4,"start":4,"end":22,"ntokens":7},{"line":5,"start":2,"end":3,"ntokens":1},{"line":2,"start":2,"end":22,"ntokens":5},{"line":3,"start":4,"end":9,"ntokens":3},{"line":7,"start":2,"end":10,"ntokens":3},{"line":8,"start":4,"end":8,"ntokens":1},{"line":9,"start":4,"end":13,"ntokens":5},{"line":9,"start":20,"end":47,"ntokens":7},{"line":14,"start":2,"end":3,"ntokens":1}],"collect":[{"line":3,"start":10,"end":68,"ntokens":26},{"line":9,"start":13,"end":47,"ntokens":10}],"compare":[{"line":10,"start":4,"end":16,"ntokens":6},{"line":11,"start":6,"end":49,"ntokens":13},{"line":12,"start":6,"end":61,"ntokens":14},{"line":13,"start":4,"end":6,"ntokens":1}]},"source":"def unique_beer_drinkers(likes):\\n  people = set([row[\'name\'] for row in likes])\\n  likes_per_person = {\\n    name: set([row[\'beer\'] for row in likes if row[\'name\'] == name])\\n    for name in people\\n  }\\n    \\n  return [\\n    name\\n    for name, beers in likes_per_person.items()\\n    if not any([\\n      other_name != name and beers == other_beers\\n      for other_name, other_beers in likes_per_person.items()\\n    ])\\n  ]","author":"will","implementation":"","ntokens":135,"category":"First-order logic","language_name":"Python - Functional","task_name":"People who like a unique set of beer","token_zscore":0.4072852901,"plan_overlap":2},{"task":"unique_beer_drinkers","language":"python-imperative","plan":{"collect":[{"line":1,"start":21,"end":37,"ntokens":4},{"line":3,"start":33,"end":50,"ntokens":7},{"line":6,"start":10,"end":47,"ntokens":10},{"line":18,"start":2,"end":15,"ntokens":3}],"iter":[{"line":2,"start":2,"end":19,"ntokens":8},{"line":3,"start":4,"end":33,"ntokens":7},{"line":5,"start":2,"end":13,"ntokens":6},{"line":6,"start":2,"end":9,"ntokens":5},{"line":6,"start":19,"end":47,"ntokens":8}],"compare":[{"line":7,"start":4,"end":20,"ntokens":5},{"line":8,"start":4,"end":49,"ntokens":15},{"line":9,"start":6,"end":18,"ntokens":8},{"line":10,"start":8,"end":16,"ntokens":1},{"line":12,"start":6,"end":30,"ntokens":8},{"line":13,"start":8,"end":25,"ntokens":5},{"line":14,"start":8,"end":13,"ntokens":1},{"line":15,"start":4,"end":17,"ntokens":4},{"line":16,"start":6,"end":23,"ntokens":6}]},"source":"def unique_beer_drinkers(likes):\\n  likes_per_person = defaultdict(set)\\n  for row in likes:\\n    likes_per_person[row[\'name\']].add(row[\'beer\'])\\n    \\n  unique = []\\n  for p1, p1_likes in likes_per_person.items():\\n    is_unique = True\\n    for p2, p2_likes in likes_per_person.items():\\n      if p1 == p2:\\n        continue\\n        \\n      if p1_likes == p2_likes:\\n        is_unique = False\\n        break\\n    if is_unique:\\n      unique.append(p1)\\n      \\n  return unique","author":"will","implementation":"","ntokens":131,"category":"First-order logic","language_name":"Python - Imperative","task_name":"People who like a unique set of beer","token_zscore":0.3045466584,"plan_overlap":2},{"task":"unique_beer_drinkers","language":"r","plan":{"iter":[{"line":1,"start":2,"end":11,"ntokens":3},{"line":2,"start":4,"end":22,"ntokens":6},{"line":6,"start":4,"end":14,"ntokens":4}],"collect":[{"line":3,"start":4,"end":54,"ntokens":16}],"compare":[{"line":4,"start":4,"end":54,"ntokens":12},{"line":5,"start":4,"end":37,"ntokens":10}]},"source":"unique_beer_drinkers <- function(likes) {\\n  likes %>%\\n    group_by(name) %>%\\n    summarize(beer_set = list(sort(unique(beer)))) %>%\\n    add_count(beer_set, name = \'num_people_likes\') %>%\\n    filter(num_people_likes == 1) %>%\\n    pull(name)\\n}","author":"will","implementation":"","ntokens":68,"category":"First-order logic","language_name":"R - Tidyverse","task_name":"People who like a unique set of beer","token_zscore":-1.3135867916,"plan_overlap":2},{"task":"youngest_over_35","language":"python-pandas","plan":{"filter":[{"line":1,"start":2,"end":35,"ntokens":14}],"null":[{"line":2,"start":2,"end":24,"ntokens":12},{"line":3,"start":4,"end":15,"ntokens":3},{"line":4,"start":2,"end":7,"ntokens":2}],"min":[{"line":5,"start":4,"end":48,"ntokens":15}],"name":[{"line":6,"start":4,"end":27,"ntokens":6}]},"source":"def youngest_over_35(people):\\n  over_35 = people[people.age > 35]\\n  if len(over_35) == 0: \\n    return None\\n  else:\\n    youngest = over_35.loc[over_35.age.idxmin()]\\n    return youngest[\'name\']","author":"will","implementation":"","ntokens":65,"category":"Aggregation","language_name":"Python - Pandas","task_name":"Youngest person over 35","token_zscore":0.1354268101,"plan_overlap":0},{"task":"youngest_over_35","language":"sql","plan":{"name":[{"line":0,"start":0,"end":11,"ntokens":3}],"min":[{"line":3,"start":2,"end":17,"ntokens":6},{"line":4,"start":2,"end":13,"ntokens":3},{"line":1,"start":0,"end":11,"ntokens":3},{"line":2,"start":0,"end":13,"ntokens":7}],"filter":[{"line":5,"start":2,"end":16,"ntokens":8},{"line":4,"start":2,"end":13,"ntokens":3}]},"source":"SELECT name\\nFROM people\\nWHERE age = (\\n  SELECT MIN(age)\\n  FROM people\\n  WHERE age > 35)\\nLIMIT 1","author":"will","implementation":"","ntokens":36,"category":"Aggregation","language_name":"SQL - SQLite","task_name":"Youngest person over 35","token_zscore":-0.9479876707,"plan_overlap":1},{"task":"youngest_over_35","language":"datalog","plan":{"min":[{"line":2,"start":45,"end":46,"ntokens":1},{"line":2,"start":2,"end":34,"ntokens":9},{"line":1,"start":2,"end":13,"ntokens":5},{"line":1,"start":18,"end":20,"ntokens":1}],"filter":[{"line":2,"start":36,"end":44,"ntokens":1}],"name":[{"line":1,"start":14,"end":18,"ntokens":1},{"line":0,"start":17,"end":21,"ntokens":1}]},"source":"youngest_over_35(Name) :- \\n  people(Age, Name), \\n  Age = min Age : { people(Age, _), Age > 35 }.","author":"will","implementation":"","ntokens":25,"category":"Aggregation","language_name":"Datalog - Souffle","task_name":"Youngest person over 35","token_zscore":-1.3589379909,"plan_overlap":2},{"task":"youngest_over_35","language":"q","plan":{"filter":[{"line":0,"start":0,"end":45,"ntokens":18}],"name":[{"line":2,"start":9,"end":20,"ntokens":4},{"line":2,"start":20,"end":36,"ntokens":6},{"line":2,"start":59,"end":64,"ntokens":1}],"min":[{"line":2,"start":37,"end":57,"ntokens":10}]},"source":"old_enough: select from people where age > 35\\nyoungest_over_35: \\n  (first select name from old_enough where age = min(age)) `name","author":"will","implementation":"","ntokens":50,"category":"Aggregation","language_name":"Q - kdb+","task_name":"Youngest person over 35","token_zscore":-0.4249599903,"plan_overlap":1},{"task":"youngest_over_35","language":"python-functional","plan":{"filter":[{"line":1,"start":2,"end":48,"ntokens":26}],"min":[{"line":2,"start":2,"end":63,"ntokens":25}],"name":[{"line":3,"start":9,"end":25,"ntokens":5}]},"source":"def youngest_over_35(people):\\n  over_35 = [p for p in people if p[\'age\'] > 35]\\n  youngest = min(over_35, default=None, key=lambda p: p[\'age\'])\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":"","ntokens":81,"category":"Aggregation","language_name":"Python - Functional","task_name":"Youngest person over 35","token_zscore":0.7331727305,"plan_overlap":0},{"task":"youngest_over_35","language":"python-imperative","plan":{"filter":[{"line":1,"start":2,"end":14,"ntokens":6},{"line":2,"start":2,"end":23,"ntokens":8},{"line":3,"start":4,"end":26,"ntokens":11},{"line":4,"start":6,"end":28,"ntokens":6}],"min":[{"line":6,"start":2,"end":17,"ntokens":5},{"line":7,"start":2,"end":24,"ntokens":8},{"line":8,"start":4,"end":59,"ntokens":22},{"line":9,"start":6,"end":23,"ntokens":5}],"name":[{"line":10,"start":9,"end":25,"ntokens":5}]},"source":"def youngest_over_35(people):\\n  over_35 = []\\n  for person in people:\\n    if person[\'age\'] > 35:\\n      over_35.append(person)\\n    \\n  youngest = None\\n  for person in over_35:\\n    if youngest is None or person[\'age\'] < youngest[\'age\']:\\n      youngest = person\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":"separate","ntokens":108,"category":"Aggregation","language_name":"Python - Imperative","task_name":"Youngest person over 35","token_zscore":1.7418689712,"plan_overlap":0},{"task":"youngest_over_35","language":"python-imperative","plan":{"min":[{"line":1,"start":2,"end":17,"ntokens":5},{"line":2,"start":2,"end":23,"ntokens":8},{"line":4,"start":7,"end":60,"ntokens":20},{"line":3,"start":4,"end":6,"ntokens":2},{"line":5,"start":6,"end":23,"ntokens":5}],"filter":[{"line":2,"start":2,"end":23,"ntokens":8},{"line":3,"start":8,"end":26,"ntokens":9},{"line":3,"start":4,"end":6,"ntokens":2}],"name":[{"line":6,"start":2,"end":25,"ntokens":7}],"null":[{"line":6,"start":26,"end":59,"ntokens":13}]},"source":"def youngest_over_35(people):\\n  youngest = None\\n  for person in people:\\n    if (person[\'age\'] > 35 and \\n       (youngest is None or person[\'age\'] < youngest[\'age\'])):\\n      youngest = person\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":"fused","ntokens":86,"category":"Aggregation","language_name":"Python - Imperative","task_name":"Youngest person over 35","token_zscore":0.9199683306,"plan_overlap":1},{"task":"youngest_over_35","language":"r","plan":{"name":[{"line":4,"start":4,"end":14,"ntokens":4}],"min":[{"line":3,"start":4,"end":29,"ntokens":8}],"filter":[{"line":2,"start":4,"end":24,"ntokens":10}]},"source":"youngest_over_35 <- function(people) {\\n  people %>%\\n    filter(age > 35) %>%\\n    slice(which.min(age)) %>%\\n    pull(name)\\n}","author":"will","implementation":"","ntokens":40,"category":"Aggregation","language_name":"R - Tidyverse","task_name":"Youngest person over 35","token_zscore":-0.7985511905,"plan_overlap":0}]')},WkPL:function(n,e){n.exports=function(n,e){(null==e||e>n.length)&&(e=n.length);for(var t=0,a=new Array(e);t<e;t++)a[t]=n[t];return a}},YFqc:function(n,e,t){n.exports=t("cTJO")},YuTi:function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},ZhPi:function(n,e,t){var a=t("WkPL");n.exports=function(n,e){if(n){if("string"===typeof n)return a(n,e);var t=Object.prototype.toString.call(n).slice(8,-1);return"Object"===t&&n.constructor&&(t=n.constructor.name),"Map"===t||"Set"===t?Array.from(n):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?a(n,e):void 0}}},a3WO:function(n,e,t){"use strict";function a(n,e){(null==e||e>n.length)&&(e=n.length);for(var t=0,a=new Array(e);t<e;t++)a[t]=n[t];return a}t.d(e,"a",(function(){return a}))},cTJO:function(n,e,t){"use strict";var a=t("zoAU"),r=t("7KCV");e.__esModule=!0,e.default=void 0;var s=r(t("q1tI")),i=t("elyg"),o=t("nOHt"),l=t("vNVm"),d={};function u(n,e,t,a){if((0,i.isLocalURL)(e)){n.prefetch(e,t,a).catch((function(n){0}));var r=a&&"undefined"!==typeof a.locale?a.locale:n&&n.locale;d[e+"%"+t+(r?"%"+r:"")]=!0}}var c=function(n){var e=!1!==n.prefetch,t=(0,o.useRouter)(),r=t&&t.pathname||"/",c=s.default.useMemo((function(){var e=(0,i.resolveHref)(r,n.href,!0),t=a(e,2),s=t[0],o=t[1];return{href:s,as:n.as?(0,i.resolveHref)(r,n.as):o||s}}),[r,n.href,n.as]),p=c.href,m=c.as,g=n.children,_=n.replace,k=n.shallow,f=n.scroll,h=n.locale;"string"===typeof g&&(g=s.default.createElement("a",null,g));var v=s.Children.only(g),y=v&&"object"===typeof v&&v.ref,w=(0,l.useIntersection)({rootMargin:"200px"}),b=a(w,2),x=b[0],E=b[1],q=s.default.useCallback((function(n){x(n),y&&("function"===typeof y?y(n):"object"===typeof y&&(y.current=n))}),[y,x]);(0,s.useEffect)((function(){var n=E&&e&&(0,i.isLocalURL)(p),a="undefined"!==typeof h?h:t&&t.locale,r=d[p+"%"+m+(a?"%"+a:"")];n&&!r&&u(t,p,m,{locale:a})}),[m,p,E,h,e,t]);var O={ref:q,onClick:function(n){v.props&&"function"===typeof v.props.onClick&&v.props.onClick(n),n.defaultPrevented||function(n,e,t,a,r,s,o,l){("A"!==n.currentTarget.nodeName||!function(n){var e=n.currentTarget.target;return e&&"_self"!==e||n.metaKey||n.ctrlKey||n.shiftKey||n.altKey||n.nativeEvent&&2===n.nativeEvent.which}(n)&&(0,i.isLocalURL)(t))&&(n.preventDefault(),null==o&&(o=a.indexOf("#")<0),e[r?"replace":"push"](t,a,{shallow:s,locale:l}).then((function(n){n&&o&&(window.scrollTo(0,0),document.body.focus())})))}(n,t,p,m,_,k,f,h)},onMouseEnter:function(n){(0,i.isLocalURL)(p)&&(v.props&&"function"===typeof v.props.onMouseEnter&&v.props.onMouseEnter(n),u(t,p,m,{priority:!0}))}};return(n.passHref||"a"===v.type&&!("href"in v.props))&&(O.href=(0,i.addBasePath)((0,i.addLocale)(m,"undefined"!==typeof h?h:t&&t.locale,t&&t.defaultLocale))),s.default.cloneElement(v,O)};e.default=c},j0Zo:function(n){n.exports=JSON.parse('[{"id":"youngest_over_35","category":"Aggregation","name":"Youngest person over 35","description":"Find the name of the youngest person older than 35, returning null if none exists.","plan":[{"id":"filter","description":"older than 35"},{"id":"min","description":"youngest person"},{"id":"name","description":"the name"},{"id":"null","description":"returning null"}],"sample_input":{"people":[{"age":35,"name":"John"},{"age":36,"name":"Mary"},{"age":37,"name":"Jane"}]},"sample_output":"Mary"},{"id":"strings_to_numbers","category":"Strings","name":"Convert strings with different formats to numbers","description":"Convert the string value in each row into a number, removing commas if format is \\"comma_sep\\" and underscores if format is \\"under_sep\\".","plan":[{"id":"iter","description":"in each row"},{"id":"cond","description":"commas if format is \\"comma_sep\\" and underscores if format is \\"under_sep\\"."},{"id":"clean","description":"removing"},{"id":"number","description":"into a number"}],"sample_input":{"numbers":[{"format":"comma_sep","value":"12,337,800"},{"format":"under_sep","value":"80_999"}]},"sample_output":[12337800,80999]},{"id":"continent_by_population","category":"Aggregation","name":"Continent with the highest average population","description":"Find the name of the continent with the highest average population by country.","plan":[{"id":"name","description":"name of the continent"},{"id":"group","description":"by country"},{"id":"average","description":"average population"},{"id":"max","description":"highest"}],"sample_input":{"countries":[{"name":"USA","population":328,"continent":"North America"},{"name":"Canada","population":37,"continent":"North America"},{"name":"Ethiopia","population":109,"continent":"Africa"},{"name":"Kenya","population":51,"continent":"Africa"}]},"sample_output":"North America"},{"id":"process_tweets","category":"Strings","name":"Filter and clean tweets","description":"Select the lower-case body and timestamp of tweets that are in English and not retweets","plan":[{"id":"filter","description":"in English and not retweets"},{"id":"lowercase","description":"lower-case"},{"id":"select","description":"body and timestamp"},{"id":"iter","description":"of tweets"}],"sample_input":{"data":[{"language":"en","is_retweet":"false","likes":8,"body":"Some Text","ts":1604534320},{"language":"en","is_retweet":"true","likes":8,"body":"some Text","ts":1604534321},{"language":"en","is_retweet":"false","likes":8,"body":"some Text","ts":1604534322},{"language":"fr","is_retweet":"false","likes":8,"body":"some Text","ts":1604534322}]},"sample_output":[{"body":"some text","ts":1604534320},{"body":"some text","ts":1604534322}]},{"id":"average_window","category":"Time Series","name":"Windowed average","description":"compute average of data points in each disjoint time window of width 7 ordered by time","plan":[{"id":"key","description":"of width 7"},{"id":"group by","description":"points in each disjoint time window"},{"id":"average","description":"compute average"},{"id":"output_order","description":"ordered by time"}],"sample_input":{"data":[{"time":20,"x":14},{"time":19,"x":15},{"time":2,"x":3},{"time":1,"x":2},{"time":3,"x":7},{"time":10,"x":9},{"time":11,"x":11}]},"sample_output":[4,10,14.5]},{"id":"unique_product","category":"First-order logic","name":"Unique product","description":"Find the name of any product whose value is different from all others","plan":[{"id":"name","description":"Find the name"},{"id":"check","description":"value is different from all others"}],"sample_input":{"list":[{"id":0,"value":"Apple"},{"id":1,"value":"Banana"},{"id":2,"value":"Banana"},{"id":3,"value":"Banana"}]},"sample_output":"Apple"},{"id":"average_adjacent","category":"Time Series","name":"Adjacent averages","description":"compute averages of adjacent values in time-ordered data","plan":[{"id":"order","description":"time-ordered data"},{"id":"pair adjacent","description":"adjacent values"},{"id":"average","description":"compute averages"}],"sample_input":{"data":[{"time":6,"x":14},{"time":2,"x":3},{"time":1,"x":1},{"time":3,"x":7},{"time":4,"x":9},{"time":5,"x":11}]},"sample_output":[{"time":1,"x":2},{"time":2,"x":5},{"time":3,"x":8},{"time":4,"x":10},{"time":5,"x":12.5}]},{"id":"changing_mean","category":"Aggregation","name":"First element that doesn\'t change mean","description":"Return index of the first element you can remove that does not change the mean of the list by more than 0.1","plan":[{"id":"remove","description":"remove"},{"id":"orig","description":"mean of the list"},{"id":"new","description":"change the"},{"id":"diff","description":"by more than 0.1"},{"id":"first","description":"index of the first element"}],"sample_input":{"vals":[{"id":0,"value":1},{"id":1,"value":2},{"id":2,"value":3},{"id":3,"value":1}]},"sample_output":1},{"id":"reachable","category":"Graphs","name":"Reflexive-transitive closure","description":"A path is a sequence of edges such that the target of each edge is the source of the next. Given a graph and a vertex v, list the vertices reachable by a path from v.","plan":[{"id":"graph","description":"a graph"},{"id":"source","description":"from v"},{"id":"edge_match","description":"target of each edge is the source of the next"},{"id":"edge_sequence","description":"a sequence of edges"},{"id":"vertices","description":"the vertices reachable by a path"}],"sample_input":{"graph":[{"source":"a","target":"b"},{"source":"b","target":"b"},{"source":"b","target":"c"},{"source":"c","target":"f"},{"source":"c","target":"b"},{"source":"a","target":"d"},{"source":"e","target":"a"}],"query":[{"source":"a"}]},"sample_output":["a","b","c","d","f"]},{"id":"tom_hanks","category":"Joins","name":"Directors of movies Tom Hanks starred in","description":"Find directors of movies that Tom Hanks starred in","plan":[{"id":"director","description":"Find directors"},{"id":"actor","description":"Tom Hanks starred in"},{"id":"movies","description":"of movies"}],"sample_input":{"actors":[{"movie":"AM","actor":"Tom Hanks"},{"movie":"AM","actor":"Not Tom Hanks"},{"movie":"AM","actor":"Also not Tom Hanks"},{"movie":"BM","actor":"Other actor"},{"movie":"CM","actor":"Other actor"}],"directors":[{"director":"A","movie":"AM"},{"director":"A","movie":"BM"},{"director":"C","movie":"CM"}]},"sample_output":["A"]},{"id":"documents_with_infrequent_words","category":"Strings","name":"Documents with infrequent words","description":"Find the index of documents that contain a word that appears exactly once in the corpus, where a word is a case-sensitive string of characters separated by a space.","plan":[{"id":"word","description":"case-sensitive string of characters separated by a space"},{"id":"frequency","description":"appears exactly once"},{"id":"documents","description":"documents that contain a word"}],"sample_input":{"documents":[{"id":1,"text":"Hello world"},{"id":2,"text":"Hello friend"},{"id":3,"text":"friend of the world"},{"id":4,"text":"Hola"}]},"sample_output":[3,4]},{"id":"customer_orders","category":"Joins","name":"Orders from California customers","description":"Select all order ids from customers that live in California","plan":[{"id":"order_ids","description":"Select all order ids"},{"id":"California","description":"live in California"},{"id":"customer","description":"customers"}],"sample_input":{"customers":[{"cid":0,"customer":"A","location":"California"},{"cid":1,"customer":"B","location":"California"},{"cid":2,"customer":"C","location":"Virginia"},{"cid":3,"customer":"D","location":"New York"}],"orders":[{"cid":0,"oid":4,"customer":"A","orderNum":"A1"},{"cid":0,"oid":5,"customer":"A","orderNum":"A2"},{"cid":1,"oid":6,"customer":"B","orderNum":"B1"},{"cid":1,"oid":7,"customer":"B","orderNum":"B2"},{"cid":2,"oid":8,"customer":"C","orderNum":"C1"}]},"sample_output":[4,5,6,7]},{"id":"purchased_all_food","category":"First-order logic","name":"People that purchased all possible items","description":"Find all buyers that ordered every food item at least once.","plan":[{"id":"iter","description":"all buyers"},{"id":"ordered","description":"ordered"},{"id":"all","description":"every food item at least once"}],"sample_input":{"food":[{"id":1,"name":"Burrito"},{"id":2,"name":"Sushi"}],"orders":[{"id":1,"buyer":"Will","food":1},{"id":2,"buyer":"Scott","food":2},{"id":3,"buyer":"Scott","food":2},{"id":4,"buyer":"Will","food":2}]},"sample_output":["Will"]},{"id":"continent_median_population","category":"Aggregation","name":"Median population for each continent","description":"For each continent, return its name and the median population of its countries.","plan":[{"id":"iter","description":"For each continent"},{"id":"name","description":"its name"},{"id":"group","description":"of its countries"},{"id":"agg","description":"median population"}],"sample_input":{"countries":[{"name":"USA","population":328,"continent":"North America"},{"name":"USA2","population":37,"continent":"North America"},{"name":"Canada","population":37,"continent":"North America"},{"name":"Ethiopia","population":109,"continent":"Africa"}]},"sample_output":[{"continent":"North America","population":37},{"continent":"Africa","population":109}]},{"id":"rolling_average","category":"Time Series","name":"Rolling average","description":"for each data point, compute average of data points within last 7 days","plan":[{"id":"windows","description":"each data point"},{"id":"group","description":"data points within last 7"},{"id":"filter","description":"compute average"}],"sample_input":{"data":[{"time":20,"x":14.5},{"time":3,"x":3},{"time":1,"x":1},{"time":9,"x":7},{"time":10,"x":11},{"time":11,"x":12}]},"sample_output":[{"end_time":1,"average":1},{"end_time":3,"average":2},{"end_time":9,"average":5},{"end_time":10,"average":9},{"end_time":11,"average":10},{"end_time":20,"average":14.5}]},{"id":"unique_beer_drinkers","category":"First-order logic","name":"People who like a unique set of beer","description":"Find all people whose preferred set of beers is distinct from each other person\'s preferred set","plan":[{"id":"collect","description":"preferred set of beers"},{"id":"iter","description":"all people"},{"id":"compare","description":"distinct from each other person\'s preferred set"}],"sample_input":{"likes":[{"name":"will","beer":"ipa"},{"name":"will","beer":"lager"},{"name":"scott","beer":"ipa"},{"name":"scott","beer":"stout"},{"name":"gleb","beer":"ipa"},{"name":"gleb","beer":"stout"},{"name":"fred","beer":"ipa"},{"name":"fred","beer":"lager"},{"name":"fred","beer":"stout"}]},"sample_output":["will","fred"]},{"id":"row_per_child","category":"Joins","name":"Row per family to row per child","description":"For each family, return a row for each child containing the family ID, child ID, DOB, and height.","plan":[{"id":"each-family","description":"For each family"},{"id":"each-child","description":"for each child"},{"id":"family-ID","description":"family ID"},{"id":"child-ID","description":"child ID"},{"id":"dob-height","description":"DOB, and height"}],"sample_input":{"families":[{"family":1,"dob_child1":"1998","dob_child2":"1999","dob_child3":"2000","height_child1":"5_11","height_child2":"5_10","height_child3":"5_9"},{"family":2,"dob_child1":"1997","dob_child2":"1995","dob_child3":"1996","height_child1":"5_3","height_child2":"5_5","height_child3":"5_1"}]},"sample_output":[{"family":1,"child":"child1","dob":"1998","height":"5_11"},{"family":1,"child":"child2","dob":"1999","height":"5_10"},{"family":1,"child":"child3","dob":"2000","height":"5_9"},{"family":2,"child":"child1","dob":"1997","height":"5_3"},{"family":2,"child":"child2","dob":"1995","height":"5_5"},{"family":2,"child":"child3","dob":"1996","height":"5_1"}]},{"id":"scc","category":"Graphs","name":"Strongly-connected components","description":"A path is a sequence of edges such that the target of each edge is the source of the next. Given a graph and a vertex v, list each vertex u such that there is a path from v to u and u to v.","plan":[{"id":"graph","description":"a graph"},{"id":"source<->target","description":"v to u and u to v"},{"id":"edge_match","description":"target of each edge is the source of the next"},{"id":"edge_sequence","description":"a sequence of edges"},{"id":"vertices","description":"a path"}],"sample_input":{"graph":[{"source":"a","target":"b"},{"source":"b","target":"b"},{"source":"b","target":"c"},{"source":"c","target":"b"},{"source":"c","target":"a"},{"source":"a","target":"d"}],"query":[{"source":"c"}]},"sample_output":["a","b","c"]}]')},lwsE:function(n,e){n.exports=function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}},m0LI:function(n,e){n.exports=function(n,e){if("undefined"!==typeof Symbol&&Symbol.iterator in Object(n)){var t=[],a=!0,r=!1,s=void 0;try{for(var i,o=n[Symbol.iterator]();!(a=(i=o.next()).done)&&(t.push(i.value),!e||t.length!==e);a=!0);}catch(l){r=!0,s=l}finally{try{a||null==o.return||o.return()}finally{if(r)throw s}}return t}}},"rAU/":function(n){n.exports=JSON.parse('[{"task":"tom_hanks","language":"python-imperative","plan":{"director":[{"line":7,"start":10,"end":40},{"line":8,"start":4,"end":22},{"line":2,"start":2,"end":21},{"line":5,"start":6,"end":25}],"actor":[{"line":4,"start":4,"end":33},{"line":3,"start":2,"end":18}],"movies":[{"line":6,"start":8,"end":36}]},"source":"\\ndef tom_hanks(actors,directors):\\n  r_directors = set()\\n  for a in actors:\\n    if \'Tom Hanks\' == a[\'actor\']:\\n      for d in directors:\\n        if a[\'movie\'] == d[\'movie\']:\\n          r_directors.add(d[\'director\'])\\n    return r_directors\\n","author":"g","implementation":""},{"task":"tom_hanks","language":"python-pandas","plan":{"director":[{"line":4,"start":2,"end":38},{"line":5,"start":4,"end":29}],"actor":[{"line":3,"start":3,"end":34}],"movies":[{"line":3,"start":36,"end":43},{"line":4,"start":19,"end":37}]},"source":"\\ndef tom_hanks(actors,directors):\\n  movies = list(actors.loc[\\n    actors[\'actor\'] == \'Tom Hanks\', \'movie\'])\\n  return directors[directors[\'movie\'].\\n    isin(movies)][\'director\']\\n","author":"g","implementation":""},{"task":"tom_hanks","language":"r","plan":{"actor":[{"line":2,"start":4,"end":36}],"movies":[{"line":1,"start":2,"end":12}],"director":[{"line":3,"start":4,"end":43},{"line":4,"start":4,"end":18}]},"source":"tom_hanks <- function(actors, directors) {\\n  actors %>%\\n    filter(actor == \\"Tom Hanks\\") %>%\\n    inner_join(directors, by = \\"movie\\") %>%\\n    pull(director)\\n}","author":"g","implementation":""},{"task":"tom_hanks","language":"q","plan":{"actor":[{"line":2,"start":3,"end":30}],"director":[{"line":2,"start":32,"end":41},{"line":1,"start":3,"end":18},{"line":1,"start":31,"end":57}],"movies":[{"line":1,"start":19,"end":30},{"line":1,"start":35,"end":41}]},"source":"tom_hanks:\\n  (select director from actors ij (`movie xkey directors) \\n   where actor ~\\\\: \\"Tom Hanks\\") `director","author":"g","implementation":""},{"task":"tom_hanks","language":"sql","plan":{"director":[{"line":1,"start":0,"end":25},{"line":2,"start":0,"end":5},{"line":3,"start":2,"end":12}],"actor":[{"line":7,"start":0,"end":30},{"line":4,"start":2,"end":19}],"movies":[{"line":5,"start":2,"end":23},{"line":6,"start":2,"end":14}]},"source":"\\nSELECT directors.director\\nFROM \\n  directors \\n  INNER JOIN actors\\n  ON directors.movie = \\n  actors.movie\\nWHERE actors.actor=\\"Tom Hanks\\"\\n","author":"g","implementation":""},{"task":"tom_hanks","language":"datalog","plan":{"director":[{"line":3,"start":2,"end":28},{"line":1,"start":10,"end":18}],"actor":[{"line":2,"start":2,"end":28}],"movies":[{"line":2,"start":21,"end":26},{"line":3,"start":21,"end":26}]},"source":"\\ntom_hanks(Director):-\\n  actors(\\"Tom Hanks\\",movie),\\n  directors(Director,movie).\\n","author":"g","implementation":""},{"task":"tom_hanks","language":"python-functional","plan":{"director":[{"line":3,"start":15,"end":47},{"line":4,"start":2,"end":18},{"line":3,"start":2,"end":19}],"actor":[{"line":2,"start":46,"end":71},{"line":2,"start":23,"end":71}],"movies":[{"line":2,"start":12,"end":22},{"line":3,"start":52,"end":75},{"line":2,"start":2,"end":19}]},"source":"\\ndef tom_hanks(actors,directors):\\n  movies = [a[\'movie\'] for a in actors if a[\'actor\'] == \'Tom Hanks\']\\n  directors = [d[\'director\'] for d in directors if d[\'movie\'] in movies]\\n  return directors\\n","author":"g","implementation":""},{"task":"inner_join","language":"python-imperative","plan":{"California":[{"line":3,"start":54,"end":93}]},"source":"  \\ndef inner_join(customers,orders):\\n    oids = []\\n    cids = [customer[\'cid\'] for customer in customers if customer[\'location\'] == \\"California\\"]\\n    oids = [order[\'oid\'] for order in orders if order[\'cid\'] in cids]\\n    return oids\\n","author":"g","implementation":""},{"task":"inner_join","language":"python-pandas","plan":{},"source":"  \\ndef inner_join(customers,orders):\\n    joined = orders.join(customers, on=\\"cid\\",how=\\"inner\\",lsuffix=\\"_j\\")\\n    joined = joined.loc[joined[\'location\'] == \\"California\\"]\\n    return pd.DataFrame({0: list(joined.oid)})\\n\\n","author":"g","implementation":""},{"task":"inner_join","language":"sql","plan":{},"source":"  \\n    SELECT orders.oid \\n    FROM \\n    (orders INNER JOIN customers ON orders.cid = customers.cid) \\n    WHERE location=\\"California\\"\\n","author":"g","implementation":""},{"task":"inner_join","language":"datalog","plan":{},"source":"  \\n    inner_join(oid):-\\n    customers(cid,customer,location),\\n    location=\\"California\\",\\n    orders(cid,_,oid,_).\\n","author":"g","implementation":""},{"task":"inner_join","language":"python-functional","plan":{},"source":"  \\ndef inner_join(customers,orders):\\n    oids = []\\n    for order in orders:\\n        for customer in customers:\\n            if customer[\'cid\'] == order[\'cid\']:\\n                if customer[\'location\'] == \\"California\\":\\n                    oids.append(order[\'oid\'])\\n    return oids\\n","author":"g","implementation":""},{"task":"continent_median_population","language":"python-pandas","plan":{"name":[{"line":4,"start":6,"end":20},{"line":4,"start":21,"end":21}],"agg":[{"line":3,"start":6,"end":26}],"iter":[{"line":2,"start":6,"end":27}],"group":[{"line":1,"start":10,"end":19}]},"source":"def continent_median_population(countries):\\n  return (countries\\n      .groupby(\'continent\')\\n      .population.median()\\n      .reset_index())","author":"will","implementation":""},{"task":"continent_median_population","language":"sql","plan":{"name":[{"line":0,"start":7,"end":16}],"agg":[{"line":0,"start":18,"end":47},{"line":2,"start":2,"end":13},{"line":3,"start":4,"end":21},{"line":4,"start":30,"end":59},{"line":5,"start":4,"end":16},{"line":6,"start":31,"end":39},{"line":7,"start":2,"end":17},{"line":8,"start":0,"end":6},{"line":9,"start":2,"end":48},{"line":10,"start":2,"end":55}],"group":[{"line":4,"start":7,"end":29},{"line":6,"start":7,"end":29}],"iter":[{"line":11,"start":0,"end":18}]},"source":"SELECT continent, AVG(population) as population\\nFROM\\n  (SELECT *, \\n    row_number() OVER \\n      (PARTITION BY continent ORDER BY population) AS rank, \\n    count() OVER \\n      (PARTITION BY continent) as count\\n  FROM countries)\\nWHERE \\n  (count % 2 = 1 AND rank = (count + 1) / 2) OR \\n  (count % 2 = 0 AND ABS(rank - 0.5 - count / 2) = 0.5)\\nGROUP BY continent","author":"will","implementation":""},{"task":"continent_median_population","language":"datalog","plan":{"iter":[{"line":20,"start":2,"end":29}],"name":[{"line":20,"start":12,"end":21},{"line":19,"start":28,"end":37}],"agg":[{"line":19,"start":39,"end":45},{"line":21,"start":2,"end":53},{"line":22,"start":2,"end":27},{"line":23,"start":4,"end":54},{"line":24,"start":3,"end":26},{"line":25,"start":4,"end":47},{"line":26,"start":4,"end":43},{"line":27,"start":4,"end":28},{"line":0,"start":0,"end":46},{"line":1,"start":0,"end":50},{"line":2,"start":0,"end":0},{"line":3,"start":0,"end":56},{"line":4,"start":0,"end":45},{"line":5,"start":2,"end":44},{"line":6,"start":2,"end":25},{"line":7,"start":2,"end":21},{"line":8,"start":4,"end":32},{"line":9,"start":4,"end":22},{"line":10,"start":4,"end":18},{"line":11,"start":2,"end":4},{"line":12,"start":2,"end":18},{"line":13,"start":4,"end":32},{"line":14,"start":4,"end":22},{"line":15,"start":4,"end":20},{"line":16,"start":4,"end":12},{"line":17,"start":2,"end":4}],"group":[{"line":21,"start":26,"end":52},{"line":8,"start":14,"end":23},{"line":5,"start":12,"end":21}]},"source":".decl unique_id(Country:symbol, Id:number)    \\nunique_id(Country, $) :- countries(_, Country, _).\\n\\n.decl rank(Continent:symbol, R:number, Population:float)\\nrank(Continent, R_less + R_eq, Population) :-\\n  countries(Continent, Country, Population),\\n  unique_id(Country, Id),\\n  R_less = count : { \\n    countries(Continent, C, P), \\n    unique_id(C, Id2),\\n    P < Population\\n  },\\n  R_eq = count : {\\n    countries(Continent, C, P), \\n    unique_id(C, Id2),\\n    P = Population, \\n    Id2 < Id\\n  }.\\n\\ncontinent_median_population(Continent, Median) :-\\n  countries(Continent, _, _),\\n  Num_countries = count : countries(Continent, _, _),\\n  ((Num_countries % 2 = 1, \\n    rank(Continent, (Num_countries - 1) / 2, Median));\\n   (Num_countries % 2 = 0,\\n    rank(Continent, Num_countries / 2 - 1, P1),\\n    rank(Continent, Num_countries / 2, P2),\\n    Median = (P1 + P2) / 2)).     ","author":"will","implementation":""},{"task":"continent_median_population","language":"q","plan":{"agg":[{"line":1,"start":17,"end":32}],"iter":[{"line":1,"start":33,"end":45}],"group":[{"line":1,"start":46,"end":60}],"name":[{"line":1,"start":33,"end":45}]},"source":"continent_median_population:\\n  () xkey select med[population] by continent from countries","author":"will","implementation":""},{"task":"continent_median_population","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":55},{"line":7,"start":4,"end":31},{"line":3,"start":4,"end":13},{"line":20,"start":4,"end":46},{"line":18,"start":2,"end":10},{"line":21,"start":2,"end":3}],"group":[{"line":4,"start":22,"end":41},{"line":5,"start":6,"end":36},{"line":6,"start":4,"end":5},{"line":3,"start":15,"end":16}],"agg":[{"line":4,"start":6,"end":21},{"line":2,"start":2,"end":17},{"line":8,"start":2,"end":3},{"line":10,"start":2,"end":27},{"line":11,"start":4,"end":23},{"line":12,"start":4,"end":17},{"line":13,"start":4,"end":18},{"line":14,"start":6,"end":31},{"line":15,"start":4,"end":9},{"line":16,"start":6,"end":50},{"line":19,"start":29,"end":63}],"name":[{"line":19,"start":5,"end":27}]},"source":"def continent_median_population(countries):\\n  continents = set([c[\'continent\'] for c in countries])\\n  populations = {\\n    continent: [\\n      c[\'population\'] for c in countries \\n      if c[\'continent\'] == continent\\n    ]\\n    for continent in continents\\n  }\\n  \\n  def compute_median(pops):\\n    pops = sorted(pops)\\n    N = len(pops)\\n    if N % 2 == 1:\\n      return pops[(N - 1) // 2]\\n    else:\\n      return (pops[N // 2 - 1] + pops[N // 2]) / 2  \\n   \\n  return [\\n    {\\"continent\\": continent, \\"population\\": compute_median(pops)}\\n    for continent, pops in populations.items()\\n  ]","author":"will","implementation":""},{"task":"continent_median_population","language":"python-imperative","plan":{"iter":[{"line":3,"start":16,"end":36},{"line":6,"start":6,"end":15},{"line":6,"start":22,"end":45},{"line":13,"start":4,"end":19},{"line":16,"start":4,"end":6},{"line":5,"start":2,"end":13},{"line":6,"start":2,"end":6},{"line":18,"start":2,"end":15}],"group":[{"line":2,"start":2,"end":27},{"line":3,"start":45,"end":52}],"agg":[{"line":1,"start":2,"end":33},{"line":3,"start":4,"end":16},{"line":3,"start":36,"end":45},{"line":3,"start":52,"end":67},{"line":6,"start":17,"end":45},{"line":7,"start":4,"end":15},{"line":8,"start":4,"end":17},{"line":9,"start":4,"end":18},{"line":10,"start":6,"end":33},{"line":11,"start":4,"end":9},{"line":12,"start":6,"end":52},{"line":15,"start":6,"end":26},{"line":6,"start":2,"end":6}],"name":[{"line":14,"start":6,"end":29}]},"source":"def continent_median_population(countries):\\n  populations = defaultdict(list)\\n  for country in countries:\\n    populations[country[\'continent\']].append(country[\'population\'])\\n  \\n  output = []  \\n  for continent, pops in populations.items():\\n    pops.sort()\\n    N = len(pops)\\n    if N % 2 == 1:\\n      median = pops[(N - 1) // 2]\\n    else:\\n      median = (pops[N // 2 - 1] + pops[N // 2]) / 2\\n    output.append({\\n      \\"continent\\": continent,\\n      \\"population\\": median\\n    })\\n    \\n  return output","author":"will","implementation":""},{"task":"continent_median_population","language":"r","plan":{"iter":[{"line":1,"start":2,"end":15}],"group":[{"line":2,"start":4,"end":27}],"agg":[{"line":3,"start":4,"end":46}],"name":[{"line":1,"start":2,"end":15}]},"source":"continent_median_population <- function(countries) {\\n  countries %>%\\n    group_by(continent) %>%\\n    summarize(population = median(population))\\n}","author":"will","implementation":""},{"task":"youngest_over_35","language":"python-pandas","plan":{"filter":[{"line":1,"start":2,"end":35}],"null":[{"line":2,"start":2,"end":24},{"line":3,"start":4,"end":15},{"line":4,"start":2,"end":7}],"min":[{"line":5,"start":4,"end":48}],"name":[{"line":6,"start":4,"end":27}]},"source":"def youngest_over_35(people):\\n  over_35 = people[people.age > 35]\\n  if len(over_35) == 0: \\n    return None\\n  else:\\n    youngest = over_35.loc[over_35.age.idxmin()]\\n    return youngest[\'name\']","author":"will","implementation":""},{"task":"youngest_over_35","language":"sql","plan":{"name":[{"line":0,"start":0,"end":11}],"min":[{"line":3,"start":2,"end":17},{"line":4,"start":2,"end":13},{"line":1,"start":0,"end":11},{"line":2,"start":0,"end":13}],"filter":[{"line":5,"start":2,"end":16},{"line":4,"start":2,"end":13}]},"source":"SELECT name\\nFROM people\\nWHERE age = (\\n  SELECT MIN(age)\\n  FROM people\\n  WHERE age > 35)\\nLIMIT 1","author":"will","implementation":""},{"task":"youngest_over_35","language":"datalog","plan":{"min":[{"line":2,"start":45,"end":46},{"line":2,"start":2,"end":34},{"line":1,"start":2,"end":13},{"line":1,"start":18,"end":20}],"filter":[{"line":2,"start":36,"end":44}],"name":[{"line":1,"start":14,"end":18},{"line":0,"start":17,"end":21}]},"source":"youngest_over_35(Name) :- \\n  people(Age, Name), \\n  Age = min Age : { people(Age, _), Age > 35 }.","author":"will","implementation":""},{"task":"youngest_over_35","language":"q","plan":{"filter":[{"line":0,"start":0,"end":45}],"name":[{"line":2,"start":9,"end":20},{"line":2,"start":20,"end":36},{"line":2,"start":59,"end":64}],"min":[{"line":2,"start":37,"end":57}]},"source":"old_enough: select from people where age > 35\\nyoungest_over_35: \\n  (first select name from old_enough where age = min(age)) `name","author":"will","implementation":""},{"task":"youngest_over_35","language":"python-functional","plan":{"filter":[{"line":1,"start":2,"end":48}],"min":[{"line":2,"start":2,"end":63}],"name":[{"line":3,"start":9,"end":25}]},"source":"def youngest_over_35(people):\\n  over_35 = [p for p in people if p[\'age\'] > 35]\\n  youngest = min(over_35, default=None, key=lambda p: p[\'age\'])\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":""},{"task":"youngest_over_35","language":"python-imperative","plan":{"filter":[{"line":1,"start":2,"end":14},{"line":2,"start":2,"end":23},{"line":3,"start":4,"end":26},{"line":4,"start":6,"end":28}],"min":[{"line":6,"start":2,"end":17},{"line":7,"start":2,"end":24},{"line":8,"start":4,"end":59},{"line":9,"start":6,"end":23}],"name":[{"line":10,"start":9,"end":25}]},"source":"def youngest_over_35(people):\\n  over_35 = []\\n  for person in people:\\n    if person[\'age\'] > 35:\\n      over_35.append(person)\\n    \\n  youngest = None\\n  for person in over_35:\\n    if youngest is None or person[\'age\'] < youngest[\'age\']:\\n      youngest = person\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":"separate"},{"task":"youngest_over_35","language":"python-imperative","plan":{"min":[{"line":1,"start":2,"end":17},{"line":2,"start":2,"end":23},{"line":4,"start":7,"end":60},{"line":3,"start":4,"end":6},{"line":5,"start":6,"end":23}],"filter":[{"line":2,"start":2,"end":23},{"line":3,"start":8,"end":26},{"line":3,"start":4,"end":6}],"name":[{"line":6,"start":2,"end":25}],"null":[{"line":6,"start":26,"end":59}]},"source":"def youngest_over_35(people):\\n  youngest = None\\n  for person in people:\\n    if (person[\'age\'] > 35 and \\n       (youngest is None or person[\'age\'] < youngest[\'age\'])):\\n      youngest = person\\n  return youngest[\'name\'] if youngest is not None else None","author":"will","implementation":"fused"},{"task":"youngest_over_35","language":"r","plan":{"name":[{"line":4,"start":4,"end":14}],"min":[{"line":3,"start":4,"end":29}],"filter":[{"line":2,"start":4,"end":24}]},"source":"youngest_over_35 <- function(people) {\\n  people %>%\\n    filter(age > 35) %>%\\n    slice(which.min(age)) %>%\\n    pull(name)\\n}","author":"will","implementation":""},{"task":"reachable","language":"sql","plan":{"step":[{"line":2,"start":0,"end":43},{"line":4,"start":0,"end":33},{"line":5,"start":2,"end":41},{"line":6,"start":2,"end":30}],"source":[{"line":9,"start":14,"end":37},{"line":11,"start":0,"end":37}],"edge_sequence":[{"line":4,"start":2,"end":34},{"line":7,"start":2,"end":41}],"edge_match":[{"line":8,"start":2,"end":30}],"vertices":[{"line":6,"start":2,"end":33},{"line":1,"start":0,"end":23},{"line":2,"start":2,"end":34},{"line":3,"start":2,"end":7},{"line":5,"start":2,"end":7},{"line":6,"start":2,"end":8},{"line":5,"start":2,"end":7},{"line":6,"start":2,"end":33},{"line":5,"start":2,"end":7},{"line":10,"start":0,"end":33}]},"source":"WITH RECURSIVE\\nclosure(source, target) AS (\\n  SELECT source, source FROM graph\\n  UNION\\n  SELECT source, target FROM graph\\n  UNION\\n  SELECT edge.source, path.target\\n  FROM closure as path JOIN graph as edge\\n  ON edge.target = path.source\\n)\\nSELECT S.target FROM closure as S\\nJOIN query ON S.source = query.source","author":"scott","implementation":""},{"task":"reachable","language":"python-imperative","plan":{"graph":[{"line":1,"start":2,"end":36},{"line":2,"start":2,"end":20},{"line":3,"start":4,"end":57}],"edge_match":[{"line":13,"start":4,"end":44},{"line":14,"start":6,"end":28}],"edge_sequence":[{"line":13,"start":20,"end":34}],"vertices":[{"line":7,"start":2,"end":26},{"line":6,"start":2,"end":17},{"line":9,"start":2,"end":26},{"line":15,"start":4,"end":24},{"line":10,"start":4,"end":28},{"line":11,"start":4,"end":26},{"line":12,"start":6,"end":14}],"source":[{"line":7,"start":18,"end":24},{"line":4,"start":2,"end":29}]},"source":"def reachable(graph, query):\\n  adjacency_list = defaultdict(list)\\n  for edge in graph:\\n    adjacency_list[edge[\\"source\\"]].append(edge[\\"target\\"])\\n  source = query[0][\\"source\\"]\\n\\n  visited = set()\\n  to_visit = set([source])\\n    \\n  while len(to_visit) > 0:\\n    current = to_visit.pop()\\n    if current in visited:\\n      continue\\n    for neighbor in adjacency_list[current]:\\n      to_visit.add(neighbor)\\n    visited.add(current)\\n            \\n  return list(visited)","author":"scott","implementation":""},{"task":"reachable","language":"python-functional","plan":{"edge_match":[{"line":6,"start":6,"end":33}],"edge_sequence":[{"line":5,"start":6,"end":23}],"vertices":[{"line":10,"start":2,"end":16},{"line":11,"start":4,"end":15},{"line":12,"start":4,"end":43},{"line":15,"start":14,"end":22},{"line":8,"start":4,"end":34},{"line":3,"start":6,"end":20},{"line":4,"start":6,"end":27},{"line":2,"start":4,"end":20}],"source":[{"line":14,"start":2,"end":29},{"line":15,"start":24,"end":37}]},"source":"def reachable(graph, query):\\n  def step(visited):\\n    frontier = set([\\n      edge[\\"target\\"]\\n      for vertex in visited\\n      for edge in graph\\n      if vertex == edge[\\"source\\"]\\n    ])\\n    return frontier.union(visited)\\n\\n  def fix(f, x):\\n    next = f(x)\\n    return x if next == x else fix(f, next)\\n\\n  source = query[0][\\"source\\"]\\n  return list(fix(step, set([source])))","author":"scott","implementation":""},{"task":"reachable","language":"datalog","plan":{"graph":[],"source":[{"line":3,"start":0,"end":35},{"line":4,"start":0,"end":47}],"vertices":[{"line":4,"start":44,"end":45},{"line":0,"start":11,"end":31},{"line":4,"start":44,"end":45},{"line":1,"start":0,"end":26},{"line":2,"start":0,"end":38},{"line":4,"start":44,"end":45},{"line":4,"start":10,"end":11}],"edge_match":[{"line":2,"start":23,"end":24},{"line":2,"start":32,"end":33}],"edge_sequence":[{"line":1,"start":14,"end":25},{"line":2,"start":14,"end":37}]},"source":".decl path(x: symbol, y: symbol)\\npath(x, y) :- graph(x, y).\\npath(x, y) :- graph(x, z), path(z, y).\\nreachable(source) :- query(source).\\nreachable(x) :- query(source), path(source, x).","author":"scott","implementation":""},{"task":"reachable","language":"q","plan":{"graph":[{"line":0,"start":0,"end":27},{"line":1,"start":0,"end":51},{"line":2,"start":0,"end":31},{"line":3,"start":0,"end":12},{"line":4,"start":2,"end":66}],"source":[{"line":6,"start":0,"end":48},{"line":7,"start":0,"end":49}],"edge_sequence":[{"line":5,"start":0,"end":62}],"vertices":[{"line":5,"start":0,"end":62}],"edge_match":[{"line":5,"start":0,"end":62}]},"source":"graph: (first\') each graph;\\nnodes: asc distinct graph[`source], graph[`target];\\nadj_list: `source xgroup graph;\\nadj_matrix: \\n  {in[;x] each nodes} each nodes ,\' (adj_list each nodes) `target;\\niterated_matrix: last ({x | any each (x *\\\\: x)} \\\\) adj_matrix;\\nquery_idx: nodes ? (first first query[`source]);\\nreachable: nodes where iterated_matrix[query_idx]","author":"scott","implementation":""},{"task":"process_tweets","language":"sql","plan":{"lowercase":[{"line":0,"start":7,"end":18}],"select":[{"line":0,"start":19,"end":30},{"line":0,"start":0,"end":6}],"iter":[{"line":1,"start":0,"end":9}],"filter":[{"line":2,"start":0,"end":46}]},"source":"SELECT LOWER(body) as body, ts\\nFROM data\\nWHERE language = \\"en\\" and is_retweet = \\"false\\"","author":"scott","implementation":""},{"task":"process_tweets","language":"python-imperative","plan":{"iter":[{"line":2,"start":2,"end":20},{"line":1,"start":2,"end":13},{"line":9,"start":2,"end":15}],"filter":[{"line":3,"start":4,"end":37},{"line":4,"start":8,"end":40}],"lowercase":[{"line":6,"start":16,"end":38}],"select":[{"line":5,"start":6,"end":21},{"line":6,"start":8,"end":15},{"line":7,"start":8,"end":25},{"line":8,"start":6,"end":8}]},"source":"def process_tweets(data):\\n  result = []\\n  for value in data:\\n    if (value[\\"language\\"] == \\"en\\" and\\n        value[\\"is_retweet\\"] == \\"false\\"):\\n      result.append({\\n        \\"body\\": value[\\"body\\"].lower(),\\n        \\"ts\\": value[\\"ts\\"]\\n      })\\n  return result","author":"scott","implementation":""},{"task":"process_tweets","language":"python-functional","plan":{"lowercase":[{"line":2,"start":13,"end":34}],"filter":[{"line":5,"start":4,"end":36},{"line":6,"start":7,"end":37}],"select":[{"line":3,"start":5,"end":23},{"line":2,"start":4,"end":13}],"iter":[{"line":4,"start":4,"end":21},{"line":7,"start":2,"end":3},{"line":1,"start":2,"end":10}]},"source":"def process_tweets(data):\\n  return [\\n    {\\"body\\": value[\\"body\\"].lower(),\\n     \\"ts\\": value[\\"ts\\"]}\\n    for value in data\\n    if value[\\"language\\"] == \\"en\\" and\\n       value[\\"is_retweet\\"] == \\"false\\" \\n  ]","author":"scott","implementation":""},{"task":"process_tweets","language":"python-pandas","plan":{"iter":[{"line":1,"start":11,"end":15}],"filter":[{"line":1,"start":15,"end":16},{"line":2,"start":4,"end":29},{"line":3,"start":4,"end":33}],"lowercase":[{"line":4,"start":2,"end":54}],"select":[{"line":5,"start":2,"end":31}]},"source":"def process_tweets(data):\\n  result = data[\\n    (data.language == \'en\') &\\n    (data.is_retweet == \'false\')]\\n  result.body = result.body.apply(lambda s: s.lower())\\n  return result[[\\"body\\", \\"ts\\"]]","author":"scott","implementation":""},{"task":"process_tweets","language":"r","plan":{"iter":[{"line":1,"start":2,"end":10}],"filter":[{"line":2,"start":4,"end":56}],"select":[{"line":4,"start":4,"end":20}],"lowercase":[{"line":3,"start":4,"end":36}]},"source":"process_tweets <- function(data) {\\n  data %>%\\n    filter(language == \\"en\\" & is_retweet == \\"false\\") %>%\\n    mutate(body = tolower(body)) %>%\\n    select(ts, body)\\n}","author":"scott","implementation":""},{"task":"process_tweets","language":"q","plan":{"lowercase":[{"line":1,"start":9,"end":15},{"line":1,"start":19,"end":20}],"select":[{"line":1,"start":15,"end":19},{"line":1,"start":20,"end":24},{"line":1,"start":2,"end":9}],"iter":[{"line":1,"start":25,"end":34}],"filter":[{"line":2,"start":2,"end":56}]},"source":"process_tweets:\\n  select lower[body], ts from data \\n  where (is_retweet ~\\\\: \\"false\\") and (language ~\\\\: \\"en\\")","author":"scott","implementation":""},{"task":"changing_list","language":"python-imperative","plan":{},"source":"\\nimport copy\\ndef get_mean(ls):\\n  sum = 0\\n  for e in ls:\\n    sum += e[\'value\']\\n  return sum/len(ls)\\n\\ndef changing_list(list):\\n  start_mean = get_mean(list)\\n  for i,elem in enumerate(list):\\n    new_ls = copy.deepcopy(list)\\n    del new_ls[i]\\n    mean = get_mean(new_ls)\\n    if abs(mean - start_mean) < 0.1:\\n      return i\\n","author":"g","implementation":""},{"task":"changing_list","language":"datalog","plan":{},"source":"\\n    .decl avg(a:number)\\n    avg(first_sum/first_count) :-\\n      first_count = count : list(_, _),\\n      real_count = first_count - 1,\\n      first_sum = sum value:{list(_,value)}.\\n      \\n    changing_list(id):-\\n    avg(a),\\n    id = a.\\n","author":"g","implementation":""},{"task":"changing_list","language":"python-functional","plan":{},"source":"\\ndef changing_list(list):\\n  start_mean = sum([l[\'value\'] for l in list])/len(list)\\n  diff = lambda m, sm: abs(m - sm)\\n    \\n  for i,elem in enumerate(list):\\n    new_ls = [x[\'value\'] for x in list if x != elem]\\n    mean = sum(new_ls)/len(new_ls)\\n    if diff(mean,start_mean) < 0.1:\\n      return i\\n","author":"g","implementation":""},{"task":"average_window","language":"sql","plan":{"key":[{"line":2,"start":9,"end":30}],"group by":[{"line":2,"start":0,"end":8},{"line":1,"start":0,"end":9}],"average":[{"line":0,"start":7,"end":18}],"output_order":[{"line":3,"start":0,"end":13},{"line":3,"start":0,"end":13},{"line":3,"start":0,"end":13}]},"source":"SELECT AVG(x) as x\\nFROM data\\nGROUP BY cast(time / 7 as int)\\nORDER BY time","author":"scott","implementation":""},{"task":"average_window","language":"python-imperative","plan":{"key":[{"line":1,"start":2,"end":20},{"line":2,"start":4,"end":40}],"output_order":[{"line":5,"start":2,"end":36}],"group by":[{"line":9,"start":2,"end":24},{"line":10,"start":4,"end":31},{"line":11,"start":4,"end":37},{"line":7,"start":2,"end":34},{"line":3,"start":2,"end":19},{"line":4,"start":4,"end":13}],"average":[{"line":12,"start":6,"end":34},{"line":13,"start":6,"end":54},{"line":8,"start":2,"end":32},{"line":6,"start":2,"end":13},{"line":14,"start":4,"end":23},{"line":15,"start":4,"end":14},{"line":17,"start":2,"end":15},{"line":16,"start":2,"end":30}]},"source":"def average_window(data):\\n  def window(value):\\n    return math.floor(value[\\"time\\"] / 7)\\n  if len(data) < 1:\\n    return []\\n  data.sort(key=lambda v: v[\\"time\\"])\\n  result = []\\n  current_window = window(data[0])\\n  total, count = data[0][\\"x\\"], 1\\n  for value in data[1:]:\\n    time_window = window(value)\\n    if time_window != current_window:\\n      result.append(total / count)\\n      current_window, total, count = time_window, 0, 0\\n    total += value[\\"x\\"]\\n    count += 1\\n  result.append(total / count)\\n  return result","author":"scott","implementation":""},{"task":"average_window","language":"python-functional","plan":{"output_order":[{"line":5,"start":4,"end":35}],"group by":[{"line":3,"start":2,"end":20},{"line":4,"start":4,"end":56},{"line":5,"start":4,"end":35},{"line":6,"start":2,"end":3},{"line":9,"start":4,"end":32},{"line":7,"start":2,"end":10},{"line":10,"start":2,"end":3}],"key":[{"line":1,"start":2,"end":20},{"line":2,"start":4,"end":40}],"average":[{"line":8,"start":4,"end":29}]},"source":"def average_window(data):\\n  def window(value):\\n    return math.floor(value[\\"time\\"] / 7)\\n  grouped_values = [\\n    [point[\\"x\\"] for point in data if window(point) == w]\\n    for w in set(map(window, data))\\n  ]\\n  return [\\n    sum(values) / len(values)\\n    for values in grouped_values\\n  ]","author":"scott","implementation":""},{"task":"average_window","language":"python-pandas","plan":{"key":[{"line":1,"start":2,"end":16},{"line":2,"start":4,"end":28}],"output_order":[{"line":3,"start":12,"end":36}],"group by":[{"line":4,"start":35,"end":50},{"line":4,"start":17,"end":35},{"line":5,"start":2,"end":29},{"line":3,"start":2,"end":11}],"average":[{"line":4,"start":51,"end":57}]},"source":"def average_window(data):\\n  def window(t):\\n    return math.floor(t / 7)\\n  result = (data.sort_values(\\"time\\")\\n                .set_index(\\"time\\").groupby(window).mean())\\n  return result[\'x\'].tolist()","author":"scott","implementation":""},{"task":"average_window","language":"datalog","plan":{"average":[{"line":5,"start":18,"end":27},{"line":6,"start":2,"end":37},{"line":7,"start":6,"end":44}],"group by":[{"line":0,"start":0,"end":23},{"line":2,"start":0,"end":35},{"line":3,"start":0,"end":31},{"line":4,"start":0,"end":41},{"line":1,"start":0,"end":26}],"key":[{"line":1,"start":7,"end":10},{"line":3,"start":9,"end":12},{"line":1,"start":7,"end":10}],"output_order":[]},"source":".decl window(w: number)\\nwindow(t/7) :- data(t, _).\\n.decl windowed(w: number, x: float)\\nwindowed(t/7, x) :- data(t, x).\\n.decl windowed_total(w: number, x: float)\\nwindowed_total(w, total / n) :- window(w),\\n  total = sum x : { windowed(w, x) },\\n      n = sum z : { windowed(w, x), z=1.0 }.\\naverage_window(v) :- windowed_total(_, v).","author":"scott","implementation":""},{"task":"average_window","language":"r","plan":{"average":[{"line":3,"start":4,"end":33},{"line":4,"start":4,"end":13}],"key":[{"line":2,"start":19,"end":27}],"group by":[{"line":1,"start":2,"end":11},{"line":2,"start":4,"end":19},{"line":2,"start":28,"end":33}]},"source":"average_window <- function(data) {\\n  data %>% \\n    group_by(floor(time / 7)) %>% \\n    summarize(avg = mean(x)) %>% \\n    pull(avg)\\n}","author":"scott","implementation":""},{"task":"average_window","language":"q","plan":{"output_order":[{"line":1,"start":15,"end":22}],"average":[{"line":1,"start":23,"end":28}],"key":[{"line":1,"start":32,"end":33}],"group by":[{"line":1,"start":29,"end":31},{"line":1,"start":34,"end":43}]},"source":"average_window:\\n  (value select[<time] avg x by 7 xbar time from data) `x","author":"scott","implementation":""},{"task":"documents_with_infrequent_words","language":"python-pandas","plan":{"word":[{"line":1,"start":2,"end":52}],"frequency":[{"line":2,"start":2,"end":37},{"line":3,"start":2,"end":49}],"documents":[{"line":4,"start":2,"end":30},{"line":5,"start":4,"end":44},{"line":6,"start":2,"end":45}]},"source":"def documents_with_infrequent_words(documents):\\n  words = documents.text.str.split(\\" \\", expand=True)\\n  freq = words.stack().value_counts()\\n  infrequent_words = freq[freq == 1].index.values\\n  infrequent_docs = documents[\\n    np.isin(words.values, infrequent_words)]\\n  return infrequent_docs.id.unique().tolist()","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"sql","plan":{"word":[{"line":3,"start":0,"end":42},{"line":4,"start":2,"end":52},{"line":5,"start":0,"end":51},{"line":6,"start":0,"end":51}],"documents":[{"line":8,"start":0,"end":18},{"line":9,"start":0,"end":5},{"line":10,"start":2,"end":11},{"line":11,"start":2,"end":12},{"line":14,"start":26,"end":38},{"line":12,"start":2,"end":23},{"line":13,"start":3,"end":13},{"line":16,"start":2,"end":44},{"line":17,"start":2,"end":36},{"line":18,"start":2,"end":36},{"line":19,"start":2,"end":25},{"line":15,"start":0,"end":5}],"frequency":[{"line":14,"start":3,"end":24}]},"source":"-- NOTE: SQLite tokenize is case-insensitive by default, \\n-- so this solution is NOT exactly like the others\\n\\nCREATE VIRTUAL TABLE doc_index USING fts4(\\n  text, id, content=documents, tokenize=simple);    \\nINSERT INTO doc_index(doc_index) VALUES(\'rebuild\');\\nCREATE VIRTUAL TABLE words USING fts4aux(doc_index);    \\n\\nSELECT DISTINCT id\\nFROM \\n  documents\\n  CROSS JOIN\\n  (SELECT DISTINCT term\\n   FROM words\\n   WHERE occurrences = 1) unique_words\\nWHERE\\n  (LOWER(text) LIKE \'% \' || term || \' %\') OR\\n  (LOWER(text) LIKE term || \' %\') OR\\n  (LOWER(text) LIKE \'% \' || term) OR\\n  (LOWER(text) LIKE term)","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"datalog","plan":{"word":[{"line":0,"start":0,"end":50},{"line":1,"start":0,"end":23},{"line":2,"start":2,"end":39},{"line":3,"start":0,"end":27},{"line":4,"start":2,"end":49},{"line":5,"start":0,"end":29},{"line":6,"start":2,"end":57},{"line":8,"start":0,"end":63},{"line":9,"start":0,"end":32},{"line":10,"start":2,"end":25},{"line":11,"start":2,"end":26},{"line":12,"start":2,"end":35},{"line":13,"start":2,"end":42},{"line":14,"start":2,"end":53},{"line":15,"start":2,"end":32},{"line":16,"start":2,"end":23}],"frequency":[{"line":21,"start":2,"end":35}],"documents":[{"line":19,"start":2,"end":19},{"line":20,"start":2,"end":24}]},"source":".decl substrs(Text:symbol, Idx:number, Len:number)\\nsubstrs(Text, 0, 1) :- \\n  documents(_, Text), strlen(Text) > 0.\\nsubstrs(Text, 0, Len+1) :- \\n  substrs(Text, 0, Len), Len + 1 <= strlen(Text).\\nsubstrs(Text, Idx+1, Len) :- \\n  substrs(Text, Idx, Len), Idx + Len + 1 <= strlen(Text).\\n\\n.decl token(Docid:number, Text:symbol, Idx:number, Word:symbol)\\ntoken(Docid, Text, Idx, Word) :-\\n  documents(Docid, Text),\\n  substrs(Text, Idx, Len),\\n  Prev = Idx - 1, Next = Idx + Len,\\n  (Prev < 0; \\" \\" = substr(Text, Prev, 1)),\\n  (Next = strlen(Text); \\" \\" = substr(Text, Next, 1)),\\n  Word = substr(Text, Idx, Len),\\n  !contains(\\" \\", Word).\\n\\ndocuments_with_infrequent_words(Id) :-\\n  documents(Id, _),\\n  token(Id, _, _, Word),\\n  1 = count : token(_, _, _, Word).","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"q","plan":{"word":[{"line":0,"start":0,"end":38}],"frequency":[{"line":1,"start":0,"end":34},{"line":2,"start":0,"end":20}],"documents":[{"line":4,"start":2,"end":70}]},"source":"words: (\\" \\" vs) each documents[`text];\\nfreq: count each group raze words;\\nuniq: where[freq=1];\\ndocuments_with_infrequent_words:\\n  (select id from documents where \'[any; in\\\\: [;uniq]] each words) `id","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"python-functional","plan":{"word":[{"line":1,"start":2,"end":55}],"frequency":[{"line":2,"start":2,"end":46},{"line":3,"start":2,"end":10},{"line":4,"start":4,"end":33},{"line":5,"start":4,"end":31},{"line":6,"start":2,"end":3},{"line":7,"start":2,"end":26},{"line":8,"start":4,"end":41},{"line":9,"start":4,"end":17},{"line":10,"start":2,"end":4}],"documents":[{"line":11,"start":2,"end":21},{"line":12,"start":4,"end":53},{"line":13,"start":4,"end":42},{"line":14,"start":2,"end":3},{"line":15,"start":2,"end":24}]},"source":"def documents_with_infrequent_words(documents):\\n  words = [doc[\\"text\\"].split(\\" \\") for doc in documents]\\n  words_flat = [w for ws in words for w in ws]\\n  freq = {\\n    word: words_flat.count(word) \\n    for word in set(words_flat)\\n  }\\n  infrequent_words = set([\\n    word for word, count in freq.items() \\n    if count == 1\\n  ])\\n  infrequent_docs = [\\n    documents[i][\\"id\\"] for i, ws in enumerate(words) \\n    if len(set(ws) & infrequent_words) > 0\\n  ]\\n  return infrequent_docs","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"python-imperative","plan":{"word":[{"line":4,"start":23,"end":45}],"frequency":[{"line":1,"start":1,"end":12},{"line":2,"start":2,"end":25},{"line":3,"start":2,"end":23},{"line":4,"start":4,"end":22},{"line":5,"start":4,"end":33},{"line":6,"start":6,"end":21},{"line":8,"start":2,"end":26},{"line":9,"start":2,"end":34},{"line":10,"start":4,"end":18},{"line":11,"start":6,"end":32}],"documents":[{"line":13,"start":2,"end":22},{"line":14,"start":2,"end":23},{"line":15,"start":4,"end":33},{"line":16,"start":6,"end":34},{"line":17,"start":8,"end":41},{"line":18,"start":8,"end":13},{"line":20,"start":0,"end":24}]},"source":"def documents_with_infrequent_words(documents):\\n  words = {}\\n  freq = defaultdict(int)\\n  for doc in documents:\\n    words[doc[\\"id\\"]] = doc[\\"text\\"].split(\\" \\")\\n    for word in words[doc[\\"id\\"]]:\\n      freq[word] += 1\\n      \\n  infrequent_words = set()\\n  for word, count in freq.items():\\n    if count == 1:\\n      infrequent_words.add(word)\\n      \\n  infrequent_docs = []\\n  for doc in documents:\\n    for word in words[doc[\\"id\\"]]:\\n      if word in infrequent_words:\\n        infrequent_docs.append(doc[\\"id\\"])\\n        break\\n        \\n  return infrequent_docs","author":"will","implementation":""},{"task":"documents_with_infrequent_words","language":"r","plan":{"documents":[{"line":6,"start":2,"end":12},{"line":7,"start":4,"end":43},{"line":8,"start":4,"end":16},{"line":9,"start":4,"end":12}],"frequency":[{"line":4,"start":2,"end":31},{"line":5,"start":2,"end":41}],"word":[{"line":1,"start":2,"end":24},{"line":2,"start":4,"end":43},{"line":3,"start":4,"end":12}]},"source":"documents_with_infrequent_words <- function(documents) {\\n  split <- documents %>%\\n    mutate(word = str_split(text, \\" \\")) %>%\\n    unnest()\\n  freq <- split %>% count(word)\\n  unique_words <- freq %>% filter(n == 1)\\n  split %>% \\n    filter(word %in% unique_words$word) %>%\\n    pull(id) %>%\\n    unique()\\n}","author":"will","implementation":""},{"task":"row_per_child","language":"python-pandas","plan":{"each-family":[{"line":2,"start":4,"end":12}],"child-ID":[{"line":7,"start":2,"end":48}],"family-ID":[{"line":5,"start":4,"end":14}],"each-child":[{"line":6,"start":4,"end":13},{"line":4,"start":4,"end":17},{"line":1,"start":7,"end":23}],"dob-height":[{"line":3,"start":4,"end":32}]},"source":"def row_per_child(families):\\n  df = pd.wide_to_long(\\n    families, \\n    stubnames=[\'dob\', \'height\'], \\n    sep=\\"_child\\", \\n    i=\'family\', \\n    j=\'child\').reset_index()\\n  df.child = df.child.map(lambda c: f\'child{c}\')\\n  return df","author":"will","implementation":""},{"task":"row_per_child","language":"sql","plan":{"child-ID":[{"line":2,"start":2,"end":30}],"dob-height":[{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":27},{"line":5,"start":4,"end":27},{"line":6,"start":4,"end":27},{"line":7,"start":3,"end":15},{"line":8,"start":2,"end":14},{"line":9,"start":4,"end":30},{"line":10,"start":4,"end":30},{"line":11,"start":4,"end":30},{"line":12,"start":3,"end":17}],"each-family":[{"line":13,"start":0,"end":5},{"line":14,"start":2,"end":10}],"each-child":[{"line":15,"start":2,"end":12},{"line":16,"start":2,"end":43}],"family-ID":[{"line":1,"start":2,"end":8}]},"source":"SELECT \\n  family,\\n  (\'child\' || child) AS child,\\n  (CASE child \\n    WHEN 1 THEN dob_child1 \\n    WHEN 2 THEN dob_child2 \\n    WHEN 3 THEN dob_child3 \\n   END) AS dob,\\n  (CASE child \\n    WHEN 1 THEN height_child1 \\n    WHEN 2 THEN height_child2 \\n    WHEN 3 THEN height_child3 \\n   END) AS height\\nFROM \\n  families\\n  CROSS JOIN\\n  (SELECT 1 as child UNION VALUES (2), (3))","author":"will","implementation":""},{"task":"row_per_child","language":"datalog","plan":{"each-family":[{"line":1,"start":2,"end":11},{"line":1,"start":42,"end":43},{"line":3,"start":2,"end":11},{"line":3,"start":42,"end":43},{"line":5,"start":2,"end":11},{"line":5,"start":42,"end":43}],"each-child":[{"line":0,"start":0,"end":47},{"line":2,"start":0,"end":47},{"line":4,"start":0,"end":47}],"family-ID":[{"line":1,"start":22,"end":28},{"line":3,"start":22,"end":28},{"line":5,"start":22,"end":28}],"child-ID":[{"line":0,"start":14,"end":22},{"line":2,"start":14,"end":22},{"line":4,"start":14,"end":22}],"dob-height":[{"line":1,"start":11,"end":14},{"line":1,"start":30,"end":36},{"line":3,"start":14,"end":17},{"line":3,"start":33,"end":39},{"line":5,"start":17,"end":20},{"line":5,"start":36,"end":42}]},"source":"row_per_child(\\"child1\\", dob, family, height) :-\\n  families(dob, _, _, family, height, _, _).\\nrow_per_child(\\"child2\\", dob, family, height) :-\\n  families(_, dob, _, family, _, height, _).\\nrow_per_child(\\"child3\\", dob, family, height) :-\\n  families(_, _, dob, family, _, _, height).","author":"will","implementation":""},{"task":"row_per_child","language":"q","plan":{"each-family":[{"line":1,"start":8,"end":28},{"line":2,"start":63,"end":64}],"each-child":[{"line":5,"start":15,"end":51},{"line":0,"start":0,"end":20},{"line":3,"start":66,"end":67}],"family-ID":[{"line":2,"start":5,"end":13}],"dob-height":[{"line":2,"start":14,"end":62}],"child-ID":[{"line":3,"start":2,"end":66}]},"source":"child_rows: {[child] \\n  rows: ?[families; (); 0b; `family`dob`height ! \\n    (`family; `$(\\"dob_child\\",child); `$(\\"height_child\\", child))];\\n  update child: (count families)#enlist (\\"child\\", child) from rows}\\n      \\nrow_per_child: (child_rows each (\\"1\\"; \\"2\\"; \\"3\\")) ,/;","author":"will","implementation":""},{"task":"row_per_child","language":"python-functional","plan":{"each-family":[{"line":6,"start":4,"end":26}],"each-child":[{"line":7,"start":4,"end":22}],"family-ID":[{"line":2,"start":5,"end":32}],"child-ID":[{"line":3,"start":5,"end":26}],"dob-height":[{"line":4,"start":5,"end":36},{"line":5,"start":5,"end":41}]},"source":"def row_per_child(families):\\n  return [\\n    {\'family\': family[\'family\'],\\n     \'child\': f\'child{i}\',\\n     \'dob\': family[f\'dob_child{i}\'],\\n     \'height\': family[f\'height_child{i}\']}\\n    for family in families    \\n    for i in [1, 2, 3]\\n  ]","author":"will","implementation":""},{"task":"row_per_child","language":"python-imperative","plan":{"each-family":[{"line":3,"start":2,"end":25}],"family-ID":[{"line":6,"start":8,"end":35}],"each-child":[{"line":4,"start":4,"end":23},{"line":5,"start":6,"end":23},{"line":10,"start":6,"end":8}],"child-ID":[{"line":7,"start":8,"end":29}],"dob-height":[{"line":8,"start":8,"end":39},{"line":9,"start":8,"end":44}]},"source":"\\ndef row_per_child(families):\\n  children = []\\n  for family in families:\\n    for i in [1, 2, 3]:\\n      children.append({\\n        \'family\': family[\'family\'],\\n        \'child\': f\'child{i}\',\\n        \'dob\': family[f\'dob_child{i}\'],\\n        \'height\': family[f\'height_child{i}\']\\n      })\\n  return children\\n","author":"will","implementation":""},{"task":"row_per_child","language":"r","plan":{"each-family":[{"line":1,"start":2,"end":14}],"family-ID":[{"line":3,"start":6,"end":13}],"each-child":[{"line":4,"start":6,"end":38},{"line":5,"start":6,"end":22}],"child-ID":[{"line":2,"start":4,"end":17},{"line":6,"start":4,"end":5}],"dob-height":[{"line":2,"start":4,"end":17},{"line":6,"start":4,"end":5}]},"source":"row_per_child <- function(families) {\\n  families %>%\\n    pivot_longer(\\n      !family,\\n      names_to = c(\\".value\\", \\"child\\"),\\n      names_sep = \\"_\\",\\n    )\\n}","author":"will","implementation":""},{"task":"rolling_average","language":"sql","plan":{"windows":[{"line":2,"start":0,"end":16},{"line":0,"start":0,"end":6},{"line":1,"start":0,"end":21}],"group":[{"line":3,"start":0,"end":18},{"line":4,"start":0,"end":29},{"line":5,"start":3,"end":28},{"line":6,"start":0,"end":17}],"filter":[{"line":1,"start":23,"end":46}]},"source":"SELECT\\nend.time as end_time,  AVG(other.x) as average\\nFROM data as end\\nJOIN data as other\\nON other.time <= end.time and\\n   other.time > end.time - 7\\nGROUP BY end.time","author":"scott","implementation":""},{"task":"rolling_average","language":"python-imperative","plan":{"windows":[{"line":3,"start":2,"end":34},{"line":2,"start":2,"end":13},{"line":10,"start":4,"end":18},{"line":11,"start":6,"end":23},{"line":14,"start":2,"end":15}],"group":[{"line":6,"start":4,"end":30},{"line":7,"start":6,"end":36},{"line":8,"start":8,"end":13},{"line":1,"start":2,"end":36},{"line":4,"start":4,"end":23}],"filter":[{"line":9,"start":6,"end":39},{"line":5,"start":4,"end":25},{"line":12,"start":7,"end":31}]},"source":"def rolling_average(data):\\n  data.sort(key=lambda v: v[\\"time\\"])\\n  result = []\\n  for i, value in enumerate(data):\\n    end = value[\\"time\\"]\\n    total, count = 0.0, 0\\n    for j in range(i, -1, -1):\\n      if data[j][\\"time\\"] <= end - 7:\\n        break\\n      total += data[j][\\"x\\"]; count += 1\\n    result.append(\\n      {\\"end_time\\": end,\\n       \\"average\\": total / count}\\n    )\\n  return result","author":"scott","implementation":""},{"task":"rolling_average","language":"python-functional","plan":{"filter":[{"line":3,"start":5,"end":34}],"windows":[{"line":4,"start":4,"end":17},{"line":1,"start":2,"end":10},{"line":2,"start":4,"end":27}],"group":[{"line":6,"start":7,"end":27},{"line":7,"start":14,"end":43},{"line":8,"start":17,"end":42},{"line":5,"start":8,"end":10}]},"source":"def rolling_average(data):\\n  return [\\n    {\\"end_time\\": x[\\"time\\"],\\n     \\"average\\": sum(vs) / len(vs)}\\n    for x in data\\n    for vs in [\\n      [y[\\"x\\"] for y in data\\n              if y[\\"time\\"] <= x[\\"time\\"] and\\n                 y[\\"time\\"] > x[\\"time\\"] - 7]\\n    ]\\n  ]","author":"scott","implementation":""},{"task":"rolling_average","language":"python-pandas","plan":{"filter":[{"line":5,"start":36,"end":42},{"line":9,"start":5,"end":37}],"group":[{"line":5,"start":15,"end":35},{"line":3,"start":2,"end":47}],"windows":[{"line":4,"start":2,"end":52},{"line":1,"start":2,"end":17},{"line":7,"start":2,"end":32},{"line":8,"start":4,"end":58}]},"source":"def rolling_average(data):\\n  d = data.copy()\\n\\n  data.time = pd.to_datetime(data.time * 10**9)\\n  data = (data.sort_values(\'time\').set_index(\'time\')\\n              .rolling(window=\'7s\').mean())\\n\\n  return pd.DataFrame.from_dict(\\n    {\'end_time\': d.sort_values(\'time\').reset_index().time,\\n     \'average\': data.reset_index().x}\\n  )","author":"scott","implementation":""},{"task":"rolling_average","language":"datalog","plan":{"group":[{"line":0,"start":0,"end":44},{"line":1,"start":0,"end":22},{"line":2,"start":2,"end":32},{"line":3,"start":2,"end":34},{"line":6,"start":31,"end":50},{"line":7,"start":31,"end":50}],"filter":[{"line":6,"start":2,"end":15},{"line":7,"start":6,"end":15},{"line":8,"start":0,"end":31},{"line":9,"start":2,"end":44},{"line":7,"start":52,"end":59}],"windows":[{"line":5,"start":30,"end":47},{"line":9,"start":2,"end":17},{"line":4,"start":0,"end":54},{"line":5,"start":0,"end":26},{"line":6,"start":19,"end":29},{"line":7,"start":19,"end":29}]},"source":".decl window(end_time: number, time: number)\\nwindow(end_time, t) :-\\n  data(end_time, _), data(t, _),\\n  t <= end_time, t > end_time - 7.\\n.decl bucket(end_time: number, total: float, n: float)\\nbucket(end_time, total, n) :- data(end_time, _),\\n  total = sum v : {data(t, v), window(end_time, t)},\\n      n = sum z : {data(t, _), window(end_time, t), z = 1.0}.\\nrolling_average(end_time, v) :-\\n  bucket(end_time, total, n), v = total / n.","author":"scott","implementation":""},{"task":"rolling_average","language":"r","plan":{"group":[{"line":3,"start":59,"end":72},{"line":3,"start":10,"end":47}],"filter":[{"line":3,"start":48,"end":59},{"line":3,"start":2,"end":10},{"line":4,"start":35,"end":49},{"line":4,"start":72,"end":79}]},"source":"library(slider)\\nrolling_average <- function(data) {\\n  data <- arrange(data, time)\\n  avgs <- unlist(slide_index(data$x, data$time, ~ mean(.x), .before = 6))\\n  data %>% mutate(end_time = time, average = avgs) %>% select(end_time, average)\\n}","author":"scott","implementation":""},{"task":"rolling_average","language":"q","plan":{"filter":[{"line":1,"start":15,"end":21},{"line":3,"start":25,"end":48},{"line":1,"start":8,"end":15}],"group":[{"line":1,"start":22,"end":61}],"windows":[{"line":3,"start":49,"end":58},{"line":3,"start":2,"end":23}]},"source":"get_avg: \\n  {[t] (select avg(x) from data where time within (t - 6; t)) `x};\\nrolling_average: \\n  select end_time: time, average: get_avg\'[time] from data","author":"scott","implementation":""},{"task":"unique_beer_drinkers","language":"python-pandas","plan":{"iter":[{"line":1,"start":22,"end":27},{"line":2,"start":4,"end":20},{"line":1,"start":2,"end":22},{"line":11,"start":1,"end":37},{"line":12,"start":52,"end":53},{"line":13,"start":2,"end":38}],"collect":[{"line":3,"start":4,"end":27},{"line":4,"start":4,"end":18},{"line":1,"start":2,"end":22}],"compare":[{"line":6,"start":2,"end":28},{"line":7,"start":4,"end":36},{"line":8,"start":6,"end":43},{"line":9,"start":4,"end":55},{"line":12,"start":4,"end":52}]},"source":"def unique_beer_drinkers(likes):\\n  likes_per_person = (likes\\n    .groupby(\'name\')\\n    .beer.unique().map(set)\\n    .reset_index())\\n\\n  def check_not_exists(row):\\n    other_people = likes_per_person[\\n      likes_per_person.name != row[\'name\']]\\n    return not (other_people.beer == row[\'beer\']).any()\\n  \\n  unique_drinkers = likes_per_person[\\n    likes_per_person.apply(check_not_exists, axis=1)]\\n  return unique_drinkers.name.tolist()","author":"will","implementation":""},{"task":"unique_beer_drinkers","language":"datalog","plan":{"iter":[{"line":11,"start":21,"end":25},{"line":12,"start":2,"end":17}],"compare":[{"line":13,"start":2,"end":20},{"line":4,"start":0,"end":27},{"line":5,"start":0,"end":20},{"line":7,"start":2,"end":18},{"line":8,"start":2,"end":16},{"line":6,"start":2,"end":18},{"line":9,"start":2,"end":23},{"line":1,"start":0,"end":16},{"line":1,"start":30,"end":61},{"line":2,"start":0,"end":46},{"line":0,"start":0,"end":32}],"collect":[{"line":1,"start":16,"end":30},{"line":2,"start":46,"end":60}]},"source":".decl differ(a:symbol, b:symbol)\\ndiffer(A, B) :- likes(Beer, A), likes(_, B), !likes(Beer, B).\\ndiffer(A, B) :- likes(_, A), likes(Beer, B), !likes(Beer, A).\\n\\n.decl exists_same(a:symbol)\\nexists_same(Name) :- \\n  likes(_, Other), \\n  likes(_, Name), \\n  Name != Other, \\n  !differ(Name, Other).\\n\\nunique_beer_drinkers(Name) :- \\n  likes(_, Name), \\n  !exists_same(Name).","author":"will","implementation":"neg_exist"},{"task":"unique_beer_drinkers","language":"sql","plan":{"iter":[{"line":0,"start":0,"end":23},{"line":1,"start":0,"end":13}],"compare":[{"line":2,"start":0,"end":17},{"line":23,"start":34,"end":35},{"line":3,"start":4,"end":12},{"line":4,"start":4,"end":17},{"line":5,"start":4,"end":28},{"line":6,"start":4,"end":19},{"line":7,"start":8,"end":16},{"line":8,"start":8,"end":21},{"line":9,"start":8,"end":31},{"line":10,"start":8,"end":23},{"line":14,"start":12,"end":35},{"line":15,"start":4,"end":19},{"line":19,"start":8,"end":23},{"line":20,"start":12,"end":20},{"line":21,"start":12,"end":25},{"line":22,"start":12,"end":35},{"line":23,"start":12,"end":35}],"collect":[{"line":11,"start":12,"end":20},{"line":12,"start":12,"end":25},{"line":13,"start":12,"end":35},{"line":16,"start":8,"end":16},{"line":17,"start":8,"end":21},{"line":18,"start":8,"end":31}]},"source":"SELECT DISTINCT L1.name\\nFROM likes L1\\nWHERE NOT EXISTS(\\n    SELECT *\\n    FROM likes L2\\n    WHERE L1.name != L2.name\\n    AND NOT EXISTS(\\n        SELECT *\\n        FROM likes L3\\n        WHERE L3.name = L2.name\\n        AND NOT EXISTS(\\n            SELECT *\\n            FROM likes L4\\n            WHERE L4.name = L1.name\\n            AND L4.beer = L3.beer))\\n    AND NOT EXISTS(\\n        SELECT *\\n        FROM likes L5\\n        WHERE L5.name = L1.name\\n        AND NOT EXISTS(\\n            SELECT *\\n            FROM likes L6\\n            WHERE L6.name = L2.name\\n            AND L6.beer= L5.beer)))","author":"will","implementation":""},{"task":"unique_beer_drinkers","language":"q","plan":{"collect":[{"line":0,"start":0,"end":37}],"compare":[{"line":1,"start":0,"end":42},{"line":3,"start":43,"end":68}],"iter":[{"line":3,"start":3,"end":42},{"line":4,"start":2,"end":7}]},"source":"likes_per_person: `name xgroup likes;\\ncounts: count each group likes_per_person;\\nunique_beer_drinkers: \\n  (select name from likes_per_person where beer in\\\\: where[counts=1])\\n  `name","author":"will","implementation":""},{"task":"unique_beer_drinkers","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":46},{"line":4,"start":4,"end":22},{"line":5,"start":2,"end":3},{"line":2,"start":2,"end":22},{"line":3,"start":4,"end":9},{"line":7,"start":2,"end":10},{"line":8,"start":4,"end":8},{"line":9,"start":4,"end":13},{"line":9,"start":20,"end":47},{"line":14,"start":2,"end":3}],"collect":[{"line":3,"start":10,"end":68},{"line":9,"start":13,"end":47}],"compare":[{"line":10,"start":4,"end":16},{"line":11,"start":6,"end":49},{"line":12,"start":6,"end":61},{"line":13,"start":4,"end":6}]},"source":"def unique_beer_drinkers(likes):\\n  people = set([row[\'name\'] for row in likes])\\n  likes_per_person = {\\n    name: set([row[\'beer\'] for row in likes if row[\'name\'] == name])\\n    for name in people\\n  }\\n    \\n  return [\\n    name\\n    for name, beers in likes_per_person.items()\\n    if not any([\\n      other_name != name and beers == other_beers\\n      for other_name, other_beers in likes_per_person.items()\\n    ])\\n  ]","author":"will","implementation":""},{"task":"unique_beer_drinkers","language":"python-imperative","plan":{"collect":[{"line":1,"start":21,"end":37},{"line":3,"start":33,"end":50},{"line":6,"start":10,"end":47},{"line":18,"start":2,"end":15}],"iter":[{"line":2,"start":2,"end":19},{"line":3,"start":4,"end":33},{"line":5,"start":2,"end":13},{"line":6,"start":2,"end":9},{"line":6,"start":19,"end":47}],"compare":[{"line":7,"start":4,"end":20},{"line":8,"start":4,"end":49},{"line":9,"start":6,"end":18},{"line":10,"start":8,"end":16},{"line":12,"start":6,"end":30},{"line":13,"start":8,"end":25},{"line":14,"start":8,"end":13},{"line":15,"start":4,"end":17},{"line":16,"start":6,"end":23}]},"source":"def unique_beer_drinkers(likes):\\n  likes_per_person = defaultdict(set)\\n  for row in likes:\\n    likes_per_person[row[\'name\']].add(row[\'beer\'])\\n    \\n  unique = []\\n  for p1, p1_likes in likes_per_person.items():\\n    is_unique = True\\n    for p2, p2_likes in likes_per_person.items():\\n      if p1 == p2:\\n        continue\\n        \\n      if p1_likes == p2_likes:\\n        is_unique = False\\n        break\\n    if is_unique:\\n      unique.append(p1)\\n      \\n  return unique","author":"will","implementation":""},{"task":"unique_beer_drinkers","language":"r","plan":{"iter":[{"line":1,"start":2,"end":11},{"line":2,"start":4,"end":22},{"line":6,"start":4,"end":14}],"collect":[{"line":3,"start":4,"end":54}],"compare":[{"line":4,"start":4,"end":54},{"line":5,"start":4,"end":37}]},"source":"unique_beer_drinkers <- function(likes) {\\n  likes %>%\\n    group_by(name) %>%\\n    summarize(beer_set = list(sort(unique(beer)))) %>%\\n    add_count(beer_set, name = \'num_people_likes\') %>%\\n    filter(num_people_likes == 1) %>%\\n    pull(name)\\n}","author":"will","implementation":""},{"task":"purchased_all_food","language":"python-pandas","plan":{"iter":[{"line":2,"start":21,"end":27},{"line":3,"start":4,"end":21},{"line":6,"start":2,"end":25},{"line":6,"start":50,"end":64}],"all":[{"line":1,"start":2,"end":20},{"line":6,"start":25,"end":50}],"ordered":[{"line":2,"start":2,"end":21},{"line":4,"start":4,"end":19},{"line":5,"start":4,"end":14}]},"source":"def purchased_all_food(food, orders):\\n  n_food = len(food)\\n  n_unique_orders = (orders\\n    .groupby(\'buyer\')\\n    .food.unique() \\n    .map(len))\\n  return n_unique_orders[n_unique_orders == n_food].index.values","author":"will","implementation":""},{"task":"purchased_all_food","language":"sql","plan":{"iter":[{"line":0,"start":0,"end":21},{"line":1,"start":0,"end":14}],"ordered":[{"line":3,"start":2,"end":46},{"line":4,"start":3,"end":29}],"all":[{"line":5,"start":2,"end":29},{"line":4,"start":30,"end":31}]},"source":"SELECT DISTINCT buyer\\nFROM orders o1\\nWHERE \\n  (SELECT COUNT(DISTINCT food) FROM orders o2 \\n   WHERE o1.buyer = o2.buyer) = \\n  (SELECT COUNT(*) FROM food)","author":"will","implementation":""},{"task":"purchased_all_food","language":"datalog","plan":{"ordered":[{"line":0,"start":0,"end":46},{"line":1,"start":0,"end":53},{"line":6,"start":2,"end":52}],"all":[{"line":5,"start":2,"end":30},{"line":7,"start":2,"end":27}],"iter":[{"line":4,"start":2,"end":22},{"line":3,"start":19,"end":24}]},"source":".decl has_purchased(Buyer:symbol, Food:number)\\nhas_purchased(Buyer, Food) :- orders(Buyer, Food, _).\\n\\npurchased_all_food(Buyer) :-\\n  orders(Buyer, _, _),\\n  N_food = count : food(_, _),\\n  N_unique_orders = count : has_purchased(Buyer, _),\\n  N_food = N_unique_orders.","author":"will","implementation":""},{"task":"purchased_all_food","language":"q","plan":{"iter":[{"line":3,"start":45,"end":56}],"ordered":[{"line":0,"start":0,"end":29}],"all":[{"line":3,"start":3,"end":44},{"line":1,"start":0,"end":18}]},"source":"buyers: `buyer xgroup orders;\\ntotal: count food;\\npurchased_all_food:\\n  (where {(count distinct x[`food]) = total} each buyers) `buyer","author":"will","implementation":""},{"task":"purchased_all_food","language":"python-functional","plan":{"iter":[{"line":2,"start":4,"end":54},{"line":4,"start":8,"end":13},{"line":5,"start":8,"end":27}],"all":[{"line":1,"start":4,"end":22},{"line":7,"start":43,"end":52},{"line":6,"start":8,"end":10}],"ordered":[{"line":6,"start":11,"end":54},{"line":7,"start":13,"end":42}]},"source":"def purchased_all_food(food, orders):\\n    n_food = len(food)\\n    buyers = set([order[\\"buyer\\"] for order in orders])\\n    return [\\n        buyer\\n        for buyer in buyers\\n        if len(set([order[\\"food\\"] for order in orders \\n             if order[\\"buyer\\"] == buyer])) == n_food\\n    ]","author":"will","implementation":""},{"task":"purchased_all_food","language":"python-imperative","plan":{"all":[{"line":1,"start":2,"end":20},{"line":8,"start":4,"end":29}],"ordered":[{"line":2,"start":2,"end":34},{"line":3,"start":2,"end":22},{"line":4,"start":4,"end":18},{"line":4,"start":32,"end":52},{"line":7,"start":13,"end":45}],"iter":[{"line":4,"start":18,"end":32},{"line":6,"start":2,"end":13},{"line":7,"start":2,"end":12},{"line":7,"start":20,"end":45},{"line":9,"start":6,"end":26},{"line":10,"start":2,"end":15}]},"source":"def purchased_all_food(food, orders):\\n  n_food = len(food)\\n  unique_orders = defaultdict(set)\\n  for order in orders:\\n    unique_orders[order[\\"buyer\\"]].add(order[\\"food\\"])\\n      \\n  buyers = []\\n  for buyer, orders in unique_orders.items():\\n    if len(orders) == n_food:\\n      buyers.append(buyer)\\n  return buyers","author":"will","implementation":""},{"task":"purchased_all_food","language":"r","plan":{"iter":[{"line":2,"start":2,"end":12},{"line":3,"start":4,"end":23},{"line":7,"start":4,"end":14}],"ordered":[{"line":4,"start":4,"end":22}],"all":[{"line":5,"start":4,"end":15},{"line":6,"start":4,"end":27},{"line":1,"start":2,"end":23}]},"source":"purchased_all_food <- function(food, orders) {\\n  n_food <- count(food)    \\n  orders %>%\\n    group_by(buyer) %>%\\n    distinct(food) %>%\\n    count() %>%\\n    filter(n == n_food) %>%\\n    pull(buyer)\\n}","author":"will","implementation":""},{"task":"customer_orders","language":"python-imperative","plan":{"order_ids":[{"line":7,"start":22,"end":34}],"California":[{"line":6,"start":8,"end":48}],"customer":[{"line":4,"start":4,"end":30}]},"source":"  \\ndef customer_orders(customers,orders):\\n  oids = []\\n  for order in orders:\\n    for customer in customers:\\n      if customer[\'cid\'] == order[\'cid\']:\\n        if customer[\'location\'] == \\"California\\":\\n          oids.append(order[\'oid\'])\\n  return oids\\n","author":"g","implementation":""},{"task":"customer_orders","language":"python-pandas","plan":{"order_ids":[{"line":4,"start":9,"end":28}],"California":[{"line":3,"start":22,"end":56}],"customer":[{"line":2,"start":23,"end":42}]},"source":"  \\ndef customer_orders(customers,orders):\\n  joined = orders.join(customers, on=\\"cid\\",how=\\"inner\\",lsuffix=\\"_j\\")\\n  joined = joined.loc[joined[\'location\'] == \\"California\\"]\\n  return joined.oid.tolist()\\n\\n","author":"g","implementation":""},{"task":"customer_orders","language":"r","plan":{"order_ids":[{"line":4,"start":4,"end":13},{"line":3,"start":4,"end":38}],"customer":[{"line":1,"start":2,"end":15}],"California":[{"line":2,"start":4,"end":40}]},"source":"customer_orders <- function(customers, orders) {\\n  customers %>%\\n    filter(location == \\"California\\") %>%\\n    inner_join(orders, by = \\"cid\\") %>%\\n    pull(oid)\\n}","author":"g","implementation":""},{"task":"customer_orders","language":"q","plan":{"order_ids":[{"line":1,"start":3,"end":25},{"line":2,"start":35,"end":39}],"California":[{"line":2,"start":2,"end":33}],"customer":[{"line":1,"start":26,"end":50}]},"source":"customer_orders: {[customers; orders]\\n  (select oid from orders ij (`cid xkey customers) \\n  where location ~\\\\: \\"California\\") `oid}","author":"g","implementation":""},{"task":"customer_orders","language":"sql","plan":{"California":[{"line":5,"start":0,"end":27}],"order_ids":[{"line":1,"start":0,"end":18}],"customer":[{"line":3,"start":1,"end":31},{"line":4,"start":0,"end":26}]},"source":"  \\nSELECT orders.oid \\nFROM \\n(orders INNER JOIN customers ON\\norders.cid = customers.cid) \\nWHERE location=\\"California\\"\\n","author":"g","implementation":""},{"task":"customer_orders","language":"datalog","plan":{"California":[{"line":2,"start":25,"end":37}],"customer":[{"line":2,"start":2,"end":24}],"order_ids":[{"line":3,"start":15,"end":18}]},"source":"  \\ncustomer_orders(oid):-\\n  customers(cid,customer,\\"California\\"),\\n  orders(cid,_,oid,_).\\n","author":"g","implementation":""},{"task":"customer_orders","language":"python-functional","plan":{"order_ids":[{"line":5,"start":10,"end":42}],"California":[{"line":4,"start":4,"end":43}],"customer":[{"line":3,"start":10,"end":51},{"line":6,"start":7,"end":27}]},"source":"  \\ndef customer_orders(customers,orders):\\n  oids = []\\n  cids = [customer[\'cid\'] for customer in customers\\n    if customer[\'location\'] == \\"California\\"]\\n  oids = [order[\'oid\'] for order in orders \\n    if order[\'cid\'] in cids]\\n  return oids\\n","author":"g","implementation":""},{"task":"changing_mean","language":"python-imperative","plan":{"remove":[{"line":10,"start":4,"end":34}],"new":[{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":11,"start":4,"end":27},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20}],"diff":[{"line":12,"start":4,"end":36}],"orig":[{"line":8,"start":2,"end":29},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9},{"line":3,"start":2,"end":14},{"line":4,"start":4,"end":21},{"line":5,"start":2,"end":20},{"line":1,"start":0,"end":17},{"line":2,"start":2,"end":9}],"first":[{"line":13,"start":6,"end":14},{"line":14,"start":2,"end":13}]},"source":"\\ndef get_mean(ls):\\n  sum = 0\\n  for e in ls:\\n    sum += e[\'value\']\\n  return sum/len(ls)\\n\\ndef changing_mean(vals):\\n  start_mean = get_mean(vals)\\n  for i,elem in enumerate(vals):\\n    new_ls = vals[:i] + vals[i+1:]\\n    mean = get_mean(new_ls)\\n    if abs(mean - start_mean) < 0.1:\\n      return i\\n  return None\\n","author":"g","implementation":""},{"task":"changing_mean","language":"python-pandas","plan":{"diff":[{"line":4,"start":14,"end":47}],"new":[{"line":3,"start":2,"end":85},{"line":4,"start":9,"end":60}],"orig":[{"line":2,"start":2,"end":26}],"remove":[{"line":4,"start":9,"end":60},{"line":3,"start":45,"end":63}],"first":[{"line":4,"start":9,"end":60}]},"source":"\\ndef changing_mean(vals):\\n  mean = vals.value.mean()\\n  mean_without = vals.apply(lambda row: vals[vals.id != row.id].value.mean(), axis=1)\\n  return vals[(mean_without - mean).abs() < 0.1].id.tolist()\\n","author":"g","implementation":""},{"task":"changing_mean","language":"r","plan":{"remove":[{"line":4,"start":43,"end":65}],"orig":[{"line":4,"start":38,"end":43},{"line":4,"start":65,"end":66},{"line":4,"start":24,"end":35},{"line":2,"start":3,"end":34}],"new":[{"line":4,"start":36,"end":37},{"line":4,"start":5,"end":24},{"line":4,"start":66,"end":68}],"first":[{"line":7,"start":5,"end":29},{"line":8,"start":5,"end":13},{"line":3,"start":3,"end":16},{"line":5,"start":5,"end":17}],"diff":[{"line":6,"start":5,"end":34}]},"source":"library(data.table)\\nchanging_mean <- function(vals) {\\n   global_mean <- mean(vals$value)\\n   setDT(vals)[, \\n     mean_change := abs(global_mean - mean(vals[id != .BY, value])), \\n     by = id] %>%\\n     filter(mean_change < 0.1) %>%\\n     slice(which.min(id)) %>%\\n     pull(id)\\n}","author":"g","implementation":""},{"task":"changing_mean","language":"q","plan":{"remove":[{"line":1,"start":44,"end":64}],"orig":[{"line":1,"start":7,"end":23},{"line":1,"start":26,"end":43}],"new":[{"line":1,"start":3,"end":6},{"line":1,"start":23,"end":26}],"diff":[{"line":4,"start":31,"end":48}],"first":[{"line":4,"start":15,"end":20},{"line":4,"start":20,"end":30}]},"source":"diffs: \\n  {abs avg vals[`value] - avg (vals[`value] where vals[`id] <> x)} \\n  each vals[`id];\\n  \\nchanging_mean: first vals[`id] where diffs < 0.1","author":"g","implementation":""},{"task":"changing_mean","language":"sql","plan":{"diff":[{"line":6,"start":35,"end":40},{"line":2,"start":6,"end":11}],"new":[{"line":3,"start":2,"end":19},{"line":4,"start":2,"end":14},{"line":5,"start":2,"end":22},{"line":2,"start":6,"end":11},{"line":3,"start":2,"end":19},{"line":4,"start":2,"end":14},{"line":5,"start":2,"end":22},{"line":6,"start":0,"end":34}],"orig":[{"line":6,"start":5,"end":32}],"remove":[{"line":5,"start":2,"end":22},{"line":5,"start":2,"end":22}],"first":[{"line":0,"start":0,"end":9}]},"source":"SELECT id\\nFROM vals v1\\nWHERE ABS((\\n  SELECT AVG(value)\\n  FROM vals v2\\n  WHERE v1.id != v2.id\\n) - (SELECT AVG(value) FROM vals)) < 0.1","author":"g","implementation":""},{"task":"changing_mean","language":"datalog","plan":{"orig":[{"line":9,"start":2,"end":27},{"line":10,"start":2,"end":29},{"line":11,"start":2,"end":18}],"new":[{"line":12,"start":2,"end":27},{"line":1,"start":0,"end":22},{"line":2,"start":2,"end":13},{"line":3,"start":2,"end":39},{"line":4,"start":2,"end":41},{"line":5,"start":2,"end":18}],"diff":[{"line":13,"start":2,"end":44},{"line":14,"start":3,"end":45}],"first":[{"line":8,"start":7,"end":8}],"remove":[{"line":3,"start":2,"end":39},{"line":4,"start":2,"end":41}]},"source":".decl avg_except(I:number, Avg:float)    \\navg_except(I, Avg) :- \\n  vals(I, _),\\n  N = sum 1.0 : { vals(J, _), I != J },\\n  Total = sum V : { vals(J, V), I != J },\\n  Avg = Total / N.\\n  \\nchanging_mean(I) :-\\n  vals(I, _),\\n  N = sum 1.0 : vals(_, _),\\n  Total = sum V : vals(_, V),\\n  Avg = Total / N,\\n  avg_except(I, AvgExcept),\\n  ((Avg > AvgExcept, Avg - AvgExcept < 0.1);\\n   (Avg < AvgExcept, AvgExcept - Avg < 0.1)).","author":"g","implementation":""},{"task":"changing_mean","language":"python-functional","plan":{"remove":[{"line":6,"start":4,"end":52}],"diff":[{"line":8,"start":4,"end":35},{"line":3,"start":2,"end":34}],"new":[{"line":6,"start":4,"end":52},{"line":7,"start":4,"end":34},{"line":1,"start":0,"end":24},{"line":2,"start":2,"end":56},{"line":3,"start":2,"end":34}],"orig":[{"line":2,"start":2,"end":56},{"line":1,"start":0,"end":24}],"first":[{"line":9,"start":6,"end":14},{"line":10,"start":2,"end":13}]},"source":"\\ndef changing_mean(vals):\\n  start_mean = sum([l[\'value\'] for l in vals])/len(vals)\\n  diff = lambda m, sm: abs(m - sm)\\n    \\n  for i,elem in enumerate(vals):\\n    new_ls = [x[\'value\'] for x in vals if x != elem]\\n    mean = sum(new_ls)/len(new_ls)\\n    if diff(mean,start_mean) < 0.1:\\n      return i\\n  return None\\n","author":"g","implementation":""},{"task":"exists_unique","language":"python-imperative","plan":{},"source":"\\ndef exists_unique(list):\\n    values = [l[\\"value\\"] for l in list]\\n    for elem in values:\\n        if values.count(elem) == 1:\\n            return 1\\n    return 0\\n","author":"g","implementation":""},{"task":"exists_unique","language":"python-pandas","plan":{},"source":"\\ndef exists_unique(list):\\n    values = list.value.value_counts()\\n    for val in values:\\n        if val == 1:\\n            return 1\\n    return 0\\n","author":"g","implementation":""},{"task":"exists_unique","language":"sql","plan":{},"source":"\\n    SELECT CASE WHEN EXISTS (\\n    SELECT value\\n    FROM list\\n    GROUP BY value\\n    HAVING Count(*) == 1\\n    )\\n    THEN CAST(1 AS INT)\\n    ELSE CAST(0 AS INT)\\n    END\\n","author":"g","implementation":""},{"task":"exists_unique","language":"datalog","plan":{},"source":"\\n.decl is_unique(Value:number)\\nis_unique(Value) :-\\nlist(_,Value), !not_unique(Value).\\n.decl not_unique(Value:number)\\nnot_unique(Value) :- list(Id1,Value), list(Id2,Value), Id1 != Id2.\\n\\nexists_unique(Value):-\\n(is_unique(_),Value=1);\\n(!is_unique(_),Value=0).\\n\\n","author":"g","implementation":""},{"task":"exists_unique","language":"python-functional","plan":{},"source":"\\ndef exists_unique(list):\\n    values = [l[\\"value\\"] for l in list]\\n    return int(any(values.count(x) == 1 for x in values))\\n","author":"g","implementation":""},{"task":"scc","language":"sql","plan":{"vertices":[{"line":1,"start":0,"end":23}],"edge_match":[{"line":6,"start":2,"end":30}],"edge_sequence":[{"line":4,"start":2,"end":33},{"line":5,"start":2,"end":41}],"source<->target":[{"line":11,"start":2,"end":62},{"line":10,"start":2,"end":44},{"line":14,"start":0,"end":33},{"line":8,"start":0,"end":22},{"line":9,"start":2,"end":33},{"line":13,"start":0,"end":31}],"graph":[{"line":2,"start":2,"end":43}]},"source":"WITH RECURSIVE\\nclosure(source, target) AS (\\n  SELECT DISTINCT source, target FROM graph\\n  UNION\\n  SELECT edge.source, path.target\\n  FROM closure as path JOIN graph as edge\\n  ON edge.target = path.source\\n),\\ncomponent(v1, v2) AS (\\n  SELECT path.source, path.target\\n  FROM closure as path JOIN closure as path_\\n  ON path.source = path_.target AND path.target = path_.source\\n)\\nSELECT S.v2 FROM component as S\\nJOIN query ON S.v1 = query.source","author":"scott","implementation":""},{"task":"scc","language":"python-imperative","plan":{"graph":[{"line":2,"start":2,"end":18},{"line":5,"start":4,"end":32},{"line":6,"start":4,"end":32},{"line":3,"start":2,"end":20},{"line":4,"start":4,"end":51},{"line":18,"start":2,"end":25}],"source<->target":[{"line":19,"start":4,"end":41},{"line":20,"start":8,"end":39},{"line":16,"start":2,"end":29},{"line":17,"start":2,"end":13},{"line":22,"start":2,"end":15},{"line":21,"start":6,"end":27}],"vertices":[{"line":1,"start":2,"end":19},{"line":12,"start":8,"end":53},{"line":13,"start":12,"end":55},{"line":14,"start":10,"end":24},{"line":15,"start":10,"end":49},{"line":8,"start":2,"end":16},{"line":9,"start":4,"end":19},{"line":21,"start":9,"end":9},{"line":7,"start":0,"end":16}],"edge_sequence":[{"line":10,"start":4,"end":22},{"line":11,"start":6,"end":29}]},"source":"def scc(graph, query):\\n  reachable = set()\\n  vertices = set()\\n  for edge in graph:\\n    reachable.add((edge[\\"source\\"], edge[\\"target\\"]))\\n    vertices.add(edge[\\"source\\"])\\n    vertices.add(edge[\\"target\\"])\\n  changed = True\\n  while changed:\\n    changed = False\\n    for edge in graph:\\n      for vertex in vertices:\\n        if ((edge[\\"source\\"], vertex) not in reachable\\n            and (edge[\\"target\\"], vertex) in reachable):\\n          changed = True\\n          reachable.add((edge[\\"source\\"], vertex))\\n  source = query[0][\\"source\\"]\\n  result = []\\n  for vertex in vertices:\\n    if ((source, vertex) in reachable and\\n        (vertex, source) in reachable):\\n      result.append(vertex)\\n  return result","author":"scott","implementation":""},{"task":"scc","language":"python-functional","plan":{"source<->target":[{"line":13,"start":4,"end":31},{"line":16,"start":4,"end":46},{"line":17,"start":6,"end":65}],"edge_sequence":[{"line":4,"start":12,"end":44},{"line":5,"start":12,"end":29}],"edge_match":[{"line":6,"start":12,"end":39}],"vertices":[{"line":1,"start":4,"end":23},{"line":2,"start":8,"end":20},{"line":3,"start":12,"end":36},{"line":9,"start":4,"end":18},{"line":10,"start":8,"end":19},{"line":11,"start":8,"end":47},{"line":15,"start":4,"end":31},{"line":7,"start":8,"end":26}],"graph":[{"line":14,"start":4,"end":68}]},"source":"def scc(graph, query):\\n    def step(relation):\\n        return set([\\n            (source, edge[\\"target\\"])\\n            for (source, target) in relation\\n            for edge in graph\\n            if target == edge[\\"source\\"]\\n        ]).union(relation)\\n\\n    def fix(f, x):\\n        next = f(x)\\n        return x if next == x else fix(f, next)\\n\\n    source = query[0][\\"source\\"]\\n    init = set([(edge[\\"source\\"], edge[\\"target\\"]) for edge in graph])\\n    reachable = fix(step, init)\\n    return list(set([v for (_, v) in reachable\\n      if (v, source) in reachable and (source, v) in reachable]))","author":"scott","implementation":""},{"task":"scc","language":"datalog","plan":{"edge_match":[{"line":8,"start":31,"end":32},{"line":5,"start":22,"end":22},{"line":5,"start":31,"end":31},{"line":5,"start":22,"end":23},{"line":5,"start":31,"end":32}],"edge_sequence":[{"line":4,"start":14,"end":25},{"line":5,"start":13,"end":36}],"graph":[{"line":10,"start":0,"end":26},{"line":7,"start":0,"end":26},{"line":8,"start":0,"end":26},{"line":6,"start":0,"end":23}],"source<->target":[{"line":0,"start":0,"end":32},{"line":1,"start":0,"end":24},{"line":2,"start":0,"end":37},{"line":9,"start":0,"end":35}],"vertices":[{"line":3,"start":0,"end":32},{"line":4,"start":0,"end":26},{"line":5,"start":0,"end":37}]},"source":".decl scc1(x: symbol, y: symbol)\\nscc1(x, x) :- vertex(x).\\nscc1(x, y) :- path(x, y), path(y, x).\\n.decl path(x: symbol, y: symbol)\\npath(x, y) :- graph(x, y).\\npath(x,y) :- graph(x, z), path(z, y).\\n.decl vertex(x: symbol)\\nvertex(x)  :- graph(x, _).\\nvertex(x)  :- graph(_, x).\\nscc(x) :- query(src), scc1(src, x).","author":"scott","implementation":""},{"task":"unique_product","language":"python-imperative","plan":{"count":[{"line":3,"start":2,"end":21}],"check":[{"line":4,"start":4,"end":31},{"line":2,"start":2,"end":37},{"line":3,"start":2,"end":21}],"name":[{"line":5,"start":6,"end":17},{"line":6,"start":2,"end":13}]},"source":"\\ndef unique_product(list):\\n  values = [l[\\"value\\"] for l in list]\\n  for elem in values:\\n    if values.count(elem) == 1:\\n      return elem\\n  return None\\n","author":"g","implementation":""},{"task":"unique_product","language":"python-pandas","plan":{"check":[{"line":3,"start":4,"end":23}],"name":[{"line":2,"start":15,"end":42},{"line":3,"start":24,"end":30},{"line":2,"start":14,"end":42}]},"source":"\\ndef unique_product(list):\\n  return list[list.groupby(\'value\').value.\\n    transform(len) == 1].value\\n","author":"g","implementation":""},{"task":"unique_product","language":"r","plan":{"name":[{"line":5,"start":4,"end":15},{"line":4,"start":4,"end":16}],"check":[{"line":1,"start":2,"end":10},{"line":2,"start":4,"end":24},{"line":3,"start":4,"end":22}]},"source":"unique_product <- function(list) {\\n  list %>%\\n    add_count(value) %>%\\n    filter(n == 1) %>%\\n    slice(1) %>%\\n    pull(value)\\n}","author":"g","implementation":""},{"task":"unique_product","language":"q","plan":{"check":[{"line":1,"start":2,"end":41},{"line":2,"start":8,"end":23}],"name":[{"line":2,"start":2,"end":23}]},"source":"unique_product: {[items]\\n  counts: count each group items[`value];\\n  first where[counts=1]}","author":"g","implementation":""},{"task":"unique_product","language":"sql","plan":{"check":[{"line":4,"start":0,"end":20}],"count":[],"name":[{"line":1,"start":0,"end":12},{"line":2,"start":0,"end":9},{"line":3,"start":0,"end":14}]},"source":"\\nSELECT value\\nFROM list\\nGROUP BY value\\nHAVING Count(*) == 1\\n","author":"g","implementation":""},{"task":"unique_product","language":"datalog","plan":{"check":[{"line":7,"start":4,"end":48},{"line":3,"start":4,"end":37}],"count":[{"line":3,"start":4,"end":17}],"name":[{"line":7,"start":4,"end":20}]},"source":"\\n.decl is_unique(Value:symbol)\\nis_unique(Value) :-\\n    list(_,Value), !not_unique(Value).\\n    \\n.decl not_unique(Value:symbol)\\nnot_unique(Value) :- \\n    list(id1,Value), list(id2,Value), id1 != id2.\\n\\nunique_product(value) :- is_unique(value).\\n","author":"g","implementation":""},{"task":"unique_product","language":"python-functional","plan":{"count":[{"line":3,"start":14,"end":31}],"check":[{"line":3,"start":32,"end":55}],"name":[{"line":3,"start":9,"end":32},{"line":2,"start":2,"end":37}]},"source":"\\ndef unique_product(list):\\n  values = [l[\\"value\\"] for l in list]\\n  return next(x for x in values if values.count(x) == 1)\\n","author":"g","implementation":""},{"task":"continent_by_population","language":"python-pandas","plan":{"group":[{"line":1,"start":22,"end":43}],"average":[{"line":1,"start":43,"end":61}],"max":[{"line":2,"start":24,"end":41}],"name":[{"line":2,"start":9,"end":24},{"line":2,"start":41,"end":42}]},"source":"def continent_by_population(countries):\\n  mean_pop = countries.groupby(\'continent\').population.mean()\\n  return mean_pop.index[mean_pop.argmax()]","author":"will","implementation":""},{"task":"continent_by_population","language":"sql","plan":{"max":[{"line":3,"start":25,"end":29},{"line":3,"start":0,"end":8},{"line":4,"start":0,"end":7}],"average":[{"line":3,"start":9,"end":24}],"group":[{"line":2,"start":0,"end":18},{"line":1,"start":0,"end":14}],"name":[{"line":0,"start":0,"end":16}]},"source":"SELECT continent \\nFROM countries\\nGROUP BY continent\\nORDER BY AVG(population) DESC\\nLIMIT 1","author":"will","implementation":""},{"task":"continent_by_population","language":"datalog","plan":{"max":[{"line":10,"start":2,"end":69},{"line":9,"start":2,"end":41}],"group":[{"line":3,"start":18,"end":45},{"line":4,"start":26,"end":53}],"name":[{"line":8,"start":2,"end":29},{"line":7,"start":24,"end":33}],"average":[{"line":5,"start":2,"end":30},{"line":4,"start":2,"end":26},{"line":3,"start":2,"end":18},{"line":2,"start":2,"end":29},{"line":0,"start":0,"end":54},{"line":1,"start":0,"end":37}]},"source":".decl average_population(Continent:symbol, Avg:number)\\naverage_population(Continent, Avg) :-\\n  countries(Continent, _, _),\\n  Total = sum P : countries(Continent, _, P),\\n  Num_countries = count : countries(Continent, _, _),\\n  Avg = Total / Num_countries.\\n  \\ncontinent_by_population(Continent) :- \\n  countries(Continent, _, _), \\n  average_population(Continent, Max_avg),\\n  Max_avg = max A : { countries(C, _, _), average_population(C, A) }.","author":"will","implementation":""},{"task":"continent_by_population","language":"q","plan":{"max":[{"line":3,"start":3,"end":8},{"line":3,"start":15,"end":28}],"average":[{"line":1,"start":9,"end":24},{"line":1,"start":2,"end":9}],"name":[{"line":3,"start":29,"end":38},{"line":3,"start":54,"end":64}],"group":[{"line":1,"start":25,"end":52}]},"source":"averages: \\n  select avg(population) by continent from countries;\\ncontinent_by_population: \\n  (first select[>population] continent from averages) `continent","author":"will","implementation":""},{"task":"continent_by_population","language":"python-functional","plan":{"group":[{"line":3,"start":33,"end":52},{"line":4,"start":17,"end":48}],"name":[{"line":6,"start":2,"end":3},{"line":2,"start":29,"end":30},{"line":8,"start":5,"end":15},{"line":9,"start":8,"end":18},{"line":11,"start":42,"end":45},{"line":11,"start":2,"end":8},{"line":3,"start":5,"end":15},{"line":5,"start":4,"end":31},{"line":1,"start":2,"end":55},{"line":2,"start":2,"end":30},{"line":7,"start":2,"end":14},{"line":9,"start":4,"end":7},{"line":9,"start":24,"end":51},{"line":10,"start":2,"end":3}],"max":[{"line":11,"start":9,"end":42}],"average":[{"line":8,"start":16,"end":37},{"line":9,"start":19,"end":23},{"line":3,"start":17,"end":32},{"line":9,"start":24,"end":51},{"line":9,"start":4,"end":7},{"line":10,"start":2,"end":3},{"line":7,"start":2,"end":14},{"line":2,"start":2,"end":30},{"line":6,"start":2,"end":3},{"line":5,"start":4,"end":31}]},"source":"def continent_by_population(countries):\\n  continents = set([c[\'continent\'] for c in countries])\\n  populations_by_continent = [\\n    (continent, [c[\'population\'] for c in countries \\n                 if c[\'continent\'] == continent])\\n    for continent in continents\\n  ]\\n  averages = [\\n    (continent, sum(pops) / len(pops))\\n    for continent, pops in populations_by_continent\\n  ]\\n  return max(averages, key=lambda t: t[1])[0]","author":"will","implementation":""},{"task":"continent_by_population","language":"python-imperative","plan":{"name":[{"line":15,"start":2,"end":22},{"line":7,"start":2,"end":22},{"line":13,"start":6,"end":31},{"line":9,"start":2,"end":16},{"line":9,"start":32,"end":59},{"line":3,"start":4,"end":36},{"line":1,"start":2,"end":32},{"line":1,"start":46,"end":47},{"line":4,"start":4,"end":30},{"line":5,"start":4,"end":30}],"max":[{"line":11,"start":4,"end":52},{"line":12,"start":6,"end":27},{"line":8,"start":2,"end":20},{"line":9,"start":2,"end":5},{"line":9,"start":32,"end":59}],"average":[{"line":9,"start":17,"end":31},{"line":10,"start":4,"end":27},{"line":4,"start":30,"end":58},{"line":5,"start":30,"end":38}],"group":[{"line":2,"start":2,"end":27},{"line":3,"start":16,"end":36}]},"source":"def continent_by_population(countries):\\n  continent_stats = defaultdict(lambda: [0, 0])\\n  for country in countries:\\n    continent = country[\'continent\']\\n    continent_stats[continent][0] += country[\'population\']\\n    continent_stats[continent][1] += 1\\n     \\n  max_continent = None\\n  max_average = None\\n  for continent, [total, count] in continent_stats.items():\\n    average = total / count\\n    if max_average is None or max_average < average:\\n      max_average = average\\n      max_continent = continent\\n      \\n  return max_continent","author":"will","implementation":""},{"task":"continent_by_population","language":"r","plan":{"name":[{"line":5,"start":4,"end":15},{"line":4,"start":31,"end":34}],"max":[{"line":4,"start":4,"end":30},{"line":3,"start":43,"end":46}],"average":[{"line":3,"start":4,"end":42},{"line":2,"start":24,"end":27}],"group":[{"line":1,"start":12,"end":15},{"line":2,"start":4,"end":23},{"line":1,"start":2,"end":12}]},"source":"continent_by_population <- function(countries) {\\n  countries %>%\\n    group_by(continent) %>%\\n    summarize(mean_pop = mean(population)) %>%\\n    slice(which.max(mean_pop)) %>%\\n    .$continent\\n}","author":"will","implementation":""},{"task":"strings_to_numbers","language":"python-pandas","plan":{"cond":[{"line":2,"start":4,"end":51}],"clean":[{"line":3,"start":15,"end":41}],"number":[{"line":3,"start":41,"end":42},{"line":3,"start":4,"end":15}],"iter":[{"line":4,"start":9,"end":48}]},"source":"def strings_to_numbers(numbers):\\n  def convert(row):\\n    sep = \\",\\" if row.format == \'comma_sep\' else \\"_\\"\\n    return int(row.value.replace(sep, \\"\\"))\\n  return numbers.apply(convert, axis=1).tolist()","author":"will","implementation":""},{"task":"strings_to_numbers","language":"sql","plan":{"cond":[{"line":1,"start":8,"end":19},{"line":4,"start":6,"end":18},{"line":5,"start":8,"end":34},{"line":6,"start":8,"end":34},{"line":7,"start":6,"end":9}],"clean":[{"line":2,"start":26,"end":49},{"line":3,"start":26,"end":49},{"line":2,"start":4,"end":12},{"line":3,"start":6,"end":13},{"line":7,"start":9,"end":14}],"number":[{"line":1,"start":2,"end":7},{"line":8,"start":4,"end":15}],"iter":[{"line":9,"start":0,"end":12}]},"source":"SELECT \\n  CAST(\\n    REPLACE(\\n      value, \\n      CASE format \\n        WHEN \\"comma_sep\\" THEN \\",\\" \\n        WHEN \\"under_sep\\" THEN \\"_\\" \\n      END, \\"\\")\\n    AS integer)\\nFROM numbers","author":"will","implementation":""},{"task":"strings_to_numbers","language":"datalog","plan":{"number":[{"line":13,"start":2,"end":22}],"cond":[{"line":6,"start":2,"end":37},{"line":7,"start":3,"end":38},{"line":1,"start":0,"end":28}],"clean":[{"line":2,"start":0,"end":32},{"line":3,"start":2,"end":34},{"line":4,"start":2,"end":19},{"line":5,"start":2,"end":26},{"line":8,"start":2,"end":33},{"line":9,"start":3,"end":44},{"line":12,"start":2,"end":40},{"line":0,"start":0,"end":62}],"iter":[{"line":1,"start":29,"end":50}]},"source":".decl clean(Format:symbol, Inp:symbol, I:number, Outp:symbol) \\nclean(Format, Inp, 0, \\"\\") :- numbers(Format, Inp).\\nclean(Format, Inp, I+1, Outp) :-\\n  clean(Format, Inp, I, Outp_rec),\\n  I <= strlen(Inp),\\n  Chr = substr(Inp, I, 1),\\n  ((Format = \\"comma_sep\\", Sep = \\",\\");\\n   (Format = \\"under_sep\\", Sep = \\"_\\")),\\n  ((Chr  = Sep, Outp = Outp_rec);\\n   (Chr != Sep, Outp = cat(Outp_rec, Chr))).\\n\\nstrings_to_numbers(N) :-\\n  clean(Format, Inp, strlen(Inp), Outp),\\n  N = to_number(Outp).","author":"will","implementation":""},{"task":"strings_to_numbers","language":"q","plan":{"cond":[{"line":1,"start":2,"end":56}],"clean":[{"line":2,"start":8,"end":25}],"number":[{"line":2,"start":2,"end":7}],"iter":[{"line":5,"start":2,"end":45}]},"source":"convert: {[val; format] \\n  sep: ((\\"comma_sep\\"; \\"under_sep\\") ! (\\",\\"; \\"_\\")) format;\\n  \\"J\\" $ ssr[val; sep; \\"\\"]}\\n  \\nstrings_to_numbers:\\n  convert\'[numbers[`value]; numbers[`format]]","author":"will","implementation":""},{"task":"strings_to_numbers","language":"python-functional","plan":{"iter":[{"line":1,"start":2,"end":10},{"line":4,"start":4,"end":30},{"line":5,"start":2,"end":3}],"number":[{"line":2,"start":4,"end":8},{"line":3,"start":55,"end":56}],"clean":[{"line":2,"start":8,"end":29},{"line":3,"start":50,"end":55}],"cond":[{"line":3,"start":6,"end":50}]},"source":"def strings_to_numbers(numbers):\\n  return [\\n    int(row[\\"value\\"].replace(\\n      \\",\\" if row[\\"format\\"] == \\"comma_sep\\" else \\"_\\", \\"\\"))\\n    for row in numbers\\n  ]","author":"will","implementation":""},{"task":"strings_to_numbers","language":"python-imperative","plan":{"iter":[{"line":1,"start":1,"end":13},{"line":7,"start":4,"end":18},{"line":7,"start":52,"end":53},{"line":2,"start":2,"end":21}],"cond":[{"line":3,"start":4,"end":36},{"line":4,"start":6,"end":15},{"line":5,"start":4,"end":9},{"line":6,"start":6,"end":15}],"number":[{"line":7,"start":18,"end":22},{"line":7,"start":51,"end":52}],"clean":[{"line":7,"start":22,"end":51}]},"source":"def strings_to_numbers(numbers):\\n  output = []\\n  for row in numbers:\\n    if row[\\"format\\"] == \'comma_sep\':\\n      sep = \\",\\"\\n    else:\\n      sep = \\"_\\"\\n    output.append(int(row[\\"value\\"].replace(sep, \\"\\")))\\n  return output","author":"will","implementation":""},{"task":"strings_to_numbers","language":"r","plan":{"cond":[{"line":3,"start":13,"end":52}],"clean":[{"line":2,"start":31,"end":47},{"line":3,"start":6,"end":13},{"line":3,"start":52,"end":57}],"number":[{"line":2,"start":20,"end":31},{"line":3,"start":57,"end":58}],"iter":[{"line":1,"start":2,"end":13},{"line":2,"start":4,"end":20},{"line":3,"start":58,"end":63},{"line":4,"start":4,"end":16}]},"source":"strings_to_numbers <- function(numbers) {\\n  numbers %>%\\n    mutate(output = as.numeric(str_replace_all(\\n      value, ifelse(format == \\"comma_sep\\", \\",\\", \\"_\\"), \\"\\"))) %>%\\n    pull(output)\\n}","author":"will","implementation":""},{"task":"average_adjacent","language":"sql","plan":{"order":[{"line":3,"start":28,"end":41},{"line":4,"start":2,"end":11},{"line":2,"start":6,"end":12},{"line":3,"start":2,"end":6},{"line":2,"start":0,"end":4},{"line":6,"start":0,"end":13}],"pair adjacent":[{"line":3,"start":8,"end":50},{"line":0,"start":0,"end":6},{"line":1,"start":2,"end":8},{"line":5,"start":0,"end":22}],"average":[{"line":1,"start":8,"end":28}]},"source":"SELECT\\n  time, (x + next) / 2 as x\\nFROM (SELECT\\n  time, x, LEAD(x, 1) OVER (ORDER BY time) as next\\n  FROM data)\\nWHERE next is not null\\nORDER BY time","author":"scott","implementation":""},{"task":"average_adjacent","language":"python-imperative","plan":{"order":[{"line":5,"start":2,"end":36}],"pair adjacent":[{"line":7,"start":2,"end":24},{"line":8,"start":2,"end":13},{"line":9,"start":2,"end":24},{"line":10,"start":4,"end":44},{"line":6,"start":2,"end":40},{"line":12,"start":4,"end":24},{"line":13,"start":2,"end":15}],"average":[{"line":1,"start":2,"end":20},{"line":2,"start":4,"end":13},{"line":3,"start":2,"end":20},{"line":4,"start":4,"end":25},{"line":11,"start":4,"end":62}]},"source":"def average_adjacent(data):\\n  if len(data) == 0:\\n    return []\\n  if len(data) == 1:\\n    return [data[0][\\"x\\"]]\\n  data.sort(key=lambda v: v[\\"time\\"])\\n  previous, current = None, data[0][\\"x\\"]\\n  time = data[0][\\"time\\"]\\n  result = []\\n  for value in data[1:]:\\n    previous = current; current = value[\\"x\\"]\\n    result.append({\\"time\\": time, \\"x\\": (previous + current)/2})\\n    time = value[\\"time\\"]\\n  return result","author":"scott","implementation":""},{"task":"average_adjacent","language":"python-functional","plan":{"order":[{"line":1,"start":0,"end":48}],"pair adjacent":[{"line":2,"start":2,"end":10},{"line":3,"start":4,"end":23},{"line":5,"start":0,"end":43},{"line":6,"start":2,"end":3}],"average":[{"line":4,"start":0,"end":35}]},"source":"def average_adjacent(data):\\n  data = sorted(data, key=lambda v: v[\\"time\\"])\\n  return [\\n    {\\"time\\": v[\\"time\\"],\\n     \\"x\\": (v[\\"x\\"] + next[\\"x\\"]) / 2}\\n    for next, v in zip(data[1:], data[:-1])\\n  ]","author":"scott","implementation":""},{"task":"average_adjacent","language":"python-pandas","plan":{"average":[{"line":4,"start":2,"end":39},{"line":5,"start":2,"end":16}],"order":[{"line":1,"start":2,"end":33}],"pair adjacent":[{"line":2,"start":2,"end":43},{"line":3,"start":2,"end":44}]},"source":"def average_adjacent(data):\\n  data = data.sort_values(\\"time\\")\\n  lagging = data[1:].reset_index(drop=True)\\n  leading = data[:-1].reset_index(drop=True)\\n  leading.x = (lagging.x + leading.x)/2\\n  return leading","author":"scott","implementation":""},{"task":"average_adjacent","language":"datalog","plan":{"order":[{"line":0,"start":0,"end":32},{"line":1,"start":0,"end":44}],"pair adjacent":[{"line":7,"start":27,"end":44},{"line":7,"start":46,"end":72},{"line":5,"start":0,"end":51},{"line":6,"start":27,"end":72},{"line":4,"start":0,"end":37},{"line":2,"start":0,"end":40},{"line":3,"start":0,"end":45},{"line":7,"start":2,"end":20},{"line":8,"start":2,"end":29},{"line":6,"start":0,"end":26}],"average":[{"line":7,"start":74,"end":87},{"line":6,"start":74,"end":88},{"line":9,"start":2,"end":15}]},"source":".decl less(x: number, y: number)\\nless(x, y) :- data(x, _), data(y, _), x < y.\\n.decl intermediate(x: number, y: number)\\nintermediate(x, y) :- less(x, z), less(z, y).\\n.decl immediate(x: number, y: number)\\nimmediate(x, y) :- less(x, y), !intermediate(x, y).\\naverage_adjacent(t1, v) :-\\n  immediate(t1, t2),\\n  data(t1, v1), data(t2, v2),\\n  v = (v1+v2)/2.","author":"scott","implementation":""}]')},rePB:function(n,e,t){"use strict";function a(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}t.d(e,"a",(function(){return a}))},vNVm:function(n,e,t){"use strict";var a=t("zoAU"),r=t("AroE");e.__esModule=!0,e.useIntersection=function(n){var e=n.rootMargin,t=n.disabled||!o,r=(0,s.useRef)(),d=(0,s.useState)(!1),u=a(d,2),c=u[0],p=u[1],m=(0,s.useCallback)((function(n){r.current&&(r.current(),r.current=void 0),t||c||n&&n.tagName&&(r.current=function(n,e,t){var a=function(n){var e=n.rootMargin||"",t=l.get(e);if(t)return t;var a=new Map,r=new IntersectionObserver((function(n){n.forEach((function(n){var e=a.get(n.target),t=n.isIntersecting||n.intersectionRatio>0;e&&t&&e(t)}))}),n);return l.set(e,t={id:e,observer:r,elements:a}),t}(t),r=a.id,s=a.observer,i=a.elements;return i.set(n,e),s.observe(n),function(){s.unobserve(n),0===i.size&&(s.disconnect(),l.delete(r))}}(n,(function(n){return n&&p(n)}),{rootMargin:e}))}),[t,e,c]);return(0,s.useEffect)((function(){o||c||(0,i.default)((function(){return p(!0)}))}),[c]),[m,c]};var s=t("q1tI"),i=r(t("0G5g")),o="undefined"!==typeof IntersectionObserver;var l=new Map},wTVA:function(n,e){n.exports=function(n){if(Array.isArray(n))return n}},wkBT:function(n,e){n.exports=function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}},yLpj:function(n,e){var t;t=function(){return this}();try{t=t||new Function("return this")()}catch(a){"object"===typeof window&&(t=window)}n.exports=t}}]);
<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>Expressiveness Benchmark</title><meta name="viewport" content="initial-scale=1.0, width=device-width"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-16662292-3"></script><script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag(&#x27;js&#x27;, new Date());

        gtag(&#x27;config&#x27;, &#x27;UA-16662292-3&#x27;);
        </script><meta name="next-head-count" content="5"/><link rel="preload" href="/expressiveness-benchmark/_next/static/css/bb7eb15fa0f289a0fe43.css" as="style"/><link rel="stylesheet" href="/expressiveness-benchmark/_next/static/css/bb7eb15fa0f289a0fe43.css" data-n-g=""/><noscript data-n-css=""></noscript><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/main-f76717e2d376ecc40880.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/webpack-95c2b224bccf352ee870.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/framework.be9133c4aa54b58ca1d2.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/commons.2ac40408ef03d6c65327.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/pages/_app-73083bb29ec45f84b02a.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/48fe5443.8cbf9bb7b72041d99e6c.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/29107295.0ba1e3749ecd6faab06a.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/f7f3ae4b7ca4f7fc373506a61db832ad86bd3f74.9662a54cf737546376a6.js" as="script"/><link rel="preload" href="/expressiveness-benchmark/_next/static/chunks/pages/analysis-98fe18b391f89ccfcf49.js" as="script"/></head><body><div id="__next"><div id="container"><div class="title"><h1><a href="/expressiveness-benchmark">Expressiveness Benchmark</a></h1><nav><span class="desktop-inline"><a href="/expressiveness-benchmark">Task matrix</a></span><span class="mobile-inline"><a href="/expressiveness-benchmark">Benchmark</a></span><a href="/expressiveness-benchmark/analysis">Dataset analysis</a></nav></div><div class="analysis"><h2>Dataset analysis</h2><div class="column-container big"><div class="sidebar"><div class="sidebar-sticky"><strong>Table of contents</strong><ol><li><a href="#question-1">Overall, how concise are programs in each language and category?</a></li><li><a href="#question-2">For a given language, what are its most and least concise tasks?</a></li><li><a href="#question-3">For a given task, what are its most and least concise languages?</a></li><li><a href="#question-4">How much do plans overlap in each language?</a></li></ol></div></div><div class="main-content"><div class="question"><h3><a id="question-1" name="question-1">1<!-- -->. <!-- -->Overall, how concise are programs in each language and category?</a></h3><div class="question-body"><p>Our goal is to use quantitative metrics to compare the conciseness of programs in each language. We use <strong>number of tokens</strong> to measure program length. For example, the program &quot;<code>(var_name + 1) * 2</code>&quot; has the tokens &quot;<code>[(, var_name, +, 1, ), *, 2]</code>&quot; for a length of 7. Using tokens instead of lines-of-code or number of characters helps control for stylistic differences in indentation, and it does not penalize e.g. longer variable names. The boxplots below show the distribution of the number of tokens in programs for each category, sorted by median.</p><center><div></div><div></div></center></div></div><div class="question"><h3><a id="question-2" name="question-2">2<!-- -->. <!-- -->For a given language, what are its most and least concise tasks?</a></h3><div class="question-body"><p>To compare languages within categories, we take each task and assign its programs a <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> based on length. The z-score tells us: for a given task (e.g. <a href="/expressiveness-benchmark/task/youngest_over_35">Youngest over 35</a>), how does program&#x27;s size in one language compare to other languages? A high z-score means a larger program than normal, and low z-score is smaller. Because the z-score is normalized, we can compare z-scores across multiple tasks. A language&#x27;s highest z-score is its worst category, and lowest z-score is its best category. Below we plot the z-scores for each language and category (z-scores within a given category/language pair are averaged).</p><center><div></div></center><p>To understand these statistics, let&#x27;s dig into an example. For <strong>Datalog</strong>, its best category is <strong>Joins</strong> and worst category is <strong>Strings</strong>. Here are the two Datalog join programs:</p><p>Datalog has more concise programs for joins because relationships between tables are implicitly expressed by sharing variables across tables. By contrast, languages like SQL require explicit <code>JOIN</code> clauses. But if we look to <strong>Strings</strong>, we can see when Datalog gets verbose:</p><p>The main issue is that Datalog (i.e. Souffle) does not have many built-in primitives for string process like splitting or removing characters, so re-implementing those primitives requires a lot of code.</p></div></div><div class="question"><h3><a id="question-3" name="question-3">3<!-- -->. <!-- -->For a given task, what are its most and least concise languages?</a></h3><div class="question-body"><p>To answer this question, we can transpose the previous analysis. For each category, we can compare the z-scores for different languages, shown below.</p><center><div></div></center><p><strong>Python - Imperative</strong> has the most verbose programs for every category except <strong>Strings</strong>. The most concise programs vary mostly between <strong>SQL</strong>, <strong>R</strong>, and <strong>Q</strong>.</p></div></div><div class="question"><h3><a id="question-4" name="question-4">4<!-- -->. <!-- -->How much do plans overlap in each language?</a></h3><div class="question-body"><p>Each program is annotated by which pieces of the code implement which sub-goals of a task. For example, the <a href="/expressiveness-benchmark/task/continent_by_population">Continent with highest average population</a> task:</p><div class="task-spec"><strong>Specification: </strong>F<!-- -->i<!-- -->n<!-- -->d<!-- --> <!-- -->t<!-- -->h<!-- -->e<!-- --> <span class="goal" style="background:rgba(161, 201, 244, 0.5);border:2px solid rgba(161, 201, 244, 1)">name of the continent</span> <!-- -->w<!-- -->i<!-- -->t<!-- -->h<!-- --> <!-- -->t<!-- -->h<!-- -->e<!-- --> <span class="goal" style="background:rgba(250, 176, 228, 0.5);border:2px solid rgba(250, 176, 228, 1)">highest</span> <span class="goal" style="background:rgba(141, 229, 161, 0.5);border:2px solid rgba(141, 229, 161, 1)">average population</span> <span class="goal" style="background:rgba(255, 180, 130, 0.5);border:2px solid rgba(255, 180, 130, 1)">by country</span>.</div><div class="program-row"><div class="program-container"><h3><a href="/expressiveness-benchmark/language/python-imperative">Python - Imperative</a></h3><div class="code-viewer"><div style="display:none"><div id="ace-editor" style="width:100%;height:368px"></div></div><pre style="width:100%;height:368px;line-height:1.3em">def continent_by_population(countries):
  continent_stats = defaultdict(lambda: [0, 0])
  for country in countries:
    continent = country[&#x27;continent&#x27;]
    continent_stats[continent][0] += country[&#x27;population&#x27;]
    continent_stats[continent][1] += 1
     
  max_continent = None
  max_average = None
  for continent, [total, count] in continent_stats.items():
    average = total / count
    if max_average is None or max_average &lt; average:
      max_average = average
      max_continent = continent
      
  return max_continent</pre></div></div><div class="program-container"><h3><a href="/expressiveness-benchmark/language/python-functional">Python - Functional</a></h3><div class="code-viewer"><div style="display:none"><div id="ace-editor" style="width:100%;height:276px"></div></div><pre style="width:100%;height:276px;line-height:1.3em">def continent_by_population(countries):
  continents = set([c[&#x27;continent&#x27;] for c in countries])
  populations_by_continent = [
    (continent, [c[&#x27;population&#x27;] for c in countries 
                 if c[&#x27;continent&#x27;] == continent])
    for continent in continents
  ]
  averages = [
    (continent, sum(pops) / len(pops))
    for continent, pops in populations_by_continent
  ]
  return max(averages, key=lambda t: t[1])[0]</pre></div></div></div><p>For a given sub-goal, e.g. &quot;average population&quot;, the set of corresponding highlighted regions is collectively its <strong>plan</strong>. Plans can tell us how hard or easy a program may be to write or read. For example, Elliot Soloway <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.11.6583&amp;rep=rep1&amp;type=pdf">found in the 1980s</a> that merging two plans together is hard for programmers. In the <strong>Python - Imperative</strong> solution, the &quot;highest&quot; and &quot;average population&quot; plans are merged together into a single for-loop, whereas in the <strong>Python - Functional</strong> solution the &quot;highest&quot; plan is separated by use of a higher-order function <code>max</code>.</p><p>Based on this observation, <a href="http://rodrigoduran.net/papers/analysis-program-complexity.pdf">Duran et al.</a> proposed that the number of overlapping plans in a program could be used as a metric of cognitive complexity. Using this dataset&#x27;s plan annotations, we can actually compute this metric. Specifically, for each program, we count the number of pairs of plans that overlap. For example, above the <strong>Python - Functional</strong> program has the &quot;name&quot; and &quot;highest&quot; plans overlapping, but does not have the &quot;average&quot; and &quot;highest&quot; plans overlapping. Below we plot the distribution of plan overlaps in each language, sorted by median:</p><center><div></div></center><p>On average, the languages <strong>Q, SQL, Python - Pandas</strong>, and <strong>R</strong> had fewer overlapping plans (median 1) while the languages <strong>Python - Functional, Python - Imperative,</strong> and <strong>Datalog</strong> had a median 3 overlapping plans. For example, here are examples with 0 overlapping plans (left) and 10 overlapping plans (right).</p><div class="program-row"><div class="program-container"><h3><a href="/expressiveness-benchmark/task/continent_by_population">Continent with the highest average population</a> / <a href="/expressiveness-benchmark/language/r">R - Tidyverse</a></h3><div class="code-viewer"><div style="display:none"><div id="ace-editor" style="width:100%;height:161px"></div></div><pre style="width:100%;height:161px;line-height:1.3em">continent_by_population &lt;- function(countries) {
  countries %&gt;%
    group_by(continent) %&gt;%
    summarize(mean_pop = mean(population)) %&gt;%
    slice(which.max(mean_pop)) %&gt;%
    .$continent
}</pre></div></div><div class="program-container"><h3><a href="/expressiveness-benchmark/task/row_per_child">Row per family to row per child</a> / <a href="/expressiveness-benchmark/language/datalog">Datalog - Souffle</a></h3><div class="code-viewer"><div style="display:none"><div id="ace-editor" style="width:100%;height:138px"></div></div><pre style="width:100%;height:138px;line-height:1.3em">row_per_child(&quot;child1&quot;, dob, family, height) :-
  families(dob, _, _, family, height, _, _).
row_per_child(&quot;child2&quot;, dob, family, height) :-
  families(_, dob, _, family, _, height, _).
row_per_child(&quot;child3&quot;, dob, family, height) :-
  families(_, _, dob, family, _, _, height).</pre></div></div></div><p>The R program has a clean separation of each row for its task. The Datalog program has every plan overlapping with every other plan, for a total of 5 choose 2 = 10 overlaps.</p></div></div></div></div></div><footer>Project by <a href="https://twitter.com/wcrichton">Will Crichton</a>, <a href="https://github.com/kovach">Scott Kovach</a>, and <a href="http://gleb.fyi/">Gleb Shevchuk</a>.</footer></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/analysis","query":{},"buildId":"UAi9pXhyWdjqPaekVeAOd","assetPrefix":"/expressiveness-benchmark","nextExport":true,"autoExport":true,"isFallback":false}</script><script nomodule="" src="/expressiveness-benchmark/_next/static/chunks/polyfills-d2769c16f665abc9d1ae.js"></script><script src="/expressiveness-benchmark/_next/static/chunks/main-f76717e2d376ecc40880.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/webpack-95c2b224bccf352ee870.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/framework.be9133c4aa54b58ca1d2.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/commons.2ac40408ef03d6c65327.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/pages/_app-73083bb29ec45f84b02a.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/48fe5443.8cbf9bb7b72041d99e6c.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/29107295.0ba1e3749ecd6faab06a.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/f7f3ae4b7ca4f7fc373506a61db832ad86bd3f74.9662a54cf737546376a6.js" async=""></script><script src="/expressiveness-benchmark/_next/static/chunks/pages/analysis-98fe18b391f89ccfcf49.js" async=""></script><script src="/expressiveness-benchmark/_next/static/UAi9pXhyWdjqPaekVeAOd/_buildManifest.js" async=""></script><script src="/expressiveness-benchmark/_next/static/UAi9pXhyWdjqPaekVeAOd/_ssgManifest.js" async=""></script></body></html>